{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed0f543e-b52a-4ee2-8196-b1614a00d206",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 14:22:52.475484: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1761826972.488496 4176479 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1761826972.493071 4176479 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1761826972.503033 4176479 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1761826972.503049 4176479 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1761826972.503050 4176479 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1761826972.503051 4176479 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-10-30 14:22:52.505964: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65254526-568d-4428-aad3-462dcd3ae6d9",
   "metadata": {},
   "source": [
    "### Load Teff and log(Y) values for sample\n",
    "\n",
    "Teff and log(Y) from Culpan et. al (2022), VizieR table J/A+A/662/A40/knownhsd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb15e4e4-d2bb-41b1-8e98-77b628442dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GaiaEDR3</th>\n",
       "      <th>Teff</th>\n",
       "      <th>logY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1792620565667968</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3018713469617920</td>\n",
       "      <td>39190.0</td>\n",
       "      <td>-0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3101962820420608</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5256284056331776</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6052403489630720</td>\n",
       "      <td>36414.0</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6588</th>\n",
       "      <td>6913910539170818816</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6589</th>\n",
       "      <td>6914322576858227968</td>\n",
       "      <td>31600.0</td>\n",
       "      <td>-3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6590</th>\n",
       "      <td>6914530384555510656</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6591</th>\n",
       "      <td>6914533614371729536</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6592</th>\n",
       "      <td>6914563236760537984</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6593 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 GaiaEDR3     Teff  logY\n",
       "0        1792620565667968      NaN   NaN\n",
       "1        3018713469617920  39190.0 -0.19\n",
       "2        3101962820420608      NaN   NaN\n",
       "3        5256284056331776      NaN   NaN\n",
       "4        6052403489630720  36414.0  0.38\n",
       "...                   ...      ...   ...\n",
       "6588  6913910539170818816      NaN   NaN\n",
       "6589  6914322576858227968  31600.0 -3.00\n",
       "6590  6914530384555510656      NaN   NaN\n",
       "6591  6914533614371729536      NaN   NaN\n",
       "6592  6914563236760537984      NaN   NaN\n",
       "\n",
       "[6593 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/known_sds_Teff_logY.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdcb854-dfe9-496c-8032-ed6db605a992",
   "metadata": {},
   "source": [
    "#### Remove hot sds with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6451396-a7d6-4711-ae5c-9168283e0929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GaiaEDR3</th>\n",
       "      <th>Teff</th>\n",
       "      <th>logY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3018713469617920</td>\n",
       "      <td>39190.0</td>\n",
       "      <td>-0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6052403489630720</td>\n",
       "      <td>36414.0</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9132341717393792</td>\n",
       "      <td>30700.0</td>\n",
       "      <td>-2.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11015044926034816</td>\n",
       "      <td>33853.0</td>\n",
       "      <td>-1.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11963171843658240</td>\n",
       "      <td>41361.0</td>\n",
       "      <td>-2.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6583</th>\n",
       "      <td>6913188263109953920</td>\n",
       "      <td>49669.0</td>\n",
       "      <td>2.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6584</th>\n",
       "      <td>6913349543425935232</td>\n",
       "      <td>35133.0</td>\n",
       "      <td>-1.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6585</th>\n",
       "      <td>6913373354725177472</td>\n",
       "      <td>33550.0</td>\n",
       "      <td>-1.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6586</th>\n",
       "      <td>6913420603662102784</td>\n",
       "      <td>35500.0</td>\n",
       "      <td>-1.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6589</th>\n",
       "      <td>6914322576858227968</td>\n",
       "      <td>31600.0</td>\n",
       "      <td>-3.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2948 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 GaiaEDR3     Teff  logY\n",
       "1        3018713469617920  39190.0 -0.19\n",
       "4        6052403489630720  36414.0  0.38\n",
       "6        9132341717393792  30700.0 -2.40\n",
       "8       11015044926034816  33853.0 -1.85\n",
       "9       11963171843658240  41361.0 -2.85\n",
       "...                   ...      ...   ...\n",
       "6583  6913188263109953920  49669.0  2.24\n",
       "6584  6913349543425935232  35133.0 -1.40\n",
       "6585  6913373354725177472  33550.0 -1.80\n",
       "6586  6913420603662102784  35500.0 -1.40\n",
       "6589  6914322576858227968  31600.0 -3.00\n",
       "\n",
       "[2948 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.dropna()\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab69a086-24bf-41e9-8593-c5a943a698a6",
   "metadata": {},
   "source": [
    "### Classify trainig sources, based on effecitve temperature and He abundance\n",
    "\n",
    "if (Teff < 35000) & (logY < -1): label = 1 (sdB)\n",
    "\n",
    "else: label = 0 (not sdB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caf6492a-bd0d-4784-aca8-9a43858d5378",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4176479/973519073.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"label\"] = 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GaiaEDR3</th>\n",
       "      <th>Teff</th>\n",
       "      <th>logY</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3018713469617920</td>\n",
       "      <td>39190.0</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6052403489630720</td>\n",
       "      <td>36414.0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9132341717393792</td>\n",
       "      <td>30700.0</td>\n",
       "      <td>-2.40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11015044926034816</td>\n",
       "      <td>33853.0</td>\n",
       "      <td>-1.85</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11963171843658240</td>\n",
       "      <td>41361.0</td>\n",
       "      <td>-2.85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6583</th>\n",
       "      <td>6913188263109953920</td>\n",
       "      <td>49669.0</td>\n",
       "      <td>2.24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6584</th>\n",
       "      <td>6913349543425935232</td>\n",
       "      <td>35133.0</td>\n",
       "      <td>-1.40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6585</th>\n",
       "      <td>6913373354725177472</td>\n",
       "      <td>33550.0</td>\n",
       "      <td>-1.80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6586</th>\n",
       "      <td>6913420603662102784</td>\n",
       "      <td>35500.0</td>\n",
       "      <td>-1.40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6589</th>\n",
       "      <td>6914322576858227968</td>\n",
       "      <td>31600.0</td>\n",
       "      <td>-3.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2948 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 GaiaEDR3     Teff  logY  label\n",
       "1        3018713469617920  39190.0 -0.19      0\n",
       "4        6052403489630720  36414.0  0.38      0\n",
       "6        9132341717393792  30700.0 -2.40      1\n",
       "8       11015044926034816  33853.0 -1.85      1\n",
       "9       11963171843658240  41361.0 -2.85      0\n",
       "...                   ...      ...   ...    ...\n",
       "6583  6913188263109953920  49669.0  2.24      0\n",
       "6584  6913349543425935232  35133.0 -1.40      0\n",
       "6585  6913373354725177472  33550.0 -1.80      1\n",
       "6586  6913420603662102784  35500.0 -1.40      0\n",
       "6589  6914322576858227968  31600.0 -3.00      1\n",
       "\n",
       "[2948 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the \"label\" column with zeros\n",
    "data[\"label\"] = 0\n",
    "\n",
    "# Apply condition: Teff < 35000 and logY < -1\n",
    "theshold_Teff = 35000\n",
    "threshold_logY = -1\n",
    "condition = (data[\"Teff\"] < theshold_Teff) & (data[\"logY\"] < threshold_logY)\n",
    "data.loc[condition, \"label\"] = 1\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105178bc-0e36-458e-ae03-6cd113e66773",
   "metadata": {},
   "source": [
    "#### Plot classes in Teff-logY diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea5cfd37-b369-4a25-bccd-5783926b66db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"All data\")\n",
    "\n",
    "# Hot/He-rich\n",
    "plt.scatter(data[data[\"label\"] == 0][\"Teff\"],\n",
    "            data[data[\"label\"] == 0][\"logY\"],\n",
    "            s=10, color=\"#a6cee3\", label=\"hot/He-rich\")\n",
    "\n",
    "# sdB\n",
    "plt.scatter(data[data[\"label\"] == 1][\"Teff\"],\n",
    "            data[data[\"label\"] == 1][\"logY\"],\n",
    "            s=10, color=\"#fb8072\", label=\"sdB\")\n",
    "\n",
    "plt.plot([theshold_Teff, theshold_Teff], [-6, threshold_logY], color=\"black\", linestyle=\"--\")\n",
    "plt.plot([theshold_Teff, 0], [threshold_logY, threshold_logY], color=\"black\", linestyle=\"--\")\n",
    "\n",
    "plt.xlabel(\"Teff (K)\")\n",
    "plt.ylabel(\"logY\")\n",
    "\n",
    "plt.xlim(15000, 150000)\n",
    "plt.ylim(-5.5, 3.5)\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce2c550-f860-44bd-ba8a-53cf0289b7a5",
   "metadata": {},
   "source": [
    "### Load normalized XP spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5e50ad1-05e7-4be2-9a14-0c1c02d36452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/XP_spectra_norm.par\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GaiaEDR3</th>\n",
       "      <th>400.0</th>\n",
       "      <th>402.0</th>\n",
       "      <th>404.0</th>\n",
       "      <th>406.0</th>\n",
       "      <th>408.0</th>\n",
       "      <th>410.0</th>\n",
       "      <th>412.0</th>\n",
       "      <th>414.0</th>\n",
       "      <th>416.0</th>\n",
       "      <th>...</th>\n",
       "      <th>932.0</th>\n",
       "      <th>934.0</th>\n",
       "      <th>936.0</th>\n",
       "      <th>938.0</th>\n",
       "      <th>940.0</th>\n",
       "      <th>942.0</th>\n",
       "      <th>944.0</th>\n",
       "      <th>946.0</th>\n",
       "      <th>948.0</th>\n",
       "      <th>950.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1306361548360576</td>\n",
       "      <td>0.853450</td>\n",
       "      <td>0.941675</td>\n",
       "      <td>1.000411</td>\n",
       "      <td>0.988710</td>\n",
       "      <td>0.925614</td>\n",
       "      <td>0.866464</td>\n",
       "      <td>0.855969</td>\n",
       "      <td>0.900321</td>\n",
       "      <td>0.961643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.993973</td>\n",
       "      <td>0.998679</td>\n",
       "      <td>1.000135</td>\n",
       "      <td>0.999833</td>\n",
       "      <td>0.991327</td>\n",
       "      <td>0.981020</td>\n",
       "      <td>0.982047</td>\n",
       "      <td>0.970091</td>\n",
       "      <td>0.965854</td>\n",
       "      <td>0.977762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1792620565667968</td>\n",
       "      <td>0.959502</td>\n",
       "      <td>0.996733</td>\n",
       "      <td>1.000108</td>\n",
       "      <td>0.975493</td>\n",
       "      <td>0.947082</td>\n",
       "      <td>0.936094</td>\n",
       "      <td>0.946869</td>\n",
       "      <td>0.972096</td>\n",
       "      <td>0.992361</td>\n",
       "      <td>...</td>\n",
       "      <td>0.989064</td>\n",
       "      <td>0.997809</td>\n",
       "      <td>1.000719</td>\n",
       "      <td>0.999373</td>\n",
       "      <td>0.987119</td>\n",
       "      <td>0.970374</td>\n",
       "      <td>0.962181</td>\n",
       "      <td>0.938859</td>\n",
       "      <td>0.921021</td>\n",
       "      <td>0.916727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6052403489630720</td>\n",
       "      <td>0.974929</td>\n",
       "      <td>0.992400</td>\n",
       "      <td>1.000032</td>\n",
       "      <td>0.988859</td>\n",
       "      <td>0.966801</td>\n",
       "      <td>0.948620</td>\n",
       "      <td>0.943953</td>\n",
       "      <td>0.955887</td>\n",
       "      <td>0.972213</td>\n",
       "      <td>...</td>\n",
       "      <td>0.988757</td>\n",
       "      <td>0.997123</td>\n",
       "      <td>1.000409</td>\n",
       "      <td>1.000030</td>\n",
       "      <td>0.989502</td>\n",
       "      <td>0.975452</td>\n",
       "      <td>0.971328</td>\n",
       "      <td>0.953621</td>\n",
       "      <td>0.943489</td>\n",
       "      <td>0.949665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6353119919810816</td>\n",
       "      <td>0.928566</td>\n",
       "      <td>0.980801</td>\n",
       "      <td>1.000170</td>\n",
       "      <td>0.977861</td>\n",
       "      <td>0.934958</td>\n",
       "      <td>0.903505</td>\n",
       "      <td>0.902977</td>\n",
       "      <td>0.933175</td>\n",
       "      <td>0.970096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.988380</td>\n",
       "      <td>0.996614</td>\n",
       "      <td>1.000155</td>\n",
       "      <td>1.000293</td>\n",
       "      <td>0.990562</td>\n",
       "      <td>0.977249</td>\n",
       "      <td>0.973427</td>\n",
       "      <td>0.955111</td>\n",
       "      <td>0.943117</td>\n",
       "      <td>0.945857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10844075163628928</td>\n",
       "      <td>0.927307</td>\n",
       "      <td>0.984887</td>\n",
       "      <td>1.000189</td>\n",
       "      <td>0.971341</td>\n",
       "      <td>0.927670</td>\n",
       "      <td>0.903547</td>\n",
       "      <td>0.913471</td>\n",
       "      <td>0.949748</td>\n",
       "      <td>0.984329</td>\n",
       "      <td>...</td>\n",
       "      <td>0.990076</td>\n",
       "      <td>0.997219</td>\n",
       "      <td>1.000149</td>\n",
       "      <td>1.000254</td>\n",
       "      <td>0.991048</td>\n",
       "      <td>0.978711</td>\n",
       "      <td>0.976138</td>\n",
       "      <td>0.958996</td>\n",
       "      <td>0.947835</td>\n",
       "      <td>0.950827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20069</th>\n",
       "      <td>6916087950150111232</td>\n",
       "      <td>0.953987</td>\n",
       "      <td>0.982351</td>\n",
       "      <td>0.993574</td>\n",
       "      <td>0.978676</td>\n",
       "      <td>0.942920</td>\n",
       "      <td>0.904479</td>\n",
       "      <td>0.884542</td>\n",
       "      <td>0.897774</td>\n",
       "      <td>0.934133</td>\n",
       "      <td>...</td>\n",
       "      <td>0.990458</td>\n",
       "      <td>0.997577</td>\n",
       "      <td>1.000323</td>\n",
       "      <td>1.000104</td>\n",
       "      <td>0.990335</td>\n",
       "      <td>0.977298</td>\n",
       "      <td>0.974000</td>\n",
       "      <td>0.956321</td>\n",
       "      <td>0.944928</td>\n",
       "      <td>0.948095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20070</th>\n",
       "      <td>6916186184642798848</td>\n",
       "      <td>0.944458</td>\n",
       "      <td>0.990766</td>\n",
       "      <td>1.000156</td>\n",
       "      <td>0.973015</td>\n",
       "      <td>0.936448</td>\n",
       "      <td>0.919586</td>\n",
       "      <td>0.932130</td>\n",
       "      <td>0.964952</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.937379</td>\n",
       "      <td>0.953363</td>\n",
       "      <td>0.968575</td>\n",
       "      <td>0.982308</td>\n",
       "      <td>0.986486</td>\n",
       "      <td>0.986290</td>\n",
       "      <td>0.994723</td>\n",
       "      <td>0.987531</td>\n",
       "      <td>0.986288</td>\n",
       "      <td>1.000191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20071</th>\n",
       "      <td>6916517859197240320</td>\n",
       "      <td>0.965473</td>\n",
       "      <td>0.982872</td>\n",
       "      <td>0.990037</td>\n",
       "      <td>0.976551</td>\n",
       "      <td>0.944274</td>\n",
       "      <td>0.908453</td>\n",
       "      <td>0.889263</td>\n",
       "      <td>0.902068</td>\n",
       "      <td>0.937744</td>\n",
       "      <td>...</td>\n",
       "      <td>0.990237</td>\n",
       "      <td>0.997536</td>\n",
       "      <td>1.000324</td>\n",
       "      <td>1.000031</td>\n",
       "      <td>0.990184</td>\n",
       "      <td>0.977328</td>\n",
       "      <td>0.974813</td>\n",
       "      <td>0.958878</td>\n",
       "      <td>0.950554</td>\n",
       "      <td>0.958498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20072</th>\n",
       "      <td>6916925361398340096</td>\n",
       "      <td>0.969359</td>\n",
       "      <td>0.985898</td>\n",
       "      <td>1.000018</td>\n",
       "      <td>0.998645</td>\n",
       "      <td>0.979826</td>\n",
       "      <td>0.953819</td>\n",
       "      <td>0.936201</td>\n",
       "      <td>0.940956</td>\n",
       "      <td>0.961661</td>\n",
       "      <td>...</td>\n",
       "      <td>0.988196</td>\n",
       "      <td>0.996699</td>\n",
       "      <td>1.000288</td>\n",
       "      <td>1.000183</td>\n",
       "      <td>0.989802</td>\n",
       "      <td>0.975520</td>\n",
       "      <td>0.970561</td>\n",
       "      <td>0.951265</td>\n",
       "      <td>0.938701</td>\n",
       "      <td>0.941522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20073</th>\n",
       "      <td>6917528512245520000</td>\n",
       "      <td>0.969176</td>\n",
       "      <td>0.994671</td>\n",
       "      <td>1.000002</td>\n",
       "      <td>0.983864</td>\n",
       "      <td>0.954208</td>\n",
       "      <td>0.925391</td>\n",
       "      <td>0.911636</td>\n",
       "      <td>0.923018</td>\n",
       "      <td>0.950192</td>\n",
       "      <td>...</td>\n",
       "      <td>0.988464</td>\n",
       "      <td>0.995897</td>\n",
       "      <td>0.999401</td>\n",
       "      <td>1.000335</td>\n",
       "      <td>0.992307</td>\n",
       "      <td>0.981481</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.965681</td>\n",
       "      <td>0.956774</td>\n",
       "      <td>0.962258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20074 rows × 277 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  GaiaEDR3     400.0     402.0     404.0     406.0     408.0  \\\n",
       "0         1306361548360576  0.853450  0.941675  1.000411  0.988710  0.925614   \n",
       "1         1792620565667968  0.959502  0.996733  1.000108  0.975493  0.947082   \n",
       "2         6052403489630720  0.974929  0.992400  1.000032  0.988859  0.966801   \n",
       "3         6353119919810816  0.928566  0.980801  1.000170  0.977861  0.934958   \n",
       "4        10844075163628928  0.927307  0.984887  1.000189  0.971341  0.927670   \n",
       "...                    ...       ...       ...       ...       ...       ...   \n",
       "20069  6916087950150111232  0.953987  0.982351  0.993574  0.978676  0.942920   \n",
       "20070  6916186184642798848  0.944458  0.990766  1.000156  0.973015  0.936448   \n",
       "20071  6916517859197240320  0.965473  0.982872  0.990037  0.976551  0.944274   \n",
       "20072  6916925361398340096  0.969359  0.985898  1.000018  0.998645  0.979826   \n",
       "20073  6917528512245520000  0.969176  0.994671  1.000002  0.983864  0.954208   \n",
       "\n",
       "          410.0     412.0     414.0     416.0  ...     932.0     934.0  \\\n",
       "0      0.866464  0.855969  0.900321  0.961643  ...  0.993973  0.998679   \n",
       "1      0.936094  0.946869  0.972096  0.992361  ...  0.989064  0.997809   \n",
       "2      0.948620  0.943953  0.955887  0.972213  ...  0.988757  0.997123   \n",
       "3      0.903505  0.902977  0.933175  0.970096  ...  0.988380  0.996614   \n",
       "4      0.903547  0.913471  0.949748  0.984329  ...  0.990076  0.997219   \n",
       "...         ...       ...       ...       ...  ...       ...       ...   \n",
       "20069  0.904479  0.884542  0.897774  0.934133  ...  0.990458  0.997577   \n",
       "20070  0.919586  0.932130  0.964952  0.992000  ...  0.937379  0.953363   \n",
       "20071  0.908453  0.889263  0.902068  0.937744  ...  0.990237  0.997536   \n",
       "20072  0.953819  0.936201  0.940956  0.961661  ...  0.988196  0.996699   \n",
       "20073  0.925391  0.911636  0.923018  0.950192  ...  0.988464  0.995897   \n",
       "\n",
       "          936.0     938.0     940.0     942.0     944.0     946.0     948.0  \\\n",
       "0      1.000135  0.999833  0.991327  0.981020  0.982047  0.970091  0.965854   \n",
       "1      1.000719  0.999373  0.987119  0.970374  0.962181  0.938859  0.921021   \n",
       "2      1.000409  1.000030  0.989502  0.975452  0.971328  0.953621  0.943489   \n",
       "3      1.000155  1.000293  0.990562  0.977249  0.973427  0.955111  0.943117   \n",
       "4      1.000149  1.000254  0.991048  0.978711  0.976138  0.958996  0.947835   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "20069  1.000323  1.000104  0.990335  0.977298  0.974000  0.956321  0.944928   \n",
       "20070  0.968575  0.982308  0.986486  0.986290  0.994723  0.987531  0.986288   \n",
       "20071  1.000324  1.000031  0.990184  0.977328  0.974813  0.958878  0.950554   \n",
       "20072  1.000288  1.000183  0.989802  0.975520  0.970561  0.951265  0.938701   \n",
       "20073  0.999401  1.000335  0.992307  0.981481  0.980769  0.965681  0.956774   \n",
       "\n",
       "          950.0  \n",
       "0      0.977762  \n",
       "1      0.916727  \n",
       "2      0.949665  \n",
       "3      0.945857  \n",
       "4      0.950827  \n",
       "...         ...  \n",
       "20069  0.948095  \n",
       "20070  1.000191  \n",
       "20071  0.958498  \n",
       "20072  0.941522  \n",
       "20073  0.962258  \n",
       "\n",
       "[20074 rows x 277 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"data/XP_spectra_norm.par\"\n",
    "all_fluxes = pd.read_parquet(filepath)\n",
    "print(filepath)\n",
    "\n",
    "# Extract names of wavelength columns and the wavelength values\n",
    "column_names = all_fluxes.columns.values\n",
    "wvl_columns = column_names[1:]\n",
    "wvl_values = wvl_columns.astype(\"float64\")\n",
    "\n",
    "all_fluxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67f0892-a784-446c-b08f-d58b5bb4e55a",
   "metadata": {},
   "source": [
    "#### Keep only sources that are in \"data\" and add labels to fluxes data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84dc6695-2597-4fbd-ac63-78fe1daf80c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GaiaEDR3</th>\n",
       "      <th>Teff</th>\n",
       "      <th>logY</th>\n",
       "      <th>label</th>\n",
       "      <th>400.0</th>\n",
       "      <th>402.0</th>\n",
       "      <th>404.0</th>\n",
       "      <th>406.0</th>\n",
       "      <th>408.0</th>\n",
       "      <th>410.0</th>\n",
       "      <th>...</th>\n",
       "      <th>932.0</th>\n",
       "      <th>934.0</th>\n",
       "      <th>936.0</th>\n",
       "      <th>938.0</th>\n",
       "      <th>940.0</th>\n",
       "      <th>942.0</th>\n",
       "      <th>944.0</th>\n",
       "      <th>946.0</th>\n",
       "      <th>948.0</th>\n",
       "      <th>950.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6052403489630720</td>\n",
       "      <td>36414.0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0</td>\n",
       "      <td>0.974929</td>\n",
       "      <td>0.992400</td>\n",
       "      <td>1.000032</td>\n",
       "      <td>0.988859</td>\n",
       "      <td>0.966801</td>\n",
       "      <td>0.948620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.988757</td>\n",
       "      <td>0.997123</td>\n",
       "      <td>1.000409</td>\n",
       "      <td>1.000030</td>\n",
       "      <td>0.989502</td>\n",
       "      <td>0.975452</td>\n",
       "      <td>0.971328</td>\n",
       "      <td>0.953621</td>\n",
       "      <td>0.943489</td>\n",
       "      <td>0.949665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11015044926034816</td>\n",
       "      <td>33853.0</td>\n",
       "      <td>-1.85</td>\n",
       "      <td>1</td>\n",
       "      <td>0.951933</td>\n",
       "      <td>0.991996</td>\n",
       "      <td>1.000114</td>\n",
       "      <td>0.977713</td>\n",
       "      <td>0.945763</td>\n",
       "      <td>0.927086</td>\n",
       "      <td>...</td>\n",
       "      <td>0.990638</td>\n",
       "      <td>0.997393</td>\n",
       "      <td>1.000133</td>\n",
       "      <td>1.000203</td>\n",
       "      <td>0.991118</td>\n",
       "      <td>0.979140</td>\n",
       "      <td>0.977299</td>\n",
       "      <td>0.961396</td>\n",
       "      <td>0.952156</td>\n",
       "      <td>0.957959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11963171843658240</td>\n",
       "      <td>41361.0</td>\n",
       "      <td>-2.85</td>\n",
       "      <td>0</td>\n",
       "      <td>0.952121</td>\n",
       "      <td>0.993361</td>\n",
       "      <td>1.000120</td>\n",
       "      <td>0.976296</td>\n",
       "      <td>0.944764</td>\n",
       "      <td>0.927838</td>\n",
       "      <td>...</td>\n",
       "      <td>0.990996</td>\n",
       "      <td>0.997503</td>\n",
       "      <td>1.000115</td>\n",
       "      <td>1.000291</td>\n",
       "      <td>0.991548</td>\n",
       "      <td>0.979929</td>\n",
       "      <td>0.978120</td>\n",
       "      <td>0.961453</td>\n",
       "      <td>0.950203</td>\n",
       "      <td>0.952289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13746369248366848</td>\n",
       "      <td>34920.0</td>\n",
       "      <td>-1.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.930601</td>\n",
       "      <td>0.981438</td>\n",
       "      <td>1.000138</td>\n",
       "      <td>0.980689</td>\n",
       "      <td>0.942526</td>\n",
       "      <td>0.913726</td>\n",
       "      <td>...</td>\n",
       "      <td>0.990885</td>\n",
       "      <td>0.997216</td>\n",
       "      <td>0.999882</td>\n",
       "      <td>1.000337</td>\n",
       "      <td>0.992174</td>\n",
       "      <td>0.981427</td>\n",
       "      <td>0.980783</td>\n",
       "      <td>0.965463</td>\n",
       "      <td>0.955725</td>\n",
       "      <td>0.959497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16615171179593088</td>\n",
       "      <td>26600.0</td>\n",
       "      <td>-2.70</td>\n",
       "      <td>1</td>\n",
       "      <td>0.912644</td>\n",
       "      <td>0.977184</td>\n",
       "      <td>1.000207</td>\n",
       "      <td>0.974613</td>\n",
       "      <td>0.927038</td>\n",
       "      <td>0.893910</td>\n",
       "      <td>...</td>\n",
       "      <td>0.991340</td>\n",
       "      <td>0.997474</td>\n",
       "      <td>1.000002</td>\n",
       "      <td>1.000332</td>\n",
       "      <td>0.992019</td>\n",
       "      <td>0.981085</td>\n",
       "      <td>0.980231</td>\n",
       "      <td>0.964736</td>\n",
       "      <td>0.954927</td>\n",
       "      <td>0.958814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>6899029954958005248</td>\n",
       "      <td>31152.0</td>\n",
       "      <td>-1.60</td>\n",
       "      <td>1</td>\n",
       "      <td>0.879913</td>\n",
       "      <td>0.957781</td>\n",
       "      <td>1.000319</td>\n",
       "      <td>0.981732</td>\n",
       "      <td>0.924425</td>\n",
       "      <td>0.875732</td>\n",
       "      <td>...</td>\n",
       "      <td>0.990980</td>\n",
       "      <td>0.997810</td>\n",
       "      <td>1.000366</td>\n",
       "      <td>1.000053</td>\n",
       "      <td>0.990231</td>\n",
       "      <td>0.977171</td>\n",
       "      <td>0.973876</td>\n",
       "      <td>0.956228</td>\n",
       "      <td>0.944905</td>\n",
       "      <td>0.948200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>6906152621346929280</td>\n",
       "      <td>59920.0</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0</td>\n",
       "      <td>0.985627</td>\n",
       "      <td>0.993220</td>\n",
       "      <td>0.989310</td>\n",
       "      <td>0.986599</td>\n",
       "      <td>0.991641</td>\n",
       "      <td>0.999527</td>\n",
       "      <td>...</td>\n",
       "      <td>0.989498</td>\n",
       "      <td>0.997262</td>\n",
       "      <td>1.000301</td>\n",
       "      <td>1.000086</td>\n",
       "      <td>0.990227</td>\n",
       "      <td>0.977309</td>\n",
       "      <td>0.974709</td>\n",
       "      <td>0.958677</td>\n",
       "      <td>0.950231</td>\n",
       "      <td>0.957990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>6913349543425935232</td>\n",
       "      <td>35133.0</td>\n",
       "      <td>-1.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.887790</td>\n",
       "      <td>0.960442</td>\n",
       "      <td>1.000335</td>\n",
       "      <td>0.982264</td>\n",
       "      <td>0.927924</td>\n",
       "      <td>0.882868</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992510</td>\n",
       "      <td>0.999310</td>\n",
       "      <td>1.000636</td>\n",
       "      <td>0.997920</td>\n",
       "      <td>0.984483</td>\n",
       "      <td>0.966772</td>\n",
       "      <td>0.957909</td>\n",
       "      <td>0.934546</td>\n",
       "      <td>0.917514</td>\n",
       "      <td>0.915180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>6913373354725177472</td>\n",
       "      <td>33550.0</td>\n",
       "      <td>-1.80</td>\n",
       "      <td>1</td>\n",
       "      <td>0.958093</td>\n",
       "      <td>0.995355</td>\n",
       "      <td>1.000104</td>\n",
       "      <td>0.976282</td>\n",
       "      <td>0.947096</td>\n",
       "      <td>0.934684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.996799</td>\n",
       "      <td>1.000274</td>\n",
       "      <td>1.000166</td>\n",
       "      <td>0.989917</td>\n",
       "      <td>0.975943</td>\n",
       "      <td>0.971515</td>\n",
       "      <td>0.952981</td>\n",
       "      <td>0.941437</td>\n",
       "      <td>0.945571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>6914322576858227968</td>\n",
       "      <td>31600.0</td>\n",
       "      <td>-3.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.906938</td>\n",
       "      <td>0.963490</td>\n",
       "      <td>1.000320</td>\n",
       "      <td>0.994020</td>\n",
       "      <td>0.952110</td>\n",
       "      <td>0.904673</td>\n",
       "      <td>...</td>\n",
       "      <td>0.988950</td>\n",
       "      <td>0.997073</td>\n",
       "      <td>1.000291</td>\n",
       "      <td>1.000060</td>\n",
       "      <td>0.990066</td>\n",
       "      <td>0.977080</td>\n",
       "      <td>0.974732</td>\n",
       "      <td>0.959569</td>\n",
       "      <td>0.952894</td>\n",
       "      <td>0.963624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1991 rows × 280 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 GaiaEDR3     Teff  logY  label     400.0     402.0     404.0  \\\n",
       "0        6052403489630720  36414.0  0.38      0  0.974929  0.992400  1.000032   \n",
       "1       11015044926034816  33853.0 -1.85      1  0.951933  0.991996  1.000114   \n",
       "2       11963171843658240  41361.0 -2.85      0  0.952121  0.993361  1.000120   \n",
       "3       13746369248366848  34920.0 -1.65      1  0.930601  0.981438  1.000138   \n",
       "4       16615171179593088  26600.0 -2.70      1  0.912644  0.977184  1.000207   \n",
       "...                   ...      ...   ...    ...       ...       ...       ...   \n",
       "1986  6899029954958005248  31152.0 -1.60      1  0.879913  0.957781  1.000319   \n",
       "1987  6906152621346929280  59920.0  0.39      0  0.985627  0.993220  0.989310   \n",
       "1988  6913349543425935232  35133.0 -1.40      0  0.887790  0.960442  1.000335   \n",
       "1989  6913373354725177472  33550.0 -1.80      1  0.958093  0.995355  1.000104   \n",
       "1990  6914322576858227968  31600.0 -3.00      1  0.906938  0.963490  1.000320   \n",
       "\n",
       "         406.0     408.0     410.0  ...     932.0     934.0     936.0  \\\n",
       "0     0.988859  0.966801  0.948620  ...  0.988757  0.997123  1.000409   \n",
       "1     0.977713  0.945763  0.927086  ...  0.990638  0.997393  1.000133   \n",
       "2     0.976296  0.944764  0.927838  ...  0.990996  0.997503  1.000115   \n",
       "3     0.980689  0.942526  0.913726  ...  0.990885  0.997216  0.999882   \n",
       "4     0.974613  0.927038  0.893910  ...  0.991340  0.997474  1.000002   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1986  0.981732  0.924425  0.875732  ...  0.990980  0.997810  1.000366   \n",
       "1987  0.986599  0.991641  0.999527  ...  0.989498  0.997262  1.000301   \n",
       "1988  0.982264  0.927924  0.882868  ...  0.992510  0.999310  1.000636   \n",
       "1989  0.976282  0.947096  0.934684  ...  0.988506  0.996799  1.000274   \n",
       "1990  0.994020  0.952110  0.904673  ...  0.988950  0.997073  1.000291   \n",
       "\n",
       "         938.0     940.0     942.0     944.0     946.0     948.0     950.0  \n",
       "0     1.000030  0.989502  0.975452  0.971328  0.953621  0.943489  0.949665  \n",
       "1     1.000203  0.991118  0.979140  0.977299  0.961396  0.952156  0.957959  \n",
       "2     1.000291  0.991548  0.979929  0.978120  0.961453  0.950203  0.952289  \n",
       "3     1.000337  0.992174  0.981427  0.980783  0.965463  0.955725  0.959497  \n",
       "4     1.000332  0.992019  0.981085  0.980231  0.964736  0.954927  0.958814  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1986  1.000053  0.990231  0.977171  0.973876  0.956228  0.944905  0.948200  \n",
       "1987  1.000086  0.990227  0.977309  0.974709  0.958677  0.950231  0.957990  \n",
       "1988  0.997920  0.984483  0.966772  0.957909  0.934546  0.917514  0.915180  \n",
       "1989  1.000166  0.989917  0.975943  0.971515  0.952981  0.941437  0.945571  \n",
       "1990  1.000060  0.990066  0.977080  0.974732  0.959569  0.952894  0.963624  \n",
       "\n",
       "[1991 rows x 280 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge \"data\" and \"all_fluxes\" DataFrames on the \"GaiaEDR3\" column\n",
    "fluxes = pd.merge(data, all_fluxes, on=\"GaiaEDR3\")\n",
    "\n",
    "# Display the merged DataFrame\n",
    "fluxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fd6ccf-e61a-4073-bf9b-b57ff8f357af",
   "metadata": {},
   "source": [
    "#### Plot classes in Teff-logY diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "195c260f-e0aa-4529-b782-08ffec80ca9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Training + test data\")\n",
    "\n",
    "plt.scatter(fluxes[fluxes[\"label\"] == 0][\"Teff\"],\n",
    "            fluxes[fluxes[\"label\"] == 0][\"logY\"],\n",
    "            s=10, color=\"#a6cee3\", label=\"hot/He-rich\")\n",
    "\n",
    "plt.scatter(fluxes[fluxes[\"label\"] == 1][\"Teff\"],\n",
    "            fluxes[fluxes[\"label\"] == 1][\"logY\"],\n",
    "            s=10, color=\"#fb8072\", label=\"sdB\")\n",
    "\n",
    "plt.plot([theshold_Teff, theshold_Teff], [-6, threshold_logY], color=\"black\", linestyle=\"--\")\n",
    "plt.plot([theshold_Teff, 0], [threshold_logY, threshold_logY], color=\"black\", linestyle=\"--\")\n",
    "\n",
    "plt.xlabel(\"Teff (K)\")\n",
    "plt.ylabel(\"logY\")\n",
    "\n",
    "plt.xlim(15000, 150000)\n",
    "plt.ylim(-5.5, 3.5)\n",
    "\n",
    "\n",
    "plt.xlabel(\"Teff (K)\")\n",
    "plt.ylabel(\"logY\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6084fe4-be6d-49a0-8180-d1a3fc54a3ad",
   "metadata": {},
   "source": [
    "### Define training, validation, and test sets for CNN training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "428118b6-83ad-4fc5-a169-aba77a0080bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_test_set(fluxes, n_test):\n",
    "    \"\"\"\n",
    "    Randomly splits the input DataFrame into a test set and a remaining set.\n",
    "\n",
    "    Parameters:\n",
    "        fluxes (pd.DataFrame): The full dataset containing a 'GaiaEDR3' column.\n",
    "        n_test (int): Number of samples to include in the test set.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (fluxes_test, fluxes_train_val)\n",
    "            - fluxes_test: Randomly selected test samples.\n",
    "            - fluxes_train_val: Remaining samples not in the test set.\n",
    "    \"\"\"\n",
    "    # Randomly select N_test rows for the test set\n",
    "    fluxes_test = fluxes.sample(n_test, ignore_index=True)\n",
    "\n",
    "    # Exclude test set rows from the original DataFrame\n",
    "    fluxes_train_val = fluxes[~fluxes[\"GaiaEDR3\"].isin(fluxes_test[\"GaiaEDR3\"])]\n",
    "\n",
    "    return fluxes_test, fluxes_train_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e1f753c-3ecd-4be8-951e-960a06028646",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_val(fluxes, n_val):\n",
    "    \"\"\"\n",
    "    Splits the input DataFrame into a validation set and a training set.\n",
    "\n",
    "    Parameters:\n",
    "        fluxes (pd.DataFrame): The dataset to split, containing 'GaiaEDR3' column.\n",
    "        n_val (int): Number of samples to include in the validation set.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (fluxes_train, fluxes_val)\n",
    "            - fluxes_train: Remaining samples after validation selection.\n",
    "            - fluxes_val: Randomly selected validation samples.\n",
    "    \"\"\"\n",
    "    # Randomly select N_val rows for the validation set\n",
    "    fluxes_val = fluxes.sample(n_val, ignore_index=True)\n",
    "\n",
    "    # Remaining samples form the training set\n",
    "    fluxes_train = fluxes[~fluxes[\"GaiaEDR3\"].isin(fluxes_val[\"GaiaEDR3\"])]\n",
    "    fluxes_train = fluxes_train.reset_index(drop=True)\n",
    "\n",
    "    return fluxes_train, fluxes_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46133a7e-63ed-4c9d-97f0-7ac5c68ef600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 1476\n",
      "683 hot/rich\n",
      "793 sdB (54%)\n",
      "\n",
      "val set: 250\n",
      "113 hot/rich\n",
      "137 sdB (55%)\n",
      "\n",
      "test set: 250\n",
      "112 hot/rich\n",
      "138 sdB (55%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define test and validation set sizes\n",
    "n_test = 250\n",
    "n_val = 250\n",
    "\n",
    "# Split the dataset\n",
    "fluxes_test, fluxes_train_val = pick_test_set(fluxes, n_test)\n",
    "fluxes_train, fluxes_val = make_train_val(fluxes_train_val, n_val)\n",
    "\n",
    "# Training set summary\n",
    "print(f\"Training set: {len(fluxes_train)}\")\n",
    "n_sdb_train = (fluxes_train[\"label\"] == 1).sum()\n",
    "n_hotrich_train = (fluxes_train[\"label\"] == 0).sum()\n",
    "print(f\"{n_hotrich_train} hot/rich\")\n",
    "print(f\"{n_sdb_train} sdB ({n_sdb_train / len(fluxes_train) * 100:.0f}%)\\n\")\n",
    "\n",
    "# Validation set summary\n",
    "print(f\"val set: {len(fluxes_val)}\")\n",
    "n_sdb_val = (fluxes_val[\"label\"] == 1).sum()\n",
    "n_hotrich_val = (fluxes_val[\"label\"] == 0).sum()\n",
    "print(f\"{n_hotrich_val} hot/rich\")\n",
    "print(f\"{n_sdb_val} sdB ({n_sdb_val / len(fluxes_val) * 100:.0f}%)\\n\")\n",
    "\n",
    "# Test set summary\n",
    "print(f\"test set: {len(fluxes_test)}\")\n",
    "n_sdb_test = (fluxes_test[\"label\"] == 1).sum()\n",
    "n_hotrich_test = (fluxes_test[\"label\"] == 0).sum()\n",
    "print(f\"{n_hotrich_test} hot/rich\")\n",
    "print(f\"{n_sdb_test} sdB ({n_sdb_test / len(fluxes_test) * 100:.0f}%)\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330e0dff-346a-4efd-9c03-0ae9318e2816",
   "metadata": {},
   "source": [
    "### Build CNN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51a8f7aa-342e-40c3-bbd7-88865948a1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    \"\"\"\n",
    "    Builds and returns a 1D CNN model for sdB classification of flux spectra.\n",
    "    \"\"\"\n",
    "    model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Input(shape=(fluxes[wvl_columns].shape[1], 1)),\n",
    "    \n",
    "            tf.keras.layers.Conv1D(filters=16, kernel_size=5),\n",
    "            tf.keras.layers.LeakyReLU(),\n",
    "    \n",
    "            tf.keras.layers.Conv1D(filters=16, kernel_size=5),\n",
    "            tf.keras.layers.LeakyReLU(),\n",
    "    \n",
    "            tf.keras.layers.Conv1D(filters=16, kernel_size=5),\n",
    "            tf.keras.layers.LeakyReLU(),\n",
    "    \n",
    "            tf.keras.layers.Flatten(),\n",
    "    \n",
    "            tf.keras.layers.Dense(128),\n",
    "            tf.keras.layers.LeakyReLU(),\n",
    "            tf.keras.layers.Dense(256),\n",
    "            tf.keras.layers.LeakyReLU(),\n",
    "            tf.keras.layers.Dense(64),\n",
    "            tf.keras.layers.LeakyReLU(),\n",
    "            tf.keras.layers.Dense(32),\n",
    "            tf.keras.layers.LeakyReLU(),\n",
    "            tf.keras.layers.Dense(16),\n",
    "            tf.keras.layers.LeakyReLU(),\n",
    "            tf.keras.layers.Dense(8),\n",
    "            tf.keras.layers.LeakyReLU(),\n",
    "            tf.keras.layers.Dense(4),\n",
    "            tf.keras.layers.LeakyReLU(),\n",
    "    \n",
    "            tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1299fdb5-5d85-4a7c-90dc-9bcbd5a94d3b",
   "metadata": {},
   "source": [
    "### Training of CNN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a8c3529-ade8-49e9-9caa-0316f50277b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 14:23:15.912065: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 - 2s - 46ms/step - binary_accuracy: 0.5341 - loss: 0.6918 - val_binary_accuracy: 0.5720 - val_loss: 0.6866\n",
      "Epoch 2/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.5341 - loss: 0.6911 - val_binary_accuracy: 0.5720 - val_loss: 0.6840\n",
      "Epoch 3/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.5341 - loss: 0.6922 - val_binary_accuracy: 0.5720 - val_loss: 0.6833\n",
      "Epoch 4/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.5341 - loss: 0.6915 - val_binary_accuracy: 0.5720 - val_loss: 0.6890\n",
      "Epoch 5/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.5341 - loss: 0.6910 - val_binary_accuracy: 0.5720 - val_loss: 0.6863\n",
      "Epoch 6/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.5341 - loss: 0.6902 - val_binary_accuracy: 0.5720 - val_loss: 0.6837\n",
      "Epoch 7/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.5341 - loss: 0.6890 - val_binary_accuracy: 0.5720 - val_loss: 0.6820\n",
      "Epoch 8/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.5341 - loss: 0.6863 - val_binary_accuracy: 0.5720 - val_loss: 0.6740\n",
      "Epoch 9/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.5409 - loss: 0.6721 - val_binary_accuracy: 0.7440 - val_loss: 0.6534\n",
      "Epoch 10/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.6802 - loss: 0.6159 - val_binary_accuracy: 0.8200 - val_loss: 0.5348\n",
      "Epoch 11/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.7958 - loss: 0.4858 - val_binary_accuracy: 0.8400 - val_loss: 0.4217\n",
      "Epoch 12/10000\n",
      "47/47 - 0s - 10ms/step - binary_accuracy: 0.8154 - loss: 0.4270 - val_binary_accuracy: 0.8520 - val_loss: 0.3568\n",
      "Epoch 13/10000\n",
      "47/47 - 1s - 13ms/step - binary_accuracy: 0.8364 - loss: 0.3865 - val_binary_accuracy: 0.8600 - val_loss: 0.3547\n",
      "Epoch 14/10000\n",
      "47/47 - 0s - 10ms/step - binary_accuracy: 0.8465 - loss: 0.3524 - val_binary_accuracy: 0.8560 - val_loss: 0.3250\n",
      "Epoch 15/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8600 - loss: 0.3347 - val_binary_accuracy: 0.8120 - val_loss: 0.3900\n",
      "Epoch 16/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8485 - loss: 0.3506 - val_binary_accuracy: 0.8720 - val_loss: 0.3162\n",
      "Epoch 17/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8594 - loss: 0.3465 - val_binary_accuracy: 0.8000 - val_loss: 0.4101\n",
      "Epoch 18/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8499 - loss: 0.3498 - val_binary_accuracy: 0.8080 - val_loss: 0.3972\n",
      "Epoch 19/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8519 - loss: 0.3393 - val_binary_accuracy: 0.8680 - val_loss: 0.3179\n",
      "Epoch 20/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8607 - loss: 0.3312 - val_binary_accuracy: 0.8680 - val_loss: 0.3144\n",
      "Epoch 21/10000\n",
      "47/47 - 0s - 10ms/step - binary_accuracy: 0.8648 - loss: 0.3272 - val_binary_accuracy: 0.8720 - val_loss: 0.3127\n",
      "Epoch 22/10000\n",
      "47/47 - 1s - 13ms/step - binary_accuracy: 0.8722 - loss: 0.3224 - val_binary_accuracy: 0.8480 - val_loss: 0.3337\n",
      "Epoch 23/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8594 - loss: 0.3289 - val_binary_accuracy: 0.8680 - val_loss: 0.3166\n",
      "Epoch 24/10000\n",
      "47/47 - 1s - 13ms/step - binary_accuracy: 0.8607 - loss: 0.3259 - val_binary_accuracy: 0.8520 - val_loss: 0.3298\n",
      "Epoch 25/10000\n",
      "47/47 - 1s - 13ms/step - binary_accuracy: 0.8472 - loss: 0.3513 - val_binary_accuracy: 0.8680 - val_loss: 0.3205\n",
      "Epoch 26/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8682 - loss: 0.3225 - val_binary_accuracy: 0.8720 - val_loss: 0.3195\n",
      "Epoch 27/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8627 - loss: 0.3248 - val_binary_accuracy: 0.8560 - val_loss: 0.3404\n",
      "Epoch 28/10000\n",
      "47/47 - 1s - 13ms/step - binary_accuracy: 0.8499 - loss: 0.3408 - val_binary_accuracy: 0.8680 - val_loss: 0.3160\n",
      "Epoch 29/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8709 - loss: 0.3221 - val_binary_accuracy: 0.8440 - val_loss: 0.3543\n",
      "Epoch 30/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8722 - loss: 0.3221 - val_binary_accuracy: 0.8520 - val_loss: 0.3256\n",
      "Epoch 31/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8702 - loss: 0.3158 - val_binary_accuracy: 0.8520 - val_loss: 0.3372\n",
      "Epoch 32/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8742 - loss: 0.3177 - val_binary_accuracy: 0.8680 - val_loss: 0.3124\n",
      "Epoch 33/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8695 - loss: 0.3156 - val_binary_accuracy: 0.8680 - val_loss: 0.3150\n",
      "Epoch 34/10000\n",
      "47/47 - 1s - 13ms/step - binary_accuracy: 0.8587 - loss: 0.3375 - val_binary_accuracy: 0.8600 - val_loss: 0.3335\n",
      "Epoch 35/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8654 - loss: 0.3146 - val_binary_accuracy: 0.8720 - val_loss: 0.3196\n",
      "Epoch 36/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8634 - loss: 0.3156 - val_binary_accuracy: 0.8680 - val_loss: 0.3168\n",
      "Epoch 37/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8702 - loss: 0.3147 - val_binary_accuracy: 0.8640 - val_loss: 0.3213\n",
      "Epoch 38/10000\n",
      "47/47 - 1s - 14ms/step - binary_accuracy: 0.8736 - loss: 0.3178 - val_binary_accuracy: 0.8480 - val_loss: 0.3442\n",
      "Epoch 39/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8600 - loss: 0.3214 - val_binary_accuracy: 0.8480 - val_loss: 0.3374\n",
      "Epoch 40/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8668 - loss: 0.3264 - val_binary_accuracy: 0.8520 - val_loss: 0.3259\n",
      "Epoch 41/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8688 - loss: 0.3210 - val_binary_accuracy: 0.8680 - val_loss: 0.3151\n",
      "Epoch 42/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8682 - loss: 0.3146 - val_binary_accuracy: 0.8560 - val_loss: 0.3270\n",
      "Epoch 43/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8729 - loss: 0.3091 - val_binary_accuracy: 0.8600 - val_loss: 0.3159\n",
      "Epoch 44/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8688 - loss: 0.3098 - val_binary_accuracy: 0.8560 - val_loss: 0.3159\n",
      "Epoch 45/10000\n",
      "47/47 - 1s - 11ms/step - binary_accuracy: 0.8682 - loss: 0.3113 - val_binary_accuracy: 0.8720 - val_loss: 0.3197\n",
      "Epoch 46/10000\n",
      "47/47 - 1s - 12ms/step - binary_accuracy: 0.8641 - loss: 0.3218 - val_binary_accuracy: 0.8520 - val_loss: 0.3328\n",
      "Epoch 47/10000\n",
      "47/47 - 1s - 14ms/step - binary_accuracy: 0.8634 - loss: 0.3189 - val_binary_accuracy: 0.8600 - val_loss: 0.3248\n",
      "Epoch 48/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8756 - loss: 0.3168 - val_binary_accuracy: 0.8480 - val_loss: 0.3379\n",
      "Epoch 49/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8722 - loss: 0.3074 - val_binary_accuracy: 0.8720 - val_loss: 0.3195\n",
      "Epoch 50/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8803 - loss: 0.3063 - val_binary_accuracy: 0.8760 - val_loss: 0.3152\n",
      "Epoch 51/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8756 - loss: 0.3041 - val_binary_accuracy: 0.8720 - val_loss: 0.3177\n",
      "Epoch 52/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8641 - loss: 0.3312 - val_binary_accuracy: 0.8480 - val_loss: 0.3447\n",
      "Epoch 53/10000\n",
      "47/47 - 1s - 13ms/step - binary_accuracy: 0.8729 - loss: 0.3050 - val_binary_accuracy: 0.8720 - val_loss: 0.3168\n",
      "Epoch 54/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8648 - loss: 0.3079 - val_binary_accuracy: 0.8480 - val_loss: 0.3391\n",
      "Epoch 55/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8736 - loss: 0.3047 - val_binary_accuracy: 0.8560 - val_loss: 0.3265\n",
      "Epoch 56/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8661 - loss: 0.3080 - val_binary_accuracy: 0.8520 - val_loss: 0.3318\n",
      "Epoch 57/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8736 - loss: 0.3057 - val_binary_accuracy: 0.8560 - val_loss: 0.3287\n",
      "Epoch 58/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8600 - loss: 0.3227 - val_binary_accuracy: 0.8720 - val_loss: 0.3160\n",
      "Epoch 59/10000\n",
      "47/47 - 1s - 13ms/step - binary_accuracy: 0.8763 - loss: 0.3050 - val_binary_accuracy: 0.8640 - val_loss: 0.3157\n",
      "Epoch 60/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8756 - loss: 0.2988 - val_binary_accuracy: 0.8600 - val_loss: 0.3252\n",
      "Epoch 61/10000\n",
      "47/47 - 1s - 13ms/step - binary_accuracy: 0.8776 - loss: 0.3040 - val_binary_accuracy: 0.8560 - val_loss: 0.3260\n",
      "Epoch 62/10000\n",
      "47/47 - 1s - 13ms/step - binary_accuracy: 0.8709 - loss: 0.3083 - val_binary_accuracy: 0.8560 - val_loss: 0.3363\n",
      "Epoch 63/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8763 - loss: 0.3033 - val_binary_accuracy: 0.8600 - val_loss: 0.3211\n",
      "Epoch 64/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8756 - loss: 0.2980 - val_binary_accuracy: 0.8600 - val_loss: 0.3182\n",
      "Epoch 65/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8654 - loss: 0.3125 - val_binary_accuracy: 0.8560 - val_loss: 0.3394\n",
      "Epoch 66/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8736 - loss: 0.3072 - val_binary_accuracy: 0.8680 - val_loss: 0.3239\n",
      "Epoch 67/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8702 - loss: 0.3003 - val_binary_accuracy: 0.8280 - val_loss: 0.3841\n",
      "Epoch 68/10000\n",
      "47/47 - 1s - 14ms/step - binary_accuracy: 0.8756 - loss: 0.3038 - val_binary_accuracy: 0.8520 - val_loss: 0.3270\n",
      "Epoch 69/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8756 - loss: 0.2921 - val_binary_accuracy: 0.8720 - val_loss: 0.3245\n",
      "Epoch 70/10000\n",
      "47/47 - 1s - 13ms/step - binary_accuracy: 0.8763 - loss: 0.2974 - val_binary_accuracy: 0.8680 - val_loss: 0.3180\n",
      "Epoch 71/10000\n",
      "47/47 - 1s - 14ms/step - binary_accuracy: 0.8729 - loss: 0.3041 - val_binary_accuracy: 0.8640 - val_loss: 0.3181\n",
      "Epoch 72/10000\n",
      "47/47 - 1s - 13ms/step - binary_accuracy: 0.8736 - loss: 0.2988 - val_binary_accuracy: 0.8640 - val_loss: 0.3471\n",
      "Epoch 73/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8715 - loss: 0.3077 - val_binary_accuracy: 0.8600 - val_loss: 0.3330\n",
      "Epoch 74/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8756 - loss: 0.2975 - val_binary_accuracy: 0.8600 - val_loss: 0.3197\n",
      "Epoch 75/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8783 - loss: 0.2920 - val_binary_accuracy: 0.8680 - val_loss: 0.3168\n",
      "Epoch 76/10000\n",
      "47/47 - 1s - 13ms/step - binary_accuracy: 0.8790 - loss: 0.2934 - val_binary_accuracy: 0.8440 - val_loss: 0.3481\n",
      "Epoch 77/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8810 - loss: 0.2918 - val_binary_accuracy: 0.8640 - val_loss: 0.3187\n",
      "Epoch 78/10000\n",
      "47/47 - 1s - 13ms/step - binary_accuracy: 0.8709 - loss: 0.2881 - val_binary_accuracy: 0.8760 - val_loss: 0.3194\n",
      "Epoch 79/10000\n",
      "47/47 - 1s - 13ms/step - binary_accuracy: 0.8790 - loss: 0.2936 - val_binary_accuracy: 0.8600 - val_loss: 0.3180\n",
      "Epoch 80/10000\n",
      "47/47 - 1s - 13ms/step - binary_accuracy: 0.8824 - loss: 0.2938 - val_binary_accuracy: 0.8640 - val_loss: 0.3341\n",
      "Epoch 81/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8729 - loss: 0.2999 - val_binary_accuracy: 0.8560 - val_loss: 0.3466\n",
      "Epoch 82/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8776 - loss: 0.2882 - val_binary_accuracy: 0.8680 - val_loss: 0.3340\n",
      "Epoch 83/10000\n",
      "47/47 - 1s - 13ms/step - binary_accuracy: 0.8763 - loss: 0.2959 - val_binary_accuracy: 0.8560 - val_loss: 0.3306\n",
      "Epoch 84/10000\n",
      "47/47 - 1s - 13ms/step - binary_accuracy: 0.8824 - loss: 0.2846 - val_binary_accuracy: 0.8600 - val_loss: 0.3220\n",
      "Epoch 85/10000\n",
      "47/47 - 1s - 15ms/step - binary_accuracy: 0.8851 - loss: 0.2801 - val_binary_accuracy: 0.8600 - val_loss: 0.3220\n",
      "Epoch 86/10000\n",
      "47/47 - 1s - 12ms/step - binary_accuracy: 0.8844 - loss: 0.2884 - val_binary_accuracy: 0.8560 - val_loss: 0.3247\n",
      "Epoch 87/10000\n",
      "47/47 - 1s - 13ms/step - binary_accuracy: 0.8790 - loss: 0.2878 - val_binary_accuracy: 0.8600 - val_loss: 0.3478\n",
      "Epoch 88/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8796 - loss: 0.2952 - val_binary_accuracy: 0.8600 - val_loss: 0.3224\n",
      "Epoch 89/10000\n",
      "47/47 - 1s - 18ms/step - binary_accuracy: 0.8729 - loss: 0.2895 - val_binary_accuracy: 0.8680 - val_loss: 0.3250\n",
      "Epoch 90/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8830 - loss: 0.2903 - val_binary_accuracy: 0.8560 - val_loss: 0.3284\n",
      "Epoch 91/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8715 - loss: 0.2992 - val_binary_accuracy: 0.8560 - val_loss: 0.3259\n",
      "Epoch 92/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8851 - loss: 0.2768 - val_binary_accuracy: 0.8640 - val_loss: 0.3215\n",
      "Epoch 93/10000\n",
      "47/47 - 1s - 15ms/step - binary_accuracy: 0.8864 - loss: 0.2778 - val_binary_accuracy: 0.8520 - val_loss: 0.3240\n",
      "Epoch 94/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8790 - loss: 0.2842 - val_binary_accuracy: 0.8600 - val_loss: 0.3206\n",
      "Epoch 95/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8790 - loss: 0.2835 - val_binary_accuracy: 0.8600 - val_loss: 0.3271\n",
      "Epoch 96/10000\n",
      "47/47 - 0s - 10ms/step - binary_accuracy: 0.8884 - loss: 0.2818 - val_binary_accuracy: 0.8640 - val_loss: 0.3225\n",
      "Epoch 97/10000\n",
      "47/47 - 0s - 10ms/step - binary_accuracy: 0.8891 - loss: 0.2807 - val_binary_accuracy: 0.8640 - val_loss: 0.3211\n",
      "Epoch 98/10000\n",
      "47/47 - 0s - 10ms/step - binary_accuracy: 0.8905 - loss: 0.2727 - val_binary_accuracy: 0.8640 - val_loss: 0.3247\n",
      "Epoch 99/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8851 - loss: 0.2714 - val_binary_accuracy: 0.8440 - val_loss: 0.3759\n",
      "Epoch 100/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8830 - loss: 0.2764 - val_binary_accuracy: 0.8600 - val_loss: 0.3274\n",
      "Epoch 101/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8837 - loss: 0.2738 - val_binary_accuracy: 0.8640 - val_loss: 0.3227\n",
      "Epoch 102/10000\n",
      "47/47 - 0s - 6ms/step - binary_accuracy: 0.8891 - loss: 0.2756 - val_binary_accuracy: 0.8520 - val_loss: 0.3315\n",
      "Epoch 103/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8824 - loss: 0.2775 - val_binary_accuracy: 0.8640 - val_loss: 0.3388\n",
      "Epoch 104/10000\n",
      "47/47 - 1s - 14ms/step - binary_accuracy: 0.8911 - loss: 0.2741 - val_binary_accuracy: 0.8480 - val_loss: 0.3523\n",
      "Epoch 105/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8857 - loss: 0.2690 - val_binary_accuracy: 0.8640 - val_loss: 0.3239\n",
      "Epoch 106/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8830 - loss: 0.2706 - val_binary_accuracy: 0.8600 - val_loss: 0.3289\n",
      "Epoch 107/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8837 - loss: 0.2727 - val_binary_accuracy: 0.8280 - val_loss: 0.4148\n",
      "Epoch 108/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8763 - loss: 0.2898 - val_binary_accuracy: 0.8240 - val_loss: 0.4246\n",
      "Epoch 109/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8783 - loss: 0.2955 - val_binary_accuracy: 0.8560 - val_loss: 0.3169\n",
      "Epoch 110/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8878 - loss: 0.2684 - val_binary_accuracy: 0.8560 - val_loss: 0.3222\n",
      "Epoch 111/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8871 - loss: 0.2702 - val_binary_accuracy: 0.8640 - val_loss: 0.3368\n",
      "Epoch 112/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8817 - loss: 0.2754 - val_binary_accuracy: 0.8560 - val_loss: 0.3275\n",
      "Epoch 113/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8796 - loss: 0.2734 - val_binary_accuracy: 0.8440 - val_loss: 0.3516\n",
      "Epoch 114/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8918 - loss: 0.2730 - val_binary_accuracy: 0.8600 - val_loss: 0.3341\n",
      "Epoch 115/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8830 - loss: 0.2676 - val_binary_accuracy: 0.8600 - val_loss: 0.3425\n",
      "Epoch 116/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8824 - loss: 0.2766 - val_binary_accuracy: 0.8400 - val_loss: 0.3656\n",
      "Epoch 117/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8864 - loss: 0.2688 - val_binary_accuracy: 0.8640 - val_loss: 0.3285\n",
      "Epoch 118/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8871 - loss: 0.2694 - val_binary_accuracy: 0.8440 - val_loss: 0.3740\n",
      "Epoch 119/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8864 - loss: 0.2633 - val_binary_accuracy: 0.8640 - val_loss: 0.3382\n",
      "Epoch 120/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8830 - loss: 0.2696 - val_binary_accuracy: 0.8600 - val_loss: 0.3301\n",
      "Epoch 121/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8911 - loss: 0.2591 - val_binary_accuracy: 0.8600 - val_loss: 0.3329\n",
      "Epoch 122/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8918 - loss: 0.2592 - val_binary_accuracy: 0.8640 - val_loss: 0.3556\n",
      "Epoch 123/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8871 - loss: 0.2689 - val_binary_accuracy: 0.8560 - val_loss: 0.3414\n",
      "Epoch 124/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8857 - loss: 0.2587 - val_binary_accuracy: 0.8440 - val_loss: 0.3845\n",
      "Epoch 125/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8817 - loss: 0.2603 - val_binary_accuracy: 0.8480 - val_loss: 0.3340\n",
      "Epoch 126/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8891 - loss: 0.2571 - val_binary_accuracy: 0.8400 - val_loss: 0.3348\n",
      "Epoch 127/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8905 - loss: 0.2672 - val_binary_accuracy: 0.8520 - val_loss: 0.3322\n",
      "Epoch 128/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8776 - loss: 0.2834 - val_binary_accuracy: 0.8640 - val_loss: 0.3284\n",
      "Epoch 129/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8864 - loss: 0.2694 - val_binary_accuracy: 0.8440 - val_loss: 0.3404\n",
      "Epoch 130/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8878 - loss: 0.2619 - val_binary_accuracy: 0.8360 - val_loss: 0.3565\n",
      "Epoch 131/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8851 - loss: 0.2616 - val_binary_accuracy: 0.8520 - val_loss: 0.3446\n",
      "Epoch 132/10000\n",
      "47/47 - 1s - 14ms/step - binary_accuracy: 0.8830 - loss: 0.2754 - val_binary_accuracy: 0.8400 - val_loss: 0.3542\n",
      "Epoch 133/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8952 - loss: 0.2554 - val_binary_accuracy: 0.8480 - val_loss: 0.3531\n",
      "Epoch 134/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8878 - loss: 0.2609 - val_binary_accuracy: 0.8320 - val_loss: 0.3680\n",
      "Epoch 135/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8864 - loss: 0.2637 - val_binary_accuracy: 0.8480 - val_loss: 0.3431\n",
      "Epoch 136/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8959 - loss: 0.2531 - val_binary_accuracy: 0.8320 - val_loss: 0.3691\n",
      "Epoch 137/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8911 - loss: 0.2605 - val_binary_accuracy: 0.8560 - val_loss: 0.3496\n",
      "Epoch 138/10000\n",
      "47/47 - 1s - 13ms/step - binary_accuracy: 0.8932 - loss: 0.2494 - val_binary_accuracy: 0.8520 - val_loss: 0.3465\n",
      "Epoch 139/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8993 - loss: 0.2500 - val_binary_accuracy: 0.8400 - val_loss: 0.3581\n",
      "Epoch 140/10000\n",
      "47/47 - 1s - 13ms/step - binary_accuracy: 0.8932 - loss: 0.2511 - val_binary_accuracy: 0.8520 - val_loss: 0.3538\n",
      "Epoch 141/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8952 - loss: 0.2510 - val_binary_accuracy: 0.8320 - val_loss: 0.4052\n",
      "Epoch 142/10000\n",
      "47/47 - 1s - 13ms/step - binary_accuracy: 0.8871 - loss: 0.2549 - val_binary_accuracy: 0.8520 - val_loss: 0.3675\n",
      "Epoch 143/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8932 - loss: 0.2541 - val_binary_accuracy: 0.8480 - val_loss: 0.3621\n",
      "Epoch 144/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8938 - loss: 0.2488 - val_binary_accuracy: 0.8320 - val_loss: 0.3679\n",
      "Epoch 145/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8837 - loss: 0.2716 - val_binary_accuracy: 0.8520 - val_loss: 0.3446\n",
      "Epoch 146/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8911 - loss: 0.2535 - val_binary_accuracy: 0.8360 - val_loss: 0.3724\n",
      "Epoch 147/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8945 - loss: 0.2588 - val_binary_accuracy: 0.8400 - val_loss: 0.3564\n",
      "Epoch 148/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8979 - loss: 0.2501 - val_binary_accuracy: 0.8440 - val_loss: 0.3703\n",
      "Epoch 149/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8898 - loss: 0.2512 - val_binary_accuracy: 0.8520 - val_loss: 0.3559\n",
      "Epoch 150/10000\n",
      "47/47 - 1s - 13ms/step - binary_accuracy: 0.8884 - loss: 0.2487 - val_binary_accuracy: 0.8400 - val_loss: 0.3714\n",
      "Epoch 151/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8932 - loss: 0.2498 - val_binary_accuracy: 0.8360 - val_loss: 0.3866\n",
      "Epoch 152/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8979 - loss: 0.2448 - val_binary_accuracy: 0.8560 - val_loss: 0.3601\n",
      "Epoch 153/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8938 - loss: 0.2512 - val_binary_accuracy: 0.8360 - val_loss: 0.3790\n",
      "Epoch 154/10000\n",
      "47/47 - 1s - 13ms/step - binary_accuracy: 0.8966 - loss: 0.2455 - val_binary_accuracy: 0.8320 - val_loss: 0.3757\n",
      "Epoch 155/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8986 - loss: 0.2428 - val_binary_accuracy: 0.8400 - val_loss: 0.3655\n",
      "Epoch 156/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8966 - loss: 0.2509 - val_binary_accuracy: 0.8320 - val_loss: 0.3994\n",
      "Epoch 157/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8959 - loss: 0.2429 - val_binary_accuracy: 0.8560 - val_loss: 0.3678\n",
      "Epoch 158/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8999 - loss: 0.2397 - val_binary_accuracy: 0.8440 - val_loss: 0.3771\n",
      "Epoch 159/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8938 - loss: 0.2451 - val_binary_accuracy: 0.8520 - val_loss: 0.3652\n",
      "Trained model saved to CNN_models/sdB_2025-10-30_model_0.keras\n",
      "Epoch 1/10000\n",
      "47/47 - 2s - 51ms/step - binary_accuracy: 0.5422 - loss: 0.6930 - val_binary_accuracy: 0.5160 - val_loss: 0.6926\n",
      "Epoch 2/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.5436 - loss: 0.6900 - val_binary_accuracy: 0.5160 - val_loss: 0.6926\n",
      "Epoch 3/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.5436 - loss: 0.6899 - val_binary_accuracy: 0.5160 - val_loss: 0.6948\n",
      "Epoch 4/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.5436 - loss: 0.6901 - val_binary_accuracy: 0.5160 - val_loss: 0.6922\n",
      "Epoch 5/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.5436 - loss: 0.6891 - val_binary_accuracy: 0.5160 - val_loss: 0.6929\n",
      "Epoch 6/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.5436 - loss: 0.6884 - val_binary_accuracy: 0.5160 - val_loss: 0.6927\n",
      "Epoch 7/10000\n",
      "47/47 - 1s - 15ms/step - binary_accuracy: 0.5436 - loss: 0.6876 - val_binary_accuracy: 0.5160 - val_loss: 0.6914\n",
      "Epoch 8/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.5591 - loss: 0.6826 - val_binary_accuracy: 0.5160 - val_loss: 0.6985\n",
      "Epoch 9/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.5260 - loss: 0.6881 - val_binary_accuracy: 0.5160 - val_loss: 0.6818\n",
      "Epoch 10/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.6219 - loss: 0.6598 - val_binary_accuracy: 0.5160 - val_loss: 0.6858\n",
      "Epoch 11/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.6833 - loss: 0.6091 - val_binary_accuracy: 0.5560 - val_loss: 0.6882\n",
      "Epoch 12/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.7839 - loss: 0.5297 - val_binary_accuracy: 0.8040 - val_loss: 0.5110\n",
      "Epoch 13/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8130 - loss: 0.4552 - val_binary_accuracy: 0.7400 - val_loss: 0.5206\n",
      "Epoch 14/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8190 - loss: 0.4296 - val_binary_accuracy: 0.8000 - val_loss: 0.4650\n",
      "Epoch 15/10000\n",
      "47/47 - 0s - 10ms/step - binary_accuracy: 0.8454 - loss: 0.3881 - val_binary_accuracy: 0.7880 - val_loss: 0.4325\n",
      "Epoch 16/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8609 - loss: 0.3507 - val_binary_accuracy: 0.7960 - val_loss: 0.4010\n",
      "Epoch 17/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8501 - loss: 0.3510 - val_binary_accuracy: 0.8120 - val_loss: 0.3802\n",
      "Epoch 18/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8602 - loss: 0.3444 - val_binary_accuracy: 0.8160 - val_loss: 0.4184\n",
      "Epoch 19/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8582 - loss: 0.3431 - val_binary_accuracy: 0.8400 - val_loss: 0.3844\n",
      "Epoch 20/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8656 - loss: 0.3375 - val_binary_accuracy: 0.8160 - val_loss: 0.3899\n",
      "Epoch 21/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8582 - loss: 0.3408 - val_binary_accuracy: 0.8240 - val_loss: 0.3717\n",
      "Epoch 22/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8717 - loss: 0.3254 - val_binary_accuracy: 0.8200 - val_loss: 0.3747\n",
      "Epoch 23/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8609 - loss: 0.3286 - val_binary_accuracy: 0.8240 - val_loss: 0.3906\n",
      "Epoch 24/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8636 - loss: 0.3318 - val_binary_accuracy: 0.8200 - val_loss: 0.3720\n",
      "Epoch 25/10000\n",
      "47/47 - 1s - 13ms/step - binary_accuracy: 0.8609 - loss: 0.3318 - val_binary_accuracy: 0.7320 - val_loss: 0.5210\n",
      "Epoch 26/10000\n",
      "47/47 - 1s - 13ms/step - binary_accuracy: 0.8542 - loss: 0.3472 - val_binary_accuracy: 0.8040 - val_loss: 0.4529\n",
      "Epoch 27/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8596 - loss: 0.3294 - val_binary_accuracy: 0.8400 - val_loss: 0.3703\n",
      "Epoch 28/10000\n",
      "47/47 - 1s - 12ms/step - binary_accuracy: 0.8690 - loss: 0.3127 - val_binary_accuracy: 0.8320 - val_loss: 0.4037\n",
      "Epoch 29/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8609 - loss: 0.3165 - val_binary_accuracy: 0.8280 - val_loss: 0.3903\n",
      "Epoch 30/10000\n",
      "47/47 - 1s - 17ms/step - binary_accuracy: 0.8690 - loss: 0.3232 - val_binary_accuracy: 0.8400 - val_loss: 0.3675\n",
      "Epoch 31/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8697 - loss: 0.3359 - val_binary_accuracy: 0.7920 - val_loss: 0.4307\n",
      "Epoch 32/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8609 - loss: 0.3398 - val_binary_accuracy: 0.8280 - val_loss: 0.4051\n",
      "Epoch 33/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8758 - loss: 0.3096 - val_binary_accuracy: 0.8080 - val_loss: 0.4032\n",
      "Epoch 34/10000\n",
      "47/47 - 1s - 13ms/step - binary_accuracy: 0.8717 - loss: 0.3154 - val_binary_accuracy: 0.8160 - val_loss: 0.3763\n",
      "Epoch 35/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8677 - loss: 0.3173 - val_binary_accuracy: 0.8400 - val_loss: 0.3685\n",
      "Epoch 36/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8683 - loss: 0.3219 - val_binary_accuracy: 0.8360 - val_loss: 0.3719\n",
      "Epoch 37/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8717 - loss: 0.3200 - val_binary_accuracy: 0.8400 - val_loss: 0.3684\n",
      "Epoch 38/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8717 - loss: 0.3116 - val_binary_accuracy: 0.8320 - val_loss: 0.3734\n",
      "Epoch 39/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8656 - loss: 0.3191 - val_binary_accuracy: 0.8400 - val_loss: 0.3707\n",
      "Epoch 40/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8629 - loss: 0.3227 - val_binary_accuracy: 0.8400 - val_loss: 0.3729\n",
      "Epoch 41/10000\n",
      "47/47 - 1s - 15ms/step - binary_accuracy: 0.8737 - loss: 0.3106 - val_binary_accuracy: 0.8400 - val_loss: 0.3710\n",
      "Epoch 42/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8771 - loss: 0.3152 - val_binary_accuracy: 0.8120 - val_loss: 0.3852\n",
      "Epoch 43/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8717 - loss: 0.3078 - val_binary_accuracy: 0.8440 - val_loss: 0.3707\n",
      "Epoch 44/10000\n",
      "47/47 - 0s - 10ms/step - binary_accuracy: 0.8724 - loss: 0.3058 - val_binary_accuracy: 0.8400 - val_loss: 0.3732\n",
      "Epoch 45/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8629 - loss: 0.3200 - val_binary_accuracy: 0.8080 - val_loss: 0.3822\n",
      "Epoch 46/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8785 - loss: 0.3045 - val_binary_accuracy: 0.8360 - val_loss: 0.3720\n",
      "Epoch 47/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8697 - loss: 0.3145 - val_binary_accuracy: 0.8320 - val_loss: 0.3974\n",
      "Epoch 48/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8805 - loss: 0.3076 - val_binary_accuracy: 0.8400 - val_loss: 0.3726\n",
      "Epoch 49/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8690 - loss: 0.3256 - val_binary_accuracy: 0.8320 - val_loss: 0.3905\n",
      "Epoch 50/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8677 - loss: 0.3308 - val_binary_accuracy: 0.8240 - val_loss: 0.3754\n",
      "Epoch 51/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8731 - loss: 0.3051 - val_binary_accuracy: 0.8400 - val_loss: 0.3743\n",
      "Epoch 52/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8744 - loss: 0.3092 - val_binary_accuracy: 0.7760 - val_loss: 0.4362\n",
      "Epoch 53/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8629 - loss: 0.3363 - val_binary_accuracy: 0.8040 - val_loss: 0.3980\n",
      "Epoch 54/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8717 - loss: 0.3083 - val_binary_accuracy: 0.8280 - val_loss: 0.3857\n",
      "Epoch 55/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8751 - loss: 0.3097 - val_binary_accuracy: 0.8280 - val_loss: 0.3772\n",
      "Epoch 56/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8737 - loss: 0.3088 - val_binary_accuracy: 0.8320 - val_loss: 0.3771\n",
      "Epoch 57/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8710 - loss: 0.3053 - val_binary_accuracy: 0.8320 - val_loss: 0.3770\n",
      "Epoch 58/10000\n",
      "47/47 - 1s - 12ms/step - binary_accuracy: 0.8818 - loss: 0.2992 - val_binary_accuracy: 0.8320 - val_loss: 0.3781\n",
      "Epoch 59/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8751 - loss: 0.2997 - val_binary_accuracy: 0.8120 - val_loss: 0.3986\n",
      "Epoch 60/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8724 - loss: 0.3045 - val_binary_accuracy: 0.8000 - val_loss: 0.4088\n",
      "Epoch 61/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8683 - loss: 0.3058 - val_binary_accuracy: 0.8120 - val_loss: 0.3865\n",
      "Epoch 62/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8798 - loss: 0.2983 - val_binary_accuracy: 0.8320 - val_loss: 0.3783\n",
      "Epoch 63/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8656 - loss: 0.3237 - val_binary_accuracy: 0.8000 - val_loss: 0.4726\n",
      "Epoch 64/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8704 - loss: 0.3141 - val_binary_accuracy: 0.8320 - val_loss: 0.3817\n",
      "Epoch 65/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8710 - loss: 0.3132 - val_binary_accuracy: 0.8240 - val_loss: 0.3984\n",
      "Epoch 66/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8832 - loss: 0.2979 - val_binary_accuracy: 0.8320 - val_loss: 0.3784\n",
      "Epoch 67/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8751 - loss: 0.2990 - val_binary_accuracy: 0.8120 - val_loss: 0.3882\n",
      "Epoch 68/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8683 - loss: 0.3212 - val_binary_accuracy: 0.8120 - val_loss: 0.4079\n",
      "Epoch 69/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8805 - loss: 0.3078 - val_binary_accuracy: 0.8360 - val_loss: 0.3795\n",
      "Epoch 70/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8764 - loss: 0.3041 - val_binary_accuracy: 0.8360 - val_loss: 0.3786\n",
      "Epoch 71/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8670 - loss: 0.3153 - val_binary_accuracy: 0.8200 - val_loss: 0.3837\n",
      "Epoch 72/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8744 - loss: 0.3005 - val_binary_accuracy: 0.8360 - val_loss: 0.3869\n",
      "Epoch 73/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8778 - loss: 0.2909 - val_binary_accuracy: 0.8120 - val_loss: 0.3884\n",
      "Epoch 74/10000\n",
      "47/47 - 1s - 11ms/step - binary_accuracy: 0.8778 - loss: 0.2984 - val_binary_accuracy: 0.8040 - val_loss: 0.3915\n",
      "Epoch 75/10000\n",
      "47/47 - 1s - 14ms/step - binary_accuracy: 0.8670 - loss: 0.3032 - val_binary_accuracy: 0.8280 - val_loss: 0.3848\n",
      "Epoch 76/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8778 - loss: 0.3047 - val_binary_accuracy: 0.8360 - val_loss: 0.3990\n",
      "Epoch 77/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8839 - loss: 0.2925 - val_binary_accuracy: 0.8280 - val_loss: 0.3946\n",
      "Epoch 78/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8785 - loss: 0.2955 - val_binary_accuracy: 0.8360 - val_loss: 0.3835\n",
      "Epoch 79/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8785 - loss: 0.2930 - val_binary_accuracy: 0.7800 - val_loss: 0.4749\n",
      "Epoch 80/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8717 - loss: 0.3046 - val_binary_accuracy: 0.8360 - val_loss: 0.3829\n",
      "Epoch 81/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8758 - loss: 0.2960 - val_binary_accuracy: 0.8360 - val_loss: 0.3967\n",
      "Epoch 82/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8778 - loss: 0.2909 - val_binary_accuracy: 0.8240 - val_loss: 0.3908\n",
      "Epoch 83/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8812 - loss: 0.2921 - val_binary_accuracy: 0.8280 - val_loss: 0.4057\n",
      "Epoch 84/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8832 - loss: 0.2903 - val_binary_accuracy: 0.7920 - val_loss: 0.4196\n",
      "Epoch 85/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8710 - loss: 0.3076 - val_binary_accuracy: 0.8160 - val_loss: 0.3926\n",
      "Epoch 86/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8791 - loss: 0.2966 - val_binary_accuracy: 0.8120 - val_loss: 0.3934\n",
      "Epoch 87/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8818 - loss: 0.2877 - val_binary_accuracy: 0.8240 - val_loss: 0.3942\n",
      "Epoch 88/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8818 - loss: 0.2854 - val_binary_accuracy: 0.8080 - val_loss: 0.4026\n",
      "Epoch 89/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8845 - loss: 0.2895 - val_binary_accuracy: 0.8000 - val_loss: 0.4018\n",
      "Epoch 90/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8663 - loss: 0.3125 - val_binary_accuracy: 0.8080 - val_loss: 0.4020\n",
      "Epoch 91/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8771 - loss: 0.2942 - val_binary_accuracy: 0.8240 - val_loss: 0.3967\n",
      "Epoch 92/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8751 - loss: 0.2959 - val_binary_accuracy: 0.8240 - val_loss: 0.3890\n",
      "Epoch 93/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8812 - loss: 0.2886 - val_binary_accuracy: 0.8200 - val_loss: 0.3934\n",
      "Epoch 94/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8859 - loss: 0.2843 - val_binary_accuracy: 0.8040 - val_loss: 0.4025\n",
      "Epoch 95/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8798 - loss: 0.2891 - val_binary_accuracy: 0.8040 - val_loss: 0.3985\n",
      "Epoch 96/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8758 - loss: 0.2891 - val_binary_accuracy: 0.8280 - val_loss: 0.3947\n",
      "Epoch 97/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8751 - loss: 0.3001 - val_binary_accuracy: 0.8160 - val_loss: 0.3944\n",
      "Epoch 98/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8764 - loss: 0.2977 - val_binary_accuracy: 0.8080 - val_loss: 0.3929\n",
      "Epoch 99/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8879 - loss: 0.2912 - val_binary_accuracy: 0.8240 - val_loss: 0.4050\n",
      "Epoch 100/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8791 - loss: 0.2846 - val_binary_accuracy: 0.8240 - val_loss: 0.4208\n",
      "Epoch 101/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8798 - loss: 0.2877 - val_binary_accuracy: 0.8040 - val_loss: 0.4501\n",
      "Epoch 102/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8758 - loss: 0.2943 - val_binary_accuracy: 0.7560 - val_loss: 0.5049\n",
      "Epoch 103/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8866 - loss: 0.2850 - val_binary_accuracy: 0.8280 - val_loss: 0.4173\n",
      "Epoch 104/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8832 - loss: 0.2871 - val_binary_accuracy: 0.8280 - val_loss: 0.4171\n",
      "Epoch 105/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8852 - loss: 0.2865 - val_binary_accuracy: 0.8000 - val_loss: 0.4241\n",
      "Epoch 106/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8879 - loss: 0.2810 - val_binary_accuracy: 0.8040 - val_loss: 0.3989\n",
      "Epoch 107/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8839 - loss: 0.2861 - val_binary_accuracy: 0.8320 - val_loss: 0.3968\n",
      "Epoch 108/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8832 - loss: 0.2848 - val_binary_accuracy: 0.8240 - val_loss: 0.4043\n",
      "Epoch 109/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8866 - loss: 0.2760 - val_binary_accuracy: 0.8160 - val_loss: 0.3990\n",
      "Epoch 110/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8778 - loss: 0.2813 - val_binary_accuracy: 0.8200 - val_loss: 0.4104\n",
      "Epoch 111/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8866 - loss: 0.2802 - val_binary_accuracy: 0.8040 - val_loss: 0.4009\n",
      "Epoch 112/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8832 - loss: 0.2757 - val_binary_accuracy: 0.8240 - val_loss: 0.4186\n",
      "Epoch 113/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8805 - loss: 0.2850 - val_binary_accuracy: 0.8120 - val_loss: 0.3987\n",
      "Epoch 114/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8839 - loss: 0.2799 - val_binary_accuracy: 0.8120 - val_loss: 0.4527\n",
      "Epoch 115/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8852 - loss: 0.2838 - val_binary_accuracy: 0.8120 - val_loss: 0.4069\n",
      "Epoch 116/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8859 - loss: 0.2715 - val_binary_accuracy: 0.8080 - val_loss: 0.4036\n",
      "Epoch 117/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8825 - loss: 0.2707 - val_binary_accuracy: 0.8000 - val_loss: 0.4214\n",
      "Epoch 118/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8866 - loss: 0.2747 - val_binary_accuracy: 0.8240 - val_loss: 0.4098\n",
      "Epoch 119/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8906 - loss: 0.2705 - val_binary_accuracy: 0.8120 - val_loss: 0.4065\n",
      "Epoch 120/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8859 - loss: 0.2722 - val_binary_accuracy: 0.7960 - val_loss: 0.4756\n",
      "Epoch 121/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8913 - loss: 0.2762 - val_binary_accuracy: 0.8160 - val_loss: 0.4059\n",
      "Epoch 122/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8845 - loss: 0.2774 - val_binary_accuracy: 0.8280 - val_loss: 0.4270\n",
      "Epoch 123/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8879 - loss: 0.2773 - val_binary_accuracy: 0.8280 - val_loss: 0.4241\n",
      "Epoch 124/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8852 - loss: 0.2689 - val_binary_accuracy: 0.8240 - val_loss: 0.4351\n",
      "Epoch 125/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8825 - loss: 0.2751 - val_binary_accuracy: 0.8080 - val_loss: 0.4037\n",
      "Epoch 126/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8866 - loss: 0.2779 - val_binary_accuracy: 0.8240 - val_loss: 0.4453\n",
      "Epoch 127/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8879 - loss: 0.2739 - val_binary_accuracy: 0.8040 - val_loss: 0.4086\n",
      "Epoch 128/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8805 - loss: 0.2855 - val_binary_accuracy: 0.8280 - val_loss: 0.4324\n",
      "Epoch 129/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8920 - loss: 0.2694 - val_binary_accuracy: 0.7960 - val_loss: 0.4435\n",
      "Epoch 130/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8872 - loss: 0.2715 - val_binary_accuracy: 0.8280 - val_loss: 0.4174\n",
      "Epoch 131/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8893 - loss: 0.2668 - val_binary_accuracy: 0.8240 - val_loss: 0.4211\n",
      "Epoch 132/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8899 - loss: 0.2725 - val_binary_accuracy: 0.8240 - val_loss: 0.4203\n",
      "Epoch 133/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8906 - loss: 0.2611 - val_binary_accuracy: 0.8000 - val_loss: 0.4193\n",
      "Epoch 134/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8913 - loss: 0.2649 - val_binary_accuracy: 0.8240 - val_loss: 0.4226\n",
      "Epoch 135/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8933 - loss: 0.2683 - val_binary_accuracy: 0.8040 - val_loss: 0.4074\n",
      "Epoch 136/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8818 - loss: 0.2809 - val_binary_accuracy: 0.8240 - val_loss: 0.4179\n",
      "Epoch 137/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8933 - loss: 0.2669 - val_binary_accuracy: 0.8160 - val_loss: 0.4389\n",
      "Epoch 138/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8886 - loss: 0.2630 - val_binary_accuracy: 0.8000 - val_loss: 0.4248\n",
      "Epoch 139/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8852 - loss: 0.2746 - val_binary_accuracy: 0.8320 - val_loss: 0.4418\n",
      "Epoch 140/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8920 - loss: 0.2674 - val_binary_accuracy: 0.8240 - val_loss: 0.4274\n",
      "Epoch 141/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8825 - loss: 0.2674 - val_binary_accuracy: 0.8120 - val_loss: 0.4278\n",
      "Epoch 142/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8893 - loss: 0.2662 - val_binary_accuracy: 0.8080 - val_loss: 0.4336\n",
      "Epoch 143/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8872 - loss: 0.2727 - val_binary_accuracy: 0.8240 - val_loss: 0.4501\n",
      "Epoch 144/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8872 - loss: 0.2608 - val_binary_accuracy: 0.8040 - val_loss: 0.4350\n",
      "Epoch 145/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8906 - loss: 0.2626 - val_binary_accuracy: 0.8200 - val_loss: 0.4258\n",
      "Epoch 146/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8926 - loss: 0.2605 - val_binary_accuracy: 0.8280 - val_loss: 0.4283\n",
      "Epoch 147/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8872 - loss: 0.2573 - val_binary_accuracy: 0.8040 - val_loss: 0.4256\n",
      "Epoch 148/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8886 - loss: 0.2582 - val_binary_accuracy: 0.8160 - val_loss: 0.4248\n",
      "Epoch 149/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8913 - loss: 0.2592 - val_binary_accuracy: 0.8120 - val_loss: 0.4264\n",
      "Epoch 150/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8879 - loss: 0.2618 - val_binary_accuracy: 0.8160 - val_loss: 0.4246\n",
      "Trained model saved to CNN_models/sdB_2025-10-30_model_1.keras\n",
      "Epoch 1/10000\n",
      "47/47 - 2s - 47ms/step - binary_accuracy: 0.5308 - loss: 0.6922 - val_binary_accuracy: 0.5720 - val_loss: 0.6860\n",
      "Epoch 2/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.5335 - loss: 0.6916 - val_binary_accuracy: 0.5720 - val_loss: 0.6863\n",
      "Epoch 3/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.5335 - loss: 0.6911 - val_binary_accuracy: 0.5720 - val_loss: 0.6854\n",
      "Epoch 4/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.5335 - loss: 0.6915 - val_binary_accuracy: 0.5720 - val_loss: 0.6876\n",
      "Epoch 5/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.5335 - loss: 0.6909 - val_binary_accuracy: 0.5720 - val_loss: 0.6839\n",
      "Epoch 6/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.5335 - loss: 0.6909 - val_binary_accuracy: 0.5720 - val_loss: 0.6841\n",
      "Epoch 7/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.5335 - loss: 0.6909 - val_binary_accuracy: 0.5720 - val_loss: 0.6875\n",
      "Epoch 8/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.5490 - loss: 0.6896 - val_binary_accuracy: 0.5720 - val_loss: 0.6819\n",
      "Epoch 9/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.5612 - loss: 0.6836 - val_binary_accuracy: 0.6480 - val_loss: 0.6714\n",
      "Epoch 10/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.6288 - loss: 0.6504 - val_binary_accuracy: 0.8560 - val_loss: 0.6084\n",
      "Epoch 11/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.7634 - loss: 0.5086 - val_binary_accuracy: 0.7800 - val_loss: 0.4641\n",
      "Epoch 12/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8120 - loss: 0.4064 - val_binary_accuracy: 0.8680 - val_loss: 0.3257\n",
      "Epoch 13/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8485 - loss: 0.3595 - val_binary_accuracy: 0.8640 - val_loss: 0.3043\n",
      "Epoch 14/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8526 - loss: 0.3576 - val_binary_accuracy: 0.8680 - val_loss: 0.3151\n",
      "Epoch 15/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8492 - loss: 0.3510 - val_binary_accuracy: 0.8120 - val_loss: 0.4145\n",
      "Epoch 16/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8303 - loss: 0.3768 - val_binary_accuracy: 0.8560 - val_loss: 0.3454\n",
      "Epoch 17/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8546 - loss: 0.3401 - val_binary_accuracy: 0.8720 - val_loss: 0.2893\n",
      "Epoch 18/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8425 - loss: 0.3556 - val_binary_accuracy: 0.8600 - val_loss: 0.3098\n",
      "Epoch 19/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8418 - loss: 0.3586 - val_binary_accuracy: 0.8840 - val_loss: 0.2960\n",
      "Epoch 20/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8560 - loss: 0.3430 - val_binary_accuracy: 0.8600 - val_loss: 0.3316\n",
      "Epoch 21/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8594 - loss: 0.3321 - val_binary_accuracy: 0.8680 - val_loss: 0.2878\n",
      "Epoch 22/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8621 - loss: 0.3311 - val_binary_accuracy: 0.8760 - val_loss: 0.2871\n",
      "Epoch 23/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8594 - loss: 0.3314 - val_binary_accuracy: 0.8640 - val_loss: 0.2984\n",
      "Epoch 24/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8573 - loss: 0.3379 - val_binary_accuracy: 0.8720 - val_loss: 0.3225\n",
      "Epoch 25/10000\n",
      "47/47 - 1s - 14ms/step - binary_accuracy: 0.8621 - loss: 0.3338 - val_binary_accuracy: 0.8760 - val_loss: 0.3046\n",
      "Epoch 26/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8580 - loss: 0.3270 - val_binary_accuracy: 0.8640 - val_loss: 0.2847\n",
      "Epoch 27/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8675 - loss: 0.3218 - val_binary_accuracy: 0.8680 - val_loss: 0.2946\n",
      "Epoch 28/10000\n",
      "47/47 - 1s - 15ms/step - binary_accuracy: 0.8661 - loss: 0.3281 - val_binary_accuracy: 0.8600 - val_loss: 0.3052\n",
      "Epoch 29/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8607 - loss: 0.3352 - val_binary_accuracy: 0.8640 - val_loss: 0.2946\n",
      "Epoch 30/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8621 - loss: 0.3363 - val_binary_accuracy: 0.8760 - val_loss: 0.2856\n",
      "Epoch 31/10000\n",
      "47/47 - 1s - 20ms/step - binary_accuracy: 0.8594 - loss: 0.3331 - val_binary_accuracy: 0.8640 - val_loss: 0.2894\n",
      "Epoch 32/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8492 - loss: 0.3388 - val_binary_accuracy: 0.8800 - val_loss: 0.2874\n",
      "Epoch 33/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8688 - loss: 0.3317 - val_binary_accuracy: 0.8560 - val_loss: 0.3304\n",
      "Epoch 34/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8654 - loss: 0.3184 - val_binary_accuracy: 0.8800 - val_loss: 0.2811\n",
      "Epoch 35/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8688 - loss: 0.3217 - val_binary_accuracy: 0.8720 - val_loss: 0.3045\n",
      "Epoch 36/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8688 - loss: 0.3160 - val_binary_accuracy: 0.8720 - val_loss: 0.2962\n",
      "Epoch 37/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8641 - loss: 0.3234 - val_binary_accuracy: 0.8720 - val_loss: 0.2813\n",
      "Epoch 38/10000\n",
      "47/47 - 0s - 10ms/step - binary_accuracy: 0.8715 - loss: 0.3184 - val_binary_accuracy: 0.8640 - val_loss: 0.2794\n",
      "Epoch 39/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8682 - loss: 0.3264 - val_binary_accuracy: 0.8760 - val_loss: 0.2801\n",
      "Epoch 40/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8641 - loss: 0.3202 - val_binary_accuracy: 0.8680 - val_loss: 0.2791\n",
      "Epoch 41/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8648 - loss: 0.3279 - val_binary_accuracy: 0.8720 - val_loss: 0.2798\n",
      "Epoch 42/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8648 - loss: 0.3184 - val_binary_accuracy: 0.8640 - val_loss: 0.3128\n",
      "Epoch 43/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8722 - loss: 0.3184 - val_binary_accuracy: 0.8640 - val_loss: 0.3123\n",
      "Epoch 44/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8634 - loss: 0.3223 - val_binary_accuracy: 0.8760 - val_loss: 0.2777\n",
      "Epoch 45/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8688 - loss: 0.3171 - val_binary_accuracy: 0.8640 - val_loss: 0.2795\n",
      "Epoch 46/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8742 - loss: 0.3084 - val_binary_accuracy: 0.8680 - val_loss: 0.2808\n",
      "Epoch 47/10000\n",
      "47/47 - 1s - 11ms/step - binary_accuracy: 0.8614 - loss: 0.3157 - val_binary_accuracy: 0.8680 - val_loss: 0.2765\n",
      "Epoch 48/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8682 - loss: 0.3124 - val_binary_accuracy: 0.8880 - val_loss: 0.2817\n",
      "Epoch 49/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8661 - loss: 0.3175 - val_binary_accuracy: 0.8760 - val_loss: 0.2770\n",
      "Epoch 50/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8722 - loss: 0.3124 - val_binary_accuracy: 0.8600 - val_loss: 0.3146\n",
      "Epoch 51/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8749 - loss: 0.3044 - val_binary_accuracy: 0.8800 - val_loss: 0.2982\n",
      "Epoch 52/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8654 - loss: 0.3162 - val_binary_accuracy: 0.8840 - val_loss: 0.2772\n",
      "Epoch 53/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8722 - loss: 0.3151 - val_binary_accuracy: 0.8800 - val_loss: 0.3048\n",
      "Epoch 54/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8702 - loss: 0.3095 - val_binary_accuracy: 0.8640 - val_loss: 0.3041\n",
      "Epoch 55/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8702 - loss: 0.3113 - val_binary_accuracy: 0.8640 - val_loss: 0.2805\n",
      "Epoch 56/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8587 - loss: 0.3197 - val_binary_accuracy: 0.8760 - val_loss: 0.2900\n",
      "Epoch 57/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8661 - loss: 0.3071 - val_binary_accuracy: 0.8840 - val_loss: 0.2754\n",
      "Epoch 58/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8709 - loss: 0.3060 - val_binary_accuracy: 0.8800 - val_loss: 0.2783\n",
      "Epoch 59/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8776 - loss: 0.2998 - val_binary_accuracy: 0.8600 - val_loss: 0.3219\n",
      "Epoch 60/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8709 - loss: 0.3145 - val_binary_accuracy: 0.8800 - val_loss: 0.2794\n",
      "Epoch 61/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8776 - loss: 0.2965 - val_binary_accuracy: 0.8440 - val_loss: 0.3345\n",
      "Epoch 62/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8682 - loss: 0.3088 - val_binary_accuracy: 0.8840 - val_loss: 0.2849\n",
      "Epoch 63/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8783 - loss: 0.2952 - val_binary_accuracy: 0.8800 - val_loss: 0.2757\n",
      "Epoch 64/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8648 - loss: 0.2991 - val_binary_accuracy: 0.8800 - val_loss: 0.2805\n",
      "Epoch 65/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8682 - loss: 0.3069 - val_binary_accuracy: 0.8680 - val_loss: 0.2997\n",
      "Epoch 66/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8452 - loss: 0.3397 - val_binary_accuracy: 0.8880 - val_loss: 0.2929\n",
      "Epoch 67/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8783 - loss: 0.3102 - val_binary_accuracy: 0.8640 - val_loss: 0.2979\n",
      "Epoch 68/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8749 - loss: 0.2943 - val_binary_accuracy: 0.8640 - val_loss: 0.2944\n",
      "Epoch 69/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8695 - loss: 0.3007 - val_binary_accuracy: 0.8720 - val_loss: 0.2938\n",
      "Epoch 70/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8614 - loss: 0.3061 - val_binary_accuracy: 0.8800 - val_loss: 0.2933\n",
      "Epoch 71/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8763 - loss: 0.2934 - val_binary_accuracy: 0.8680 - val_loss: 0.2998\n",
      "Epoch 72/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8796 - loss: 0.2904 - val_binary_accuracy: 0.8800 - val_loss: 0.2781\n",
      "Epoch 73/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8749 - loss: 0.2971 - val_binary_accuracy: 0.8800 - val_loss: 0.2783\n",
      "Epoch 74/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8756 - loss: 0.2972 - val_binary_accuracy: 0.8720 - val_loss: 0.3032\n",
      "Epoch 75/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8776 - loss: 0.2942 - val_binary_accuracy: 0.8840 - val_loss: 0.2788\n",
      "Epoch 76/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8682 - loss: 0.2997 - val_binary_accuracy: 0.8720 - val_loss: 0.2810\n",
      "Epoch 77/10000\n",
      "47/47 - 0s - 10ms/step - binary_accuracy: 0.8769 - loss: 0.2931 - val_binary_accuracy: 0.8800 - val_loss: 0.2791\n",
      "Epoch 78/10000\n",
      "47/47 - 0s - 10ms/step - binary_accuracy: 0.8742 - loss: 0.2917 - val_binary_accuracy: 0.8720 - val_loss: 0.2949\n",
      "Epoch 79/10000\n",
      "47/47 - 1s - 11ms/step - binary_accuracy: 0.8763 - loss: 0.2993 - val_binary_accuracy: 0.8720 - val_loss: 0.2837\n",
      "Epoch 80/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8803 - loss: 0.2935 - val_binary_accuracy: 0.8760 - val_loss: 0.2828\n",
      "Epoch 81/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8790 - loss: 0.2840 - val_binary_accuracy: 0.8800 - val_loss: 0.2814\n",
      "Epoch 82/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8796 - loss: 0.2852 - val_binary_accuracy: 0.8760 - val_loss: 0.3002\n",
      "Epoch 83/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8803 - loss: 0.2853 - val_binary_accuracy: 0.8680 - val_loss: 0.2880\n",
      "Epoch 84/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8803 - loss: 0.2819 - val_binary_accuracy: 0.8760 - val_loss: 0.2988\n",
      "Epoch 85/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8857 - loss: 0.2790 - val_binary_accuracy: 0.8680 - val_loss: 0.2889\n",
      "Epoch 86/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8844 - loss: 0.2858 - val_binary_accuracy: 0.8720 - val_loss: 0.2928\n",
      "Epoch 87/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8837 - loss: 0.2837 - val_binary_accuracy: 0.8800 - val_loss: 0.2841\n",
      "Epoch 88/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8729 - loss: 0.2938 - val_binary_accuracy: 0.8720 - val_loss: 0.2849\n",
      "Epoch 89/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8729 - loss: 0.2809 - val_binary_accuracy: 0.8840 - val_loss: 0.2929\n",
      "Epoch 90/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8830 - loss: 0.2825 - val_binary_accuracy: 0.8840 - val_loss: 0.2870\n",
      "Epoch 91/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8851 - loss: 0.2935 - val_binary_accuracy: 0.8800 - val_loss: 0.2857\n",
      "Epoch 92/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8837 - loss: 0.2792 - val_binary_accuracy: 0.8800 - val_loss: 0.2855\n",
      "Epoch 93/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8810 - loss: 0.2866 - val_binary_accuracy: 0.8760 - val_loss: 0.2872\n",
      "Epoch 94/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8857 - loss: 0.2811 - val_binary_accuracy: 0.8600 - val_loss: 0.3545\n",
      "Epoch 95/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8857 - loss: 0.2788 - val_binary_accuracy: 0.8720 - val_loss: 0.2887\n",
      "Epoch 96/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8857 - loss: 0.2732 - val_binary_accuracy: 0.8760 - val_loss: 0.2886\n",
      "Epoch 97/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8810 - loss: 0.2742 - val_binary_accuracy: 0.8760 - val_loss: 0.3151\n",
      "Epoch 98/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8810 - loss: 0.2790 - val_binary_accuracy: 0.8720 - val_loss: 0.2935\n",
      "Epoch 99/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8871 - loss: 0.2751 - val_binary_accuracy: 0.8720 - val_loss: 0.2939\n",
      "Epoch 100/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8830 - loss: 0.2774 - val_binary_accuracy: 0.8720 - val_loss: 0.2901\n",
      "Epoch 101/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8803 - loss: 0.2783 - val_binary_accuracy: 0.8720 - val_loss: 0.3054\n",
      "Epoch 102/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8763 - loss: 0.2894 - val_binary_accuracy: 0.8720 - val_loss: 0.2956\n",
      "Epoch 103/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8817 - loss: 0.2882 - val_binary_accuracy: 0.8720 - val_loss: 0.2986\n",
      "Epoch 104/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8790 - loss: 0.2860 - val_binary_accuracy: 0.8760 - val_loss: 0.2951\n",
      "Epoch 105/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8742 - loss: 0.2841 - val_binary_accuracy: 0.8720 - val_loss: 0.3045\n",
      "Epoch 106/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8783 - loss: 0.2849 - val_binary_accuracy: 0.8640 - val_loss: 0.3010\n",
      "Epoch 107/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8878 - loss: 0.2702 - val_binary_accuracy: 0.8800 - val_loss: 0.2988\n",
      "Epoch 108/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8851 - loss: 0.2712 - val_binary_accuracy: 0.8640 - val_loss: 0.3063\n",
      "Epoch 109/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8803 - loss: 0.2726 - val_binary_accuracy: 0.8760 - val_loss: 0.2954\n",
      "Epoch 110/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8878 - loss: 0.2627 - val_binary_accuracy: 0.8800 - val_loss: 0.3147\n",
      "Epoch 111/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8905 - loss: 0.2671 - val_binary_accuracy: 0.8720 - val_loss: 0.2962\n",
      "Epoch 112/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8803 - loss: 0.2839 - val_binary_accuracy: 0.8720 - val_loss: 0.3358\n",
      "Epoch 113/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8857 - loss: 0.2672 - val_binary_accuracy: 0.8840 - val_loss: 0.2994\n",
      "Epoch 114/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8844 - loss: 0.2752 - val_binary_accuracy: 0.8680 - val_loss: 0.3270\n",
      "Epoch 115/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8864 - loss: 0.2674 - val_binary_accuracy: 0.8800 - val_loss: 0.2948\n",
      "Epoch 116/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8776 - loss: 0.2831 - val_binary_accuracy: 0.8680 - val_loss: 0.3379\n",
      "Epoch 117/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8756 - loss: 0.2902 - val_binary_accuracy: 0.8760 - val_loss: 0.3232\n",
      "Epoch 118/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8810 - loss: 0.2693 - val_binary_accuracy: 0.8760 - val_loss: 0.3125\n",
      "Epoch 119/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8844 - loss: 0.2693 - val_binary_accuracy: 0.8720 - val_loss: 0.3069\n",
      "Epoch 120/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8844 - loss: 0.2684 - val_binary_accuracy: 0.8560 - val_loss: 0.3612\n",
      "Epoch 121/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8796 - loss: 0.2773 - val_binary_accuracy: 0.8680 - val_loss: 0.3113\n",
      "Epoch 122/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8837 - loss: 0.2739 - val_binary_accuracy: 0.8760 - val_loss: 0.3211\n",
      "Epoch 123/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8803 - loss: 0.2642 - val_binary_accuracy: 0.8680 - val_loss: 0.3314\n",
      "Epoch 124/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8830 - loss: 0.2770 - val_binary_accuracy: 0.8640 - val_loss: 0.3108\n",
      "Epoch 125/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8857 - loss: 0.2666 - val_binary_accuracy: 0.8760 - val_loss: 0.3042\n",
      "Epoch 126/10000\n",
      "47/47 - 1s - 15ms/step - binary_accuracy: 0.8864 - loss: 0.2701 - val_binary_accuracy: 0.8400 - val_loss: 0.4094\n",
      "Epoch 127/10000\n",
      "47/47 - 0s - 10ms/step - binary_accuracy: 0.8864 - loss: 0.2752 - val_binary_accuracy: 0.8760 - val_loss: 0.3111\n",
      "Epoch 128/10000\n",
      "47/47 - 1s - 12ms/step - binary_accuracy: 0.8905 - loss: 0.2628 - val_binary_accuracy: 0.8720 - val_loss: 0.3066\n",
      "Epoch 129/10000\n",
      "47/47 - 1s - 13ms/step - binary_accuracy: 0.8925 - loss: 0.2586 - val_binary_accuracy: 0.8720 - val_loss: 0.3310\n",
      "Epoch 130/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8837 - loss: 0.2603 - val_binary_accuracy: 0.8880 - val_loss: 0.3052\n",
      "Epoch 131/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8925 - loss: 0.2587 - val_binary_accuracy: 0.8640 - val_loss: 0.3377\n",
      "Epoch 132/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8857 - loss: 0.2633 - val_binary_accuracy: 0.8560 - val_loss: 0.3542\n",
      "Epoch 133/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8837 - loss: 0.2623 - val_binary_accuracy: 0.8800 - val_loss: 0.3059\n",
      "Epoch 134/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8898 - loss: 0.2604 - val_binary_accuracy: 0.8640 - val_loss: 0.3079\n",
      "Epoch 135/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8884 - loss: 0.2738 - val_binary_accuracy: 0.8720 - val_loss: 0.3171\n",
      "Epoch 136/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8864 - loss: 0.2607 - val_binary_accuracy: 0.8720 - val_loss: 0.3152\n",
      "Epoch 137/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8830 - loss: 0.2672 - val_binary_accuracy: 0.8800 - val_loss: 0.3185\n",
      "Epoch 138/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8864 - loss: 0.2651 - val_binary_accuracy: 0.8720 - val_loss: 0.3169\n",
      "Epoch 139/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8878 - loss: 0.2619 - val_binary_accuracy: 0.8640 - val_loss: 0.3318\n",
      "Epoch 140/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8898 - loss: 0.2626 - val_binary_accuracy: 0.8760 - val_loss: 0.3232\n",
      "Epoch 141/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8844 - loss: 0.2713 - val_binary_accuracy: 0.8640 - val_loss: 0.3467\n",
      "Epoch 142/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8925 - loss: 0.2569 - val_binary_accuracy: 0.8720 - val_loss: 0.3287\n",
      "Epoch 143/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8857 - loss: 0.2563 - val_binary_accuracy: 0.8760 - val_loss: 0.3256\n",
      "Epoch 144/10000\n",
      "47/47 - 1s - 16ms/step - binary_accuracy: 0.8911 - loss: 0.2516 - val_binary_accuracy: 0.8720 - val_loss: 0.3185\n",
      "Epoch 145/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8952 - loss: 0.2506 - val_binary_accuracy: 0.8680 - val_loss: 0.3427\n",
      "Epoch 146/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8905 - loss: 0.2589 - val_binary_accuracy: 0.8720 - val_loss: 0.3140\n",
      "Epoch 147/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8878 - loss: 0.2499 - val_binary_accuracy: 0.8720 - val_loss: 0.3370\n",
      "Epoch 148/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8905 - loss: 0.2524 - val_binary_accuracy: 0.8720 - val_loss: 0.3301\n",
      "Epoch 149/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8864 - loss: 0.2637 - val_binary_accuracy: 0.8760 - val_loss: 0.3170\n",
      "Epoch 150/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8871 - loss: 0.2534 - val_binary_accuracy: 0.8680 - val_loss: 0.3272\n",
      "Epoch 151/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8911 - loss: 0.2580 - val_binary_accuracy: 0.8720 - val_loss: 0.3194\n",
      "Epoch 152/10000\n",
      "47/47 - 1s - 13ms/step - binary_accuracy: 0.8810 - loss: 0.2566 - val_binary_accuracy: 0.8560 - val_loss: 0.3726\n",
      "Epoch 153/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8905 - loss: 0.2507 - val_binary_accuracy: 0.8640 - val_loss: 0.3497\n",
      "Epoch 154/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8878 - loss: 0.2512 - val_binary_accuracy: 0.8680 - val_loss: 0.3294\n",
      "Epoch 155/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8979 - loss: 0.2445 - val_binary_accuracy: 0.8680 - val_loss: 0.3660\n",
      "Epoch 156/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8911 - loss: 0.2501 - val_binary_accuracy: 0.8720 - val_loss: 0.3472\n",
      "Epoch 157/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8952 - loss: 0.2466 - val_binary_accuracy: 0.8840 - val_loss: 0.3302\n",
      "Trained model saved to CNN_models/sdB_2025-10-30_model_2.keras\n",
      "Epoch 1/10000\n",
      "47/47 - 2s - 48ms/step - binary_accuracy: 0.5406 - loss: 0.6911 - val_binary_accuracy: 0.5200 - val_loss: 0.6932\n",
      "Epoch 2/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.5433 - loss: 0.6900 - val_binary_accuracy: 0.5200 - val_loss: 0.6929\n",
      "Epoch 3/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.5433 - loss: 0.6899 - val_binary_accuracy: 0.5200 - val_loss: 0.6925\n",
      "Epoch 4/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.5433 - loss: 0.6895 - val_binary_accuracy: 0.5200 - val_loss: 0.6936\n",
      "Epoch 5/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.5433 - loss: 0.6896 - val_binary_accuracy: 0.5200 - val_loss: 0.6931\n",
      "Epoch 6/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.5433 - loss: 0.6897 - val_binary_accuracy: 0.5200 - val_loss: 0.6924\n",
      "Epoch 7/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.5433 - loss: 0.6894 - val_binary_accuracy: 0.5200 - val_loss: 0.6937\n",
      "Epoch 8/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.5433 - loss: 0.6892 - val_binary_accuracy: 0.5200 - val_loss: 0.6915\n",
      "Epoch 9/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.5433 - loss: 0.6896 - val_binary_accuracy: 0.5200 - val_loss: 0.6926\n",
      "Epoch 10/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.5433 - loss: 0.6891 - val_binary_accuracy: 0.5200 - val_loss: 0.6934\n",
      "Epoch 11/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.5433 - loss: 0.6893 - val_binary_accuracy: 0.5200 - val_loss: 0.6910\n",
      "Epoch 12/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.5433 - loss: 0.6888 - val_binary_accuracy: 0.5200 - val_loss: 0.6922\n",
      "Epoch 13/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.5433 - loss: 0.6878 - val_binary_accuracy: 0.5200 - val_loss: 0.6911\n",
      "Epoch 14/10000\n",
      "47/47 - 0s - 10ms/step - binary_accuracy: 0.5433 - loss: 0.6861 - val_binary_accuracy: 0.5200 - val_loss: 0.6878\n",
      "Epoch 15/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.5433 - loss: 0.6827 - val_binary_accuracy: 0.5200 - val_loss: 0.6834\n",
      "Epoch 16/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.6685 - loss: 0.6379 - val_binary_accuracy: 0.6200 - val_loss: 0.6289\n",
      "Epoch 17/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.7909 - loss: 0.4824 - val_binary_accuracy: 0.8120 - val_loss: 0.4194\n",
      "Epoch 18/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8173 - loss: 0.4141 - val_binary_accuracy: 0.7600 - val_loss: 0.4508\n",
      "Epoch 19/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8011 - loss: 0.4421 - val_binary_accuracy: 0.8640 - val_loss: 0.3720\n",
      "Epoch 20/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8383 - loss: 0.3733 - val_binary_accuracy: 0.8520 - val_loss: 0.3479\n",
      "Epoch 21/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8512 - loss: 0.3591 - val_binary_accuracy: 0.8480 - val_loss: 0.3514\n",
      "Epoch 22/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8512 - loss: 0.3474 - val_binary_accuracy: 0.8720 - val_loss: 0.3448\n",
      "Epoch 23/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8498 - loss: 0.3489 - val_binary_accuracy: 0.8520 - val_loss: 0.3403\n",
      "Epoch 24/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8525 - loss: 0.3359 - val_binary_accuracy: 0.8640 - val_loss: 0.3282\n",
      "Epoch 25/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8356 - loss: 0.3581 - val_binary_accuracy: 0.8720 - val_loss: 0.3256\n",
      "Epoch 26/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8586 - loss: 0.3407 - val_binary_accuracy: 0.8400 - val_loss: 0.3687\n",
      "Epoch 27/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8586 - loss: 0.3387 - val_binary_accuracy: 0.8280 - val_loss: 0.3743\n",
      "Epoch 28/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8586 - loss: 0.3381 - val_binary_accuracy: 0.8400 - val_loss: 0.3687\n",
      "Epoch 29/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8484 - loss: 0.3492 - val_binary_accuracy: 0.8280 - val_loss: 0.3896\n",
      "Epoch 30/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8593 - loss: 0.3444 - val_binary_accuracy: 0.8560 - val_loss: 0.3406\n",
      "Epoch 31/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8566 - loss: 0.3319 - val_binary_accuracy: 0.8360 - val_loss: 0.3769\n",
      "Epoch 32/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8586 - loss: 0.3330 - val_binary_accuracy: 0.8680 - val_loss: 0.3251\n",
      "Epoch 33/10000\n",
      "47/47 - 1s - 13ms/step - binary_accuracy: 0.8701 - loss: 0.3264 - val_binary_accuracy: 0.8640 - val_loss: 0.3285\n",
      "Epoch 34/10000\n",
      "47/47 - 1s - 13ms/step - binary_accuracy: 0.8620 - loss: 0.3329 - val_binary_accuracy: 0.8720 - val_loss: 0.3198\n",
      "Epoch 35/10000\n",
      "47/47 - 0s - 10ms/step - binary_accuracy: 0.8674 - loss: 0.3198 - val_binary_accuracy: 0.8720 - val_loss: 0.3162\n",
      "Epoch 36/10000\n",
      "47/47 - 1s - 15ms/step - binary_accuracy: 0.8681 - loss: 0.3222 - val_binary_accuracy: 0.8720 - val_loss: 0.3229\n",
      "Epoch 37/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8654 - loss: 0.3260 - val_binary_accuracy: 0.8680 - val_loss: 0.3299\n",
      "Epoch 38/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8647 - loss: 0.3192 - val_binary_accuracy: 0.8560 - val_loss: 0.3462\n",
      "Epoch 39/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8478 - loss: 0.3434 - val_binary_accuracy: 0.8760 - val_loss: 0.3200\n",
      "Epoch 40/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8572 - loss: 0.3330 - val_binary_accuracy: 0.8760 - val_loss: 0.3183\n",
      "Epoch 41/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8748 - loss: 0.3160 - val_binary_accuracy: 0.8720 - val_loss: 0.3178\n",
      "Epoch 42/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8545 - loss: 0.3252 - val_binary_accuracy: 0.8760 - val_loss: 0.3167\n",
      "Epoch 43/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8579 - loss: 0.3287 - val_binary_accuracy: 0.8720 - val_loss: 0.3172\n",
      "Epoch 44/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8640 - loss: 0.3266 - val_binary_accuracy: 0.8720 - val_loss: 0.3376\n",
      "Epoch 45/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8471 - loss: 0.3416 - val_binary_accuracy: 0.8680 - val_loss: 0.3402\n",
      "Epoch 46/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8633 - loss: 0.3216 - val_binary_accuracy: 0.8680 - val_loss: 0.3158\n",
      "Epoch 47/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8660 - loss: 0.3303 - val_binary_accuracy: 0.8720 - val_loss: 0.3210\n",
      "Epoch 48/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8647 - loss: 0.3250 - val_binary_accuracy: 0.8560 - val_loss: 0.3666\n",
      "Epoch 49/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8599 - loss: 0.3320 - val_binary_accuracy: 0.8720 - val_loss: 0.3197\n",
      "Epoch 50/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8701 - loss: 0.3141 - val_binary_accuracy: 0.8720 - val_loss: 0.3164\n",
      "Epoch 51/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8579 - loss: 0.3299 - val_binary_accuracy: 0.8720 - val_loss: 0.3295\n",
      "Epoch 52/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8633 - loss: 0.3299 - val_binary_accuracy: 0.8760 - val_loss: 0.3217\n",
      "Epoch 53/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8599 - loss: 0.3198 - val_binary_accuracy: 0.8720 - val_loss: 0.3176\n",
      "Epoch 54/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8613 - loss: 0.3216 - val_binary_accuracy: 0.8560 - val_loss: 0.3578\n",
      "Epoch 55/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8566 - loss: 0.3409 - val_binary_accuracy: 0.8840 - val_loss: 0.3176\n",
      "Epoch 56/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8674 - loss: 0.3203 - val_binary_accuracy: 0.8680 - val_loss: 0.3303\n",
      "Epoch 57/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8714 - loss: 0.3113 - val_binary_accuracy: 0.8760 - val_loss: 0.3320\n",
      "Epoch 58/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8674 - loss: 0.3178 - val_binary_accuracy: 0.8720 - val_loss: 0.3202\n",
      "Epoch 59/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8613 - loss: 0.3359 - val_binary_accuracy: 0.8720 - val_loss: 0.3198\n",
      "Epoch 60/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8647 - loss: 0.3160 - val_binary_accuracy: 0.8720 - val_loss: 0.3179\n",
      "Epoch 61/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8748 - loss: 0.3128 - val_binary_accuracy: 0.8760 - val_loss: 0.3375\n",
      "Epoch 62/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8525 - loss: 0.3341 - val_binary_accuracy: 0.8800 - val_loss: 0.3180\n",
      "Epoch 63/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8667 - loss: 0.3189 - val_binary_accuracy: 0.8760 - val_loss: 0.3292\n",
      "Epoch 64/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8748 - loss: 0.3120 - val_binary_accuracy: 0.8720 - val_loss: 0.3202\n",
      "Epoch 65/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8687 - loss: 0.3147 - val_binary_accuracy: 0.8760 - val_loss: 0.3287\n",
      "Epoch 66/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8735 - loss: 0.3098 - val_binary_accuracy: 0.8800 - val_loss: 0.3172\n",
      "Epoch 67/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8694 - loss: 0.3162 - val_binary_accuracy: 0.8480 - val_loss: 0.3767\n",
      "Epoch 68/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8721 - loss: 0.3174 - val_binary_accuracy: 0.8600 - val_loss: 0.3577\n",
      "Epoch 69/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8694 - loss: 0.3150 - val_binary_accuracy: 0.8600 - val_loss: 0.3519\n",
      "Epoch 70/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8681 - loss: 0.3139 - val_binary_accuracy: 0.8760 - val_loss: 0.3276\n",
      "Epoch 71/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8721 - loss: 0.3146 - val_binary_accuracy: 0.8800 - val_loss: 0.3312\n",
      "Epoch 72/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8627 - loss: 0.3211 - val_binary_accuracy: 0.8760 - val_loss: 0.3363\n",
      "Epoch 73/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8735 - loss: 0.3104 - val_binary_accuracy: 0.8760 - val_loss: 0.3181\n",
      "Epoch 74/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8660 - loss: 0.3135 - val_binary_accuracy: 0.8360 - val_loss: 0.3961\n",
      "Epoch 75/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8701 - loss: 0.3102 - val_binary_accuracy: 0.8760 - val_loss: 0.3291\n",
      "Epoch 76/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8674 - loss: 0.3077 - val_binary_accuracy: 0.8720 - val_loss: 0.3253\n",
      "Epoch 77/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8667 - loss: 0.3164 - val_binary_accuracy: 0.8720 - val_loss: 0.3292\n",
      "Epoch 78/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8681 - loss: 0.3193 - val_binary_accuracy: 0.8640 - val_loss: 0.3231\n",
      "Epoch 79/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8762 - loss: 0.3069 - val_binary_accuracy: 0.8760 - val_loss: 0.3299\n",
      "Epoch 80/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8708 - loss: 0.3140 - val_binary_accuracy: 0.8760 - val_loss: 0.3219\n",
      "Epoch 81/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8681 - loss: 0.3138 - val_binary_accuracy: 0.8800 - val_loss: 0.3180\n",
      "Epoch 82/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8721 - loss: 0.3143 - val_binary_accuracy: 0.8800 - val_loss: 0.3183\n",
      "Epoch 83/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8674 - loss: 0.3116 - val_binary_accuracy: 0.8640 - val_loss: 0.3645\n",
      "Epoch 84/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8742 - loss: 0.3155 - val_binary_accuracy: 0.8720 - val_loss: 0.3256\n",
      "Epoch 85/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8687 - loss: 0.3151 - val_binary_accuracy: 0.8680 - val_loss: 0.3224\n",
      "Epoch 86/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8714 - loss: 0.3092 - val_binary_accuracy: 0.8520 - val_loss: 0.3719\n",
      "Epoch 87/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8701 - loss: 0.3190 - val_binary_accuracy: 0.8440 - val_loss: 0.3817\n",
      "Epoch 88/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8681 - loss: 0.3136 - val_binary_accuracy: 0.8720 - val_loss: 0.3386\n",
      "Epoch 89/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8694 - loss: 0.3084 - val_binary_accuracy: 0.8800 - val_loss: 0.3153\n",
      "Epoch 90/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8647 - loss: 0.3100 - val_binary_accuracy: 0.8640 - val_loss: 0.3165\n",
      "Epoch 91/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8755 - loss: 0.3072 - val_binary_accuracy: 0.8720 - val_loss: 0.3143\n",
      "Epoch 92/10000\n",
      "47/47 - 1s - 11ms/step - binary_accuracy: 0.8687 - loss: 0.3097 - val_binary_accuracy: 0.8760 - val_loss: 0.3160\n",
      "Epoch 93/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8687 - loss: 0.3068 - val_binary_accuracy: 0.8680 - val_loss: 0.3192\n",
      "Epoch 94/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8742 - loss: 0.3118 - val_binary_accuracy: 0.8720 - val_loss: 0.3212\n",
      "Epoch 95/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8545 - loss: 0.3302 - val_binary_accuracy: 0.8680 - val_loss: 0.3303\n",
      "Epoch 96/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8674 - loss: 0.3182 - val_binary_accuracy: 0.8720 - val_loss: 0.3174\n",
      "Epoch 97/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8505 - loss: 0.3468 - val_binary_accuracy: 0.8760 - val_loss: 0.3168\n",
      "Epoch 98/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8681 - loss: 0.3122 - val_binary_accuracy: 0.8800 - val_loss: 0.3173\n",
      "Epoch 99/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8674 - loss: 0.3165 - val_binary_accuracy: 0.8760 - val_loss: 0.3178\n",
      "Epoch 100/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8728 - loss: 0.3081 - val_binary_accuracy: 0.8760 - val_loss: 0.3194\n",
      "Epoch 101/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8687 - loss: 0.3060 - val_binary_accuracy: 0.8720 - val_loss: 0.3373\n",
      "Epoch 102/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8755 - loss: 0.3062 - val_binary_accuracy: 0.8800 - val_loss: 0.3167\n",
      "Epoch 103/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8708 - loss: 0.3004 - val_binary_accuracy: 0.8680 - val_loss: 0.3295\n",
      "Epoch 104/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8694 - loss: 0.3062 - val_binary_accuracy: 0.8760 - val_loss: 0.3159\n",
      "Epoch 105/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8748 - loss: 0.3006 - val_binary_accuracy: 0.8720 - val_loss: 0.3430\n",
      "Epoch 106/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8735 - loss: 0.3134 - val_binary_accuracy: 0.8680 - val_loss: 0.3249\n",
      "Epoch 107/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8681 - loss: 0.3095 - val_binary_accuracy: 0.8880 - val_loss: 0.3161\n",
      "Epoch 108/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8802 - loss: 0.2977 - val_binary_accuracy: 0.8800 - val_loss: 0.3229\n",
      "Epoch 109/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8769 - loss: 0.2962 - val_binary_accuracy: 0.8760 - val_loss: 0.3148\n",
      "Epoch 110/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8769 - loss: 0.2962 - val_binary_accuracy: 0.8800 - val_loss: 0.3170\n",
      "Epoch 111/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8728 - loss: 0.2978 - val_binary_accuracy: 0.8840 - val_loss: 0.3170\n",
      "Epoch 112/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8721 - loss: 0.3059 - val_binary_accuracy: 0.8760 - val_loss: 0.3248\n",
      "Epoch 113/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8559 - loss: 0.3229 - val_binary_accuracy: 0.8760 - val_loss: 0.3174\n",
      "Epoch 114/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8755 - loss: 0.2974 - val_binary_accuracy: 0.8800 - val_loss: 0.3208\n",
      "Epoch 115/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8748 - loss: 0.2988 - val_binary_accuracy: 0.8600 - val_loss: 0.3595\n",
      "Epoch 116/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8762 - loss: 0.2991 - val_binary_accuracy: 0.8720 - val_loss: 0.3345\n",
      "Epoch 117/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8728 - loss: 0.2959 - val_binary_accuracy: 0.8760 - val_loss: 0.3398\n",
      "Epoch 118/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8762 - loss: 0.3044 - val_binary_accuracy: 0.8760 - val_loss: 0.3348\n",
      "Epoch 119/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8735 - loss: 0.2946 - val_binary_accuracy: 0.8800 - val_loss: 0.3227\n",
      "Epoch 120/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8742 - loss: 0.2986 - val_binary_accuracy: 0.8840 - val_loss: 0.3217\n",
      "Epoch 121/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8755 - loss: 0.2933 - val_binary_accuracy: 0.8720 - val_loss: 0.3164\n",
      "Epoch 122/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8742 - loss: 0.2966 - val_binary_accuracy: 0.8720 - val_loss: 0.3411\n",
      "Epoch 123/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8694 - loss: 0.3108 - val_binary_accuracy: 0.8760 - val_loss: 0.3182\n",
      "Epoch 124/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8742 - loss: 0.2925 - val_binary_accuracy: 0.8680 - val_loss: 0.3299\n",
      "Epoch 125/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8660 - loss: 0.3017 - val_binary_accuracy: 0.8600 - val_loss: 0.3625\n",
      "Epoch 126/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8674 - loss: 0.3024 - val_binary_accuracy: 0.8840 - val_loss: 0.3116\n",
      "Epoch 127/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8714 - loss: 0.2985 - val_binary_accuracy: 0.8840 - val_loss: 0.3117\n",
      "Epoch 128/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8769 - loss: 0.2956 - val_binary_accuracy: 0.8760 - val_loss: 0.3098\n",
      "Epoch 129/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8769 - loss: 0.2958 - val_binary_accuracy: 0.8760 - val_loss: 0.3215\n",
      "Epoch 130/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8762 - loss: 0.2988 - val_binary_accuracy: 0.8720 - val_loss: 0.3130\n",
      "Epoch 131/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8742 - loss: 0.2998 - val_binary_accuracy: 0.8720 - val_loss: 0.3121\n",
      "Epoch 132/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8735 - loss: 0.2960 - val_binary_accuracy: 0.8840 - val_loss: 0.3179\n",
      "Epoch 133/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8802 - loss: 0.2933 - val_binary_accuracy: 0.8800 - val_loss: 0.3103\n",
      "Epoch 134/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8694 - loss: 0.2930 - val_binary_accuracy: 0.8840 - val_loss: 0.3221\n",
      "Epoch 135/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8735 - loss: 0.2918 - val_binary_accuracy: 0.8840 - val_loss: 0.3203\n",
      "Epoch 136/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8782 - loss: 0.2880 - val_binary_accuracy: 0.8800 - val_loss: 0.3096\n",
      "Epoch 137/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8701 - loss: 0.2925 - val_binary_accuracy: 0.8720 - val_loss: 0.3380\n",
      "Epoch 138/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8816 - loss: 0.2933 - val_binary_accuracy: 0.8840 - val_loss: 0.3181\n",
      "Epoch 139/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8789 - loss: 0.2874 - val_binary_accuracy: 0.8800 - val_loss: 0.3087\n",
      "Epoch 140/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8775 - loss: 0.2871 - val_binary_accuracy: 0.8720 - val_loss: 0.3076\n",
      "Epoch 141/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8796 - loss: 0.2848 - val_binary_accuracy: 0.8680 - val_loss: 0.3110\n",
      "Epoch 142/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8714 - loss: 0.2982 - val_binary_accuracy: 0.8720 - val_loss: 0.3219\n",
      "Epoch 143/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8735 - loss: 0.2922 - val_binary_accuracy: 0.8880 - val_loss: 0.3219\n",
      "Epoch 144/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8829 - loss: 0.2901 - val_binary_accuracy: 0.8840 - val_loss: 0.3231\n",
      "Epoch 145/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8721 - loss: 0.2873 - val_binary_accuracy: 0.8400 - val_loss: 0.3750\n",
      "Epoch 146/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8687 - loss: 0.3060 - val_binary_accuracy: 0.8800 - val_loss: 0.3126\n",
      "Epoch 147/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8748 - loss: 0.2941 - val_binary_accuracy: 0.8840 - val_loss: 0.3163\n",
      "Epoch 148/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8701 - loss: 0.3058 - val_binary_accuracy: 0.8840 - val_loss: 0.3191\n",
      "Epoch 149/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8850 - loss: 0.2839 - val_binary_accuracy: 0.8840 - val_loss: 0.3139\n",
      "Epoch 150/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8742 - loss: 0.2883 - val_binary_accuracy: 0.8840 - val_loss: 0.3117\n",
      "Trained model saved to CNN_models/sdB_2025-10-30_model_3.keras\n",
      "Epoch 1/10000\n",
      "46/46 - 2s - 44ms/step - binary_accuracy: 0.5421 - loss: 0.6911 - val_binary_accuracy: 0.5320 - val_loss: 0.6912\n",
      "Epoch 2/10000\n",
      "46/46 - 0s - 8ms/step - binary_accuracy: 0.5421 - loss: 0.6904 - val_binary_accuracy: 0.5320 - val_loss: 0.6912\n",
      "Epoch 3/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.5421 - loss: 0.6904 - val_binary_accuracy: 0.5320 - val_loss: 0.6914\n",
      "Epoch 4/10000\n",
      "46/46 - 0s - 8ms/step - binary_accuracy: 0.5421 - loss: 0.6900 - val_binary_accuracy: 0.5320 - val_loss: 0.6910\n",
      "Epoch 5/10000\n",
      "46/46 - 0s - 8ms/step - binary_accuracy: 0.5421 - loss: 0.6903 - val_binary_accuracy: 0.5320 - val_loss: 0.6908\n",
      "Epoch 6/10000\n",
      "46/46 - 0s - 8ms/step - binary_accuracy: 0.5421 - loss: 0.6898 - val_binary_accuracy: 0.5320 - val_loss: 0.6905\n",
      "Epoch 7/10000\n",
      "46/46 - 0s - 8ms/step - binary_accuracy: 0.5421 - loss: 0.6894 - val_binary_accuracy: 0.5320 - val_loss: 0.6903\n",
      "Epoch 8/10000\n",
      "46/46 - 0s - 8ms/step - binary_accuracy: 0.5421 - loss: 0.6891 - val_binary_accuracy: 0.5320 - val_loss: 0.6896\n",
      "Epoch 9/10000\n",
      "46/46 - 0s - 8ms/step - binary_accuracy: 0.5421 - loss: 0.6878 - val_binary_accuracy: 0.5320 - val_loss: 0.6881\n",
      "Epoch 10/10000\n",
      "46/46 - 0s - 8ms/step - binary_accuracy: 0.5421 - loss: 0.6851 - val_binary_accuracy: 0.5320 - val_loss: 0.6829\n",
      "Epoch 11/10000\n",
      "46/46 - 0s - 8ms/step - binary_accuracy: 0.5713 - loss: 0.6833 - val_binary_accuracy: 0.5440 - val_loss: 0.6826\n",
      "Epoch 12/10000\n",
      "46/46 - 0s - 8ms/step - binary_accuracy: 0.6101 - loss: 0.6724 - val_binary_accuracy: 0.5320 - val_loss: 0.6713\n",
      "Epoch 13/10000\n",
      "46/46 - 0s - 8ms/step - binary_accuracy: 0.6902 - loss: 0.6265 - val_binary_accuracy: 0.7520 - val_loss: 0.5703\n",
      "Epoch 14/10000\n",
      "46/46 - 0s - 8ms/step - binary_accuracy: 0.7588 - loss: 0.5345 - val_binary_accuracy: 0.8000 - val_loss: 0.4984\n",
      "Epoch 15/10000\n",
      "46/46 - 0s - 8ms/step - binary_accuracy: 0.8166 - loss: 0.4301 - val_binary_accuracy: 0.8320 - val_loss: 0.3984\n",
      "Epoch 16/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8397 - loss: 0.3901 - val_binary_accuracy: 0.8000 - val_loss: 0.4382\n",
      "Epoch 17/10000\n",
      "46/46 - 0s - 8ms/step - binary_accuracy: 0.8390 - loss: 0.3655 - val_binary_accuracy: 0.8280 - val_loss: 0.3963\n",
      "Epoch 18/10000\n",
      "46/46 - 0s - 8ms/step - binary_accuracy: 0.8485 - loss: 0.3430 - val_binary_accuracy: 0.8640 - val_loss: 0.3591\n",
      "Epoch 19/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8512 - loss: 0.3431 - val_binary_accuracy: 0.8440 - val_loss: 0.3622\n",
      "Epoch 20/10000\n",
      "46/46 - 0s - 8ms/step - binary_accuracy: 0.8539 - loss: 0.3371 - val_binary_accuracy: 0.8560 - val_loss: 0.3533\n",
      "Epoch 21/10000\n",
      "46/46 - 0s - 8ms/step - binary_accuracy: 0.8526 - loss: 0.3322 - val_binary_accuracy: 0.8600 - val_loss: 0.3532\n",
      "Epoch 22/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8573 - loss: 0.3289 - val_binary_accuracy: 0.8520 - val_loss: 0.3639\n",
      "Epoch 23/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8668 - loss: 0.3284 - val_binary_accuracy: 0.8600 - val_loss: 0.3938\n",
      "Epoch 24/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8628 - loss: 0.3175 - val_binary_accuracy: 0.8520 - val_loss: 0.3719\n",
      "Epoch 25/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8424 - loss: 0.3461 - val_binary_accuracy: 0.8640 - val_loss: 0.3653\n",
      "Epoch 26/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8573 - loss: 0.3221 - val_binary_accuracy: 0.8400 - val_loss: 0.3806\n",
      "Epoch 27/10000\n",
      "46/46 - 0s - 8ms/step - binary_accuracy: 0.8580 - loss: 0.3269 - val_binary_accuracy: 0.8560 - val_loss: 0.3541\n",
      "Epoch 28/10000\n",
      "46/46 - 0s - 9ms/step - binary_accuracy: 0.8648 - loss: 0.3374 - val_binary_accuracy: 0.8640 - val_loss: 0.3613\n",
      "Epoch 29/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8641 - loss: 0.3196 - val_binary_accuracy: 0.8480 - val_loss: 0.3560\n",
      "Epoch 30/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8675 - loss: 0.3164 - val_binary_accuracy: 0.8320 - val_loss: 0.3838\n",
      "Epoch 31/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8553 - loss: 0.3408 - val_binary_accuracy: 0.8280 - val_loss: 0.3575\n",
      "Epoch 32/10000\n",
      "46/46 - 0s - 10ms/step - binary_accuracy: 0.8635 - loss: 0.3205 - val_binary_accuracy: 0.8640 - val_loss: 0.3512\n",
      "Epoch 33/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8641 - loss: 0.3126 - val_binary_accuracy: 0.8560 - val_loss: 0.3570\n",
      "Epoch 34/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8641 - loss: 0.3136 - val_binary_accuracy: 0.8440 - val_loss: 0.3566\n",
      "Epoch 35/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8505 - loss: 0.3453 - val_binary_accuracy: 0.8640 - val_loss: 0.3589\n",
      "Epoch 36/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8573 - loss: 0.3291 - val_binary_accuracy: 0.8600 - val_loss: 0.3522\n",
      "Epoch 37/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8628 - loss: 0.3189 - val_binary_accuracy: 0.8320 - val_loss: 0.3754\n",
      "Epoch 38/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8655 - loss: 0.3138 - val_binary_accuracy: 0.8560 - val_loss: 0.3578\n",
      "Epoch 39/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8716 - loss: 0.3110 - val_binary_accuracy: 0.8240 - val_loss: 0.3892\n",
      "Epoch 40/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8689 - loss: 0.3124 - val_binary_accuracy: 0.8560 - val_loss: 0.3614\n",
      "Epoch 41/10000\n",
      "46/46 - 0s - 8ms/step - binary_accuracy: 0.8628 - loss: 0.3204 - val_binary_accuracy: 0.8600 - val_loss: 0.3573\n",
      "Epoch 42/10000\n",
      "46/46 - 0s - 9ms/step - binary_accuracy: 0.8635 - loss: 0.3302 - val_binary_accuracy: 0.8640 - val_loss: 0.3497\n",
      "Epoch 43/10000\n",
      "46/46 - 0s - 8ms/step - binary_accuracy: 0.8662 - loss: 0.3304 - val_binary_accuracy: 0.8400 - val_loss: 0.3657\n",
      "Epoch 44/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8716 - loss: 0.3154 - val_binary_accuracy: 0.8320 - val_loss: 0.3649\n",
      "Epoch 45/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8655 - loss: 0.3207 - val_binary_accuracy: 0.8360 - val_loss: 0.3558\n",
      "Epoch 46/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8675 - loss: 0.3084 - val_binary_accuracy: 0.8280 - val_loss: 0.3659\n",
      "Epoch 47/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8716 - loss: 0.3065 - val_binary_accuracy: 0.8560 - val_loss: 0.3565\n",
      "Epoch 48/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8682 - loss: 0.3078 - val_binary_accuracy: 0.8280 - val_loss: 0.3674\n",
      "Epoch 49/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8675 - loss: 0.3173 - val_binary_accuracy: 0.8560 - val_loss: 0.3596\n",
      "Epoch 50/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8662 - loss: 0.3108 - val_binary_accuracy: 0.8640 - val_loss: 0.3704\n",
      "Epoch 51/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8675 - loss: 0.3176 - val_binary_accuracy: 0.8640 - val_loss: 0.3634\n",
      "Epoch 52/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8668 - loss: 0.3099 - val_binary_accuracy: 0.8280 - val_loss: 0.3699\n",
      "Epoch 53/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8648 - loss: 0.3293 - val_binary_accuracy: 0.8480 - val_loss: 0.4247\n",
      "Epoch 54/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8648 - loss: 0.3233 - val_binary_accuracy: 0.8480 - val_loss: 0.3556\n",
      "Epoch 55/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8580 - loss: 0.3159 - val_binary_accuracy: 0.8320 - val_loss: 0.3629\n",
      "Epoch 56/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8641 - loss: 0.3180 - val_binary_accuracy: 0.8680 - val_loss: 0.3611\n",
      "Epoch 57/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8723 - loss: 0.3049 - val_binary_accuracy: 0.8400 - val_loss: 0.3598\n",
      "Epoch 58/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8648 - loss: 0.3085 - val_binary_accuracy: 0.8360 - val_loss: 0.3617\n",
      "Epoch 59/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8628 - loss: 0.3163 - val_binary_accuracy: 0.8360 - val_loss: 0.3612\n",
      "Epoch 60/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8682 - loss: 0.3112 - val_binary_accuracy: 0.8600 - val_loss: 0.3580\n",
      "Epoch 61/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8628 - loss: 0.3111 - val_binary_accuracy: 0.8480 - val_loss: 0.3571\n",
      "Epoch 62/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8716 - loss: 0.3055 - val_binary_accuracy: 0.8600 - val_loss: 0.3603\n",
      "Epoch 63/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8682 - loss: 0.3175 - val_binary_accuracy: 0.8480 - val_loss: 0.3649\n",
      "Epoch 64/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8770 - loss: 0.3004 - val_binary_accuracy: 0.8520 - val_loss: 0.3582\n",
      "Epoch 65/10000\n",
      "46/46 - 1s - 14ms/step - binary_accuracy: 0.8736 - loss: 0.3061 - val_binary_accuracy: 0.8640 - val_loss: 0.3584\n",
      "Epoch 66/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8675 - loss: 0.3083 - val_binary_accuracy: 0.8440 - val_loss: 0.3619\n",
      "Epoch 67/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8702 - loss: 0.3046 - val_binary_accuracy: 0.8600 - val_loss: 0.3624\n",
      "Epoch 68/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8750 - loss: 0.3072 - val_binary_accuracy: 0.8400 - val_loss: 0.3729\n",
      "Epoch 69/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8689 - loss: 0.3136 - val_binary_accuracy: 0.8360 - val_loss: 0.3640\n",
      "Epoch 70/10000\n",
      "46/46 - 0s - 8ms/step - binary_accuracy: 0.8702 - loss: 0.3072 - val_binary_accuracy: 0.8280 - val_loss: 0.3664\n",
      "Epoch 71/10000\n",
      "46/46 - 0s - 8ms/step - binary_accuracy: 0.8764 - loss: 0.3001 - val_binary_accuracy: 0.8400 - val_loss: 0.3778\n",
      "Epoch 72/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8689 - loss: 0.3028 - val_binary_accuracy: 0.8480 - val_loss: 0.3617\n",
      "Epoch 73/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8764 - loss: 0.3013 - val_binary_accuracy: 0.8360 - val_loss: 0.3740\n",
      "Epoch 74/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8716 - loss: 0.3065 - val_binary_accuracy: 0.8320 - val_loss: 0.3655\n",
      "Epoch 75/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8709 - loss: 0.2988 - val_binary_accuracy: 0.8600 - val_loss: 0.3567\n",
      "Epoch 76/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8709 - loss: 0.3041 - val_binary_accuracy: 0.8360 - val_loss: 0.3847\n",
      "Epoch 77/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8702 - loss: 0.3016 - val_binary_accuracy: 0.8200 - val_loss: 0.3998\n",
      "Epoch 78/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8757 - loss: 0.3088 - val_binary_accuracy: 0.8440 - val_loss: 0.3680\n",
      "Epoch 79/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8601 - loss: 0.3154 - val_binary_accuracy: 0.8440 - val_loss: 0.3619\n",
      "Epoch 80/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8736 - loss: 0.3018 - val_binary_accuracy: 0.8320 - val_loss: 0.3673\n",
      "Epoch 81/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8635 - loss: 0.3114 - val_binary_accuracy: 0.8360 - val_loss: 0.3795\n",
      "Epoch 82/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8723 - loss: 0.3107 - val_binary_accuracy: 0.8640 - val_loss: 0.3589\n",
      "Epoch 83/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8675 - loss: 0.3121 - val_binary_accuracy: 0.8440 - val_loss: 0.3599\n",
      "Epoch 84/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8757 - loss: 0.2953 - val_binary_accuracy: 0.8360 - val_loss: 0.3790\n",
      "Epoch 85/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8702 - loss: 0.3014 - val_binary_accuracy: 0.8480 - val_loss: 0.3614\n",
      "Epoch 86/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8736 - loss: 0.3018 - val_binary_accuracy: 0.8480 - val_loss: 0.3638\n",
      "Epoch 87/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8662 - loss: 0.3012 - val_binary_accuracy: 0.8320 - val_loss: 0.3661\n",
      "Epoch 88/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8587 - loss: 0.3147 - val_binary_accuracy: 0.8280 - val_loss: 0.3851\n",
      "Epoch 89/10000\n",
      "46/46 - 0s - 8ms/step - binary_accuracy: 0.8750 - loss: 0.2974 - val_binary_accuracy: 0.8520 - val_loss: 0.3566\n",
      "Epoch 90/10000\n",
      "46/46 - 0s - 8ms/step - binary_accuracy: 0.8750 - loss: 0.2974 - val_binary_accuracy: 0.8520 - val_loss: 0.3586\n",
      "Epoch 91/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8709 - loss: 0.2985 - val_binary_accuracy: 0.8320 - val_loss: 0.3686\n",
      "Epoch 92/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8668 - loss: 0.3020 - val_binary_accuracy: 0.8640 - val_loss: 0.3560\n",
      "Epoch 93/10000\n",
      "46/46 - 0s - 9ms/step - binary_accuracy: 0.8709 - loss: 0.3050 - val_binary_accuracy: 0.8680 - val_loss: 0.3666\n",
      "Epoch 94/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8764 - loss: 0.2967 - val_binary_accuracy: 0.8400 - val_loss: 0.3593\n",
      "Epoch 95/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8709 - loss: 0.3072 - val_binary_accuracy: 0.8640 - val_loss: 0.3629\n",
      "Epoch 96/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8764 - loss: 0.2941 - val_binary_accuracy: 0.8520 - val_loss: 0.3601\n",
      "Epoch 97/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8777 - loss: 0.3002 - val_binary_accuracy: 0.8600 - val_loss: 0.3802\n",
      "Epoch 98/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8655 - loss: 0.3091 - val_binary_accuracy: 0.8400 - val_loss: 0.3687\n",
      "Epoch 99/10000\n",
      "46/46 - 0s - 8ms/step - binary_accuracy: 0.8811 - loss: 0.2937 - val_binary_accuracy: 0.8320 - val_loss: 0.3698\n",
      "Epoch 100/10000\n",
      "46/46 - 0s - 8ms/step - binary_accuracy: 0.8804 - loss: 0.2914 - val_binary_accuracy: 0.8680 - val_loss: 0.3636\n",
      "Epoch 101/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8750 - loss: 0.2915 - val_binary_accuracy: 0.8640 - val_loss: 0.3667\n",
      "Epoch 102/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8736 - loss: 0.2917 - val_binary_accuracy: 0.8560 - val_loss: 0.3585\n",
      "Epoch 103/10000\n",
      "46/46 - 0s - 8ms/step - binary_accuracy: 0.8709 - loss: 0.3053 - val_binary_accuracy: 0.8560 - val_loss: 0.3545\n",
      "Epoch 104/10000\n",
      "46/46 - 0s - 8ms/step - binary_accuracy: 0.8730 - loss: 0.3040 - val_binary_accuracy: 0.8640 - val_loss: 0.3582\n",
      "Epoch 105/10000\n",
      "46/46 - 0s - 8ms/step - binary_accuracy: 0.8757 - loss: 0.2946 - val_binary_accuracy: 0.8680 - val_loss: 0.3624\n",
      "Epoch 106/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8641 - loss: 0.3009 - val_binary_accuracy: 0.8600 - val_loss: 0.3565\n",
      "Epoch 107/10000\n",
      "46/46 - 0s - 8ms/step - binary_accuracy: 0.8777 - loss: 0.2897 - val_binary_accuracy: 0.8680 - val_loss: 0.3767\n",
      "Epoch 108/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8757 - loss: 0.2890 - val_binary_accuracy: 0.8400 - val_loss: 0.3689\n",
      "Epoch 109/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8757 - loss: 0.3002 - val_binary_accuracy: 0.8560 - val_loss: 0.3732\n",
      "Epoch 110/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8757 - loss: 0.3005 - val_binary_accuracy: 0.8440 - val_loss: 0.3523\n",
      "Epoch 111/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8770 - loss: 0.2932 - val_binary_accuracy: 0.8320 - val_loss: 0.3673\n",
      "Epoch 112/10000\n",
      "46/46 - 0s - 8ms/step - binary_accuracy: 0.8804 - loss: 0.2922 - val_binary_accuracy: 0.8360 - val_loss: 0.3726\n",
      "Epoch 113/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8757 - loss: 0.2886 - val_binary_accuracy: 0.8360 - val_loss: 0.3729\n",
      "Epoch 114/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8750 - loss: 0.2977 - val_binary_accuracy: 0.8520 - val_loss: 0.3571\n",
      "Epoch 115/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8750 - loss: 0.2916 - val_binary_accuracy: 0.8640 - val_loss: 0.3684\n",
      "Epoch 116/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8791 - loss: 0.2840 - val_binary_accuracy: 0.8600 - val_loss: 0.3576\n",
      "Epoch 117/10000\n",
      "46/46 - 0s - 8ms/step - binary_accuracy: 0.8777 - loss: 0.2866 - val_binary_accuracy: 0.8560 - val_loss: 0.3905\n",
      "Epoch 118/10000\n",
      "46/46 - 0s - 8ms/step - binary_accuracy: 0.8798 - loss: 0.2917 - val_binary_accuracy: 0.8480 - val_loss: 0.3620\n",
      "Epoch 119/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8791 - loss: 0.2842 - val_binary_accuracy: 0.8520 - val_loss: 0.3600\n",
      "Epoch 120/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8770 - loss: 0.2872 - val_binary_accuracy: 0.8480 - val_loss: 0.3556\n",
      "Epoch 121/10000\n",
      "46/46 - 1s - 14ms/step - binary_accuracy: 0.8798 - loss: 0.2859 - val_binary_accuracy: 0.8520 - val_loss: 0.3593\n",
      "Epoch 122/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8750 - loss: 0.2885 - val_binary_accuracy: 0.8480 - val_loss: 0.3586\n",
      "Epoch 123/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8736 - loss: 0.2868 - val_binary_accuracy: 0.8360 - val_loss: 0.3641\n",
      "Epoch 124/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8716 - loss: 0.2877 - val_binary_accuracy: 0.8520 - val_loss: 0.3575\n",
      "Epoch 125/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8757 - loss: 0.2919 - val_binary_accuracy: 0.8560 - val_loss: 0.3518\n",
      "Epoch 126/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8750 - loss: 0.2826 - val_binary_accuracy: 0.8640 - val_loss: 0.3595\n",
      "Epoch 127/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8865 - loss: 0.2818 - val_binary_accuracy: 0.8440 - val_loss: 0.3599\n",
      "Epoch 128/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8798 - loss: 0.2878 - val_binary_accuracy: 0.8360 - val_loss: 0.3821\n",
      "Epoch 129/10000\n",
      "46/46 - 0s - 8ms/step - binary_accuracy: 0.8736 - loss: 0.2981 - val_binary_accuracy: 0.8680 - val_loss: 0.3492\n",
      "Epoch 130/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8777 - loss: 0.2876 - val_binary_accuracy: 0.8640 - val_loss: 0.3585\n",
      "Epoch 131/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8825 - loss: 0.2830 - val_binary_accuracy: 0.8320 - val_loss: 0.3895\n",
      "Epoch 132/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8784 - loss: 0.2860 - val_binary_accuracy: 0.8680 - val_loss: 0.3509\n",
      "Epoch 133/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8832 - loss: 0.2845 - val_binary_accuracy: 0.8360 - val_loss: 0.3665\n",
      "Epoch 134/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8838 - loss: 0.2839 - val_binary_accuracy: 0.8600 - val_loss: 0.4173\n",
      "Epoch 135/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8723 - loss: 0.2928 - val_binary_accuracy: 0.8480 - val_loss: 0.3645\n",
      "Epoch 136/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8757 - loss: 0.2848 - val_binary_accuracy: 0.8520 - val_loss: 0.3557\n",
      "Epoch 137/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8832 - loss: 0.2763 - val_binary_accuracy: 0.8480 - val_loss: 0.3596\n",
      "Epoch 138/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8764 - loss: 0.2812 - val_binary_accuracy: 0.8400 - val_loss: 0.3757\n",
      "Epoch 139/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8852 - loss: 0.2828 - val_binary_accuracy: 0.8560 - val_loss: 0.3538\n",
      "Epoch 140/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8879 - loss: 0.2768 - val_binary_accuracy: 0.8360 - val_loss: 0.3683\n",
      "Epoch 141/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8736 - loss: 0.2899 - val_binary_accuracy: 0.8360 - val_loss: 0.3658\n",
      "Epoch 142/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8764 - loss: 0.2847 - val_binary_accuracy: 0.8360 - val_loss: 0.3620\n",
      "Epoch 143/10000\n",
      "46/46 - 0s - 8ms/step - binary_accuracy: 0.8811 - loss: 0.2761 - val_binary_accuracy: 0.8600 - val_loss: 0.3485\n",
      "Epoch 144/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8811 - loss: 0.2807 - val_binary_accuracy: 0.8320 - val_loss: 0.3609\n",
      "Epoch 145/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8723 - loss: 0.2878 - val_binary_accuracy: 0.8600 - val_loss: 0.3650\n",
      "Epoch 146/10000\n",
      "46/46 - 0s - 8ms/step - binary_accuracy: 0.8845 - loss: 0.2767 - val_binary_accuracy: 0.8600 - val_loss: 0.3532\n",
      "Epoch 147/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8879 - loss: 0.2752 - val_binary_accuracy: 0.8360 - val_loss: 0.3879\n",
      "Epoch 148/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8736 - loss: 0.2825 - val_binary_accuracy: 0.8480 - val_loss: 0.3579\n",
      "Epoch 149/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8852 - loss: 0.2734 - val_binary_accuracy: 0.8720 - val_loss: 0.3605\n",
      "Epoch 150/10000\n",
      "46/46 - 0s - 7ms/step - binary_accuracy: 0.8872 - loss: 0.2779 - val_binary_accuracy: 0.8360 - val_loss: 0.3775\n",
      "Trained model saved to CNN_models/sdB_2025-10-30_model_4.keras\n",
      "Epoch 1/10000\n",
      "47/47 - 2s - 43ms/step - binary_accuracy: 0.5355 - loss: 0.6918 - val_binary_accuracy: 0.5600 - val_loss: 0.6881\n",
      "Epoch 2/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.5355 - loss: 0.6914 - val_binary_accuracy: 0.5600 - val_loss: 0.6873\n",
      "Epoch 3/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.5355 - loss: 0.6909 - val_binary_accuracy: 0.5600 - val_loss: 0.6874\n",
      "Epoch 4/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.5355 - loss: 0.6913 - val_binary_accuracy: 0.5600 - val_loss: 0.6881\n",
      "Epoch 5/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.5355 - loss: 0.6909 - val_binary_accuracy: 0.5600 - val_loss: 0.6865\n",
      "Epoch 6/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.5355 - loss: 0.6909 - val_binary_accuracy: 0.5600 - val_loss: 0.6868\n",
      "Epoch 7/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.5355 - loss: 0.6907 - val_binary_accuracy: 0.5600 - val_loss: 0.6878\n",
      "Epoch 8/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.5355 - loss: 0.6908 - val_binary_accuracy: 0.5600 - val_loss: 0.6880\n",
      "Epoch 9/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.5355 - loss: 0.6904 - val_binary_accuracy: 0.5600 - val_loss: 0.6855\n",
      "Epoch 10/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.5355 - loss: 0.6903 - val_binary_accuracy: 0.5600 - val_loss: 0.6848\n",
      "Epoch 11/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.5355 - loss: 0.6894 - val_binary_accuracy: 0.5600 - val_loss: 0.6863\n",
      "Epoch 12/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.5490 - loss: 0.6876 - val_binary_accuracy: 0.5600 - val_loss: 0.6807\n",
      "Epoch 13/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.5517 - loss: 0.6867 - val_binary_accuracy: 0.5600 - val_loss: 0.6775\n",
      "Epoch 14/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.5761 - loss: 0.6762 - val_binary_accuracy: 0.6160 - val_loss: 0.6481\n",
      "Epoch 15/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.7018 - loss: 0.6159 - val_binary_accuracy: 0.8760 - val_loss: 0.5064\n",
      "Epoch 16/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.7823 - loss: 0.5105 - val_binary_accuracy: 0.8760 - val_loss: 0.3728\n",
      "Epoch 17/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.7978 - loss: 0.4549 - val_binary_accuracy: 0.8920 - val_loss: 0.3407\n",
      "Epoch 18/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8492 - loss: 0.3781 - val_binary_accuracy: 0.8760 - val_loss: 0.3005\n",
      "Epoch 19/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8445 - loss: 0.3777 - val_binary_accuracy: 0.8880 - val_loss: 0.2886\n",
      "Epoch 20/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8411 - loss: 0.3802 - val_binary_accuracy: 0.8760 - val_loss: 0.2937\n",
      "Epoch 21/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8540 - loss: 0.3535 - val_binary_accuracy: 0.8800 - val_loss: 0.2952\n",
      "Epoch 22/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8526 - loss: 0.3459 - val_binary_accuracy: 0.8720 - val_loss: 0.2838\n",
      "Epoch 23/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8506 - loss: 0.3531 - val_binary_accuracy: 0.8320 - val_loss: 0.3524\n",
      "Epoch 24/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8580 - loss: 0.3426 - val_binary_accuracy: 0.8840 - val_loss: 0.2821\n",
      "Epoch 25/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8553 - loss: 0.3393 - val_binary_accuracy: 0.8840 - val_loss: 0.2771\n",
      "Epoch 26/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8648 - loss: 0.3305 - val_binary_accuracy: 0.8800 - val_loss: 0.2868\n",
      "Epoch 27/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8540 - loss: 0.3526 - val_binary_accuracy: 0.8240 - val_loss: 0.3697\n",
      "Epoch 28/10000\n",
      "47/47 - 1s - 16ms/step - binary_accuracy: 0.8526 - loss: 0.3560 - val_binary_accuracy: 0.8800 - val_loss: 0.2880\n",
      "Epoch 29/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8627 - loss: 0.3253 - val_binary_accuracy: 0.8640 - val_loss: 0.2854\n",
      "Epoch 30/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8614 - loss: 0.3262 - val_binary_accuracy: 0.8640 - val_loss: 0.3012\n",
      "Epoch 31/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8594 - loss: 0.3350 - val_binary_accuracy: 0.8640 - val_loss: 0.3142\n",
      "Epoch 32/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8648 - loss: 0.3357 - val_binary_accuracy: 0.8640 - val_loss: 0.2844\n",
      "Epoch 33/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8736 - loss: 0.3200 - val_binary_accuracy: 0.8640 - val_loss: 0.3022\n",
      "Epoch 34/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8567 - loss: 0.3420 - val_binary_accuracy: 0.8680 - val_loss: 0.3519\n",
      "Epoch 35/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8661 - loss: 0.3292 - val_binary_accuracy: 0.8760 - val_loss: 0.2900\n",
      "Epoch 36/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8634 - loss: 0.3349 - val_binary_accuracy: 0.8640 - val_loss: 0.2815\n",
      "Epoch 37/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8580 - loss: 0.3390 - val_binary_accuracy: 0.8720 - val_loss: 0.2956\n",
      "Epoch 38/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8729 - loss: 0.3281 - val_binary_accuracy: 0.8640 - val_loss: 0.2860\n",
      "Epoch 39/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8715 - loss: 0.3179 - val_binary_accuracy: 0.8720 - val_loss: 0.2819\n",
      "Epoch 40/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8702 - loss: 0.3185 - val_binary_accuracy: 0.8800 - val_loss: 0.2862\n",
      "Epoch 41/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8614 - loss: 0.3300 - val_binary_accuracy: 0.8720 - val_loss: 0.2818\n",
      "Epoch 42/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8567 - loss: 0.3378 - val_binary_accuracy: 0.8800 - val_loss: 0.2875\n",
      "Epoch 43/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8715 - loss: 0.3170 - val_binary_accuracy: 0.8640 - val_loss: 0.2885\n",
      "Epoch 44/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8722 - loss: 0.3158 - val_binary_accuracy: 0.8760 - val_loss: 0.2811\n",
      "Epoch 45/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8688 - loss: 0.3169 - val_binary_accuracy: 0.8760 - val_loss: 0.2805\n",
      "Epoch 46/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8594 - loss: 0.3332 - val_binary_accuracy: 0.8640 - val_loss: 0.2869\n",
      "Epoch 47/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8648 - loss: 0.3171 - val_binary_accuracy: 0.8640 - val_loss: 0.2927\n",
      "Epoch 48/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8722 - loss: 0.3112 - val_binary_accuracy: 0.8760 - val_loss: 0.2826\n",
      "Epoch 49/10000\n",
      "47/47 - 1s - 12ms/step - binary_accuracy: 0.8675 - loss: 0.3151 - val_binary_accuracy: 0.8600 - val_loss: 0.3111\n",
      "Epoch 50/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8783 - loss: 0.3125 - val_binary_accuracy: 0.8760 - val_loss: 0.2778\n",
      "Epoch 51/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8695 - loss: 0.3113 - val_binary_accuracy: 0.8680 - val_loss: 0.2857\n",
      "Epoch 52/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8763 - loss: 0.3102 - val_binary_accuracy: 0.8640 - val_loss: 0.2871\n",
      "Epoch 53/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8749 - loss: 0.3107 - val_binary_accuracy: 0.8640 - val_loss: 0.3203\n",
      "Epoch 54/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8675 - loss: 0.3172 - val_binary_accuracy: 0.8760 - val_loss: 0.2862\n",
      "Epoch 55/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8736 - loss: 0.3088 - val_binary_accuracy: 0.8640 - val_loss: 0.2874\n",
      "Epoch 56/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8695 - loss: 0.3106 - val_binary_accuracy: 0.8760 - val_loss: 0.2812\n",
      "Epoch 57/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8688 - loss: 0.3102 - val_binary_accuracy: 0.8680 - val_loss: 0.2878\n",
      "Epoch 58/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8668 - loss: 0.3103 - val_binary_accuracy: 0.8720 - val_loss: 0.2819\n",
      "Epoch 59/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8736 - loss: 0.3063 - val_binary_accuracy: 0.8720 - val_loss: 0.2841\n",
      "Epoch 60/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8715 - loss: 0.3150 - val_binary_accuracy: 0.8680 - val_loss: 0.2896\n",
      "Epoch 61/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8783 - loss: 0.3050 - val_binary_accuracy: 0.8720 - val_loss: 0.2879\n",
      "Epoch 62/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8715 - loss: 0.3076 - val_binary_accuracy: 0.8720 - val_loss: 0.2893\n",
      "Epoch 63/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8695 - loss: 0.3112 - val_binary_accuracy: 0.8720 - val_loss: 0.2830\n",
      "Epoch 64/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8614 - loss: 0.3175 - val_binary_accuracy: 0.8640 - val_loss: 0.3173\n",
      "Epoch 65/10000\n",
      "47/47 - 1s - 14ms/step - binary_accuracy: 0.8776 - loss: 0.3049 - val_binary_accuracy: 0.8680 - val_loss: 0.3045\n",
      "Epoch 66/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8709 - loss: 0.3148 - val_binary_accuracy: 0.8680 - val_loss: 0.2947\n",
      "Epoch 67/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8587 - loss: 0.3220 - val_binary_accuracy: 0.8760 - val_loss: 0.2833\n",
      "Epoch 68/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8695 - loss: 0.3130 - val_binary_accuracy: 0.8720 - val_loss: 0.2993\n",
      "Epoch 69/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8715 - loss: 0.3171 - val_binary_accuracy: 0.8760 - val_loss: 0.2847\n",
      "Epoch 70/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8736 - loss: 0.3087 - val_binary_accuracy: 0.8720 - val_loss: 0.2837\n",
      "Epoch 71/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8695 - loss: 0.3178 - val_binary_accuracy: 0.8600 - val_loss: 0.3062\n",
      "Epoch 72/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8769 - loss: 0.3084 - val_binary_accuracy: 0.8720 - val_loss: 0.2834\n",
      "Epoch 73/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8553 - loss: 0.3317 - val_binary_accuracy: 0.8560 - val_loss: 0.3419\n",
      "Epoch 74/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8695 - loss: 0.3114 - val_binary_accuracy: 0.8680 - val_loss: 0.2860\n",
      "Epoch 75/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8803 - loss: 0.3002 - val_binary_accuracy: 0.8640 - val_loss: 0.2975\n",
      "Epoch 76/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8682 - loss: 0.3108 - val_binary_accuracy: 0.8720 - val_loss: 0.2893\n",
      "Epoch 77/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8769 - loss: 0.3109 - val_binary_accuracy: 0.8680 - val_loss: 0.2883\n",
      "Epoch 78/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8756 - loss: 0.2970 - val_binary_accuracy: 0.8560 - val_loss: 0.2965\n",
      "Epoch 79/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8756 - loss: 0.2971 - val_binary_accuracy: 0.8680 - val_loss: 0.2849\n",
      "Epoch 80/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8783 - loss: 0.2985 - val_binary_accuracy: 0.8680 - val_loss: 0.2862\n",
      "Epoch 81/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8736 - loss: 0.3004 - val_binary_accuracy: 0.8640 - val_loss: 0.2847\n",
      "Epoch 82/10000\n",
      "47/47 - 1s - 15ms/step - binary_accuracy: 0.8769 - loss: 0.2949 - val_binary_accuracy: 0.8600 - val_loss: 0.3115\n",
      "Epoch 83/10000\n",
      "47/47 - 0s - 10ms/step - binary_accuracy: 0.8783 - loss: 0.3012 - val_binary_accuracy: 0.8640 - val_loss: 0.2883\n",
      "Epoch 84/10000\n",
      "47/47 - 1s - 12ms/step - binary_accuracy: 0.8817 - loss: 0.2944 - val_binary_accuracy: 0.8720 - val_loss: 0.2904\n",
      "Epoch 85/10000\n",
      "47/47 - 0s - 10ms/step - binary_accuracy: 0.8769 - loss: 0.2951 - val_binary_accuracy: 0.8600 - val_loss: 0.3281\n",
      "Epoch 86/10000\n",
      "47/47 - 0s - 11ms/step - binary_accuracy: 0.8817 - loss: 0.2949 - val_binary_accuracy: 0.8600 - val_loss: 0.3007\n",
      "Epoch 87/10000\n",
      "47/47 - 1s - 12ms/step - binary_accuracy: 0.8857 - loss: 0.2949 - val_binary_accuracy: 0.8720 - val_loss: 0.2897\n",
      "Epoch 88/10000\n",
      "47/47 - 1s - 14ms/step - binary_accuracy: 0.8817 - loss: 0.3069 - val_binary_accuracy: 0.8600 - val_loss: 0.3237\n",
      "Epoch 89/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8776 - loss: 0.2999 - val_binary_accuracy: 0.8720 - val_loss: 0.2968\n",
      "Epoch 90/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8715 - loss: 0.3022 - val_binary_accuracy: 0.8640 - val_loss: 0.3286\n",
      "Epoch 91/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8783 - loss: 0.2920 - val_binary_accuracy: 0.8560 - val_loss: 0.3004\n",
      "Epoch 92/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8796 - loss: 0.2934 - val_binary_accuracy: 0.8600 - val_loss: 0.2974\n",
      "Epoch 93/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8796 - loss: 0.2944 - val_binary_accuracy: 0.8720 - val_loss: 0.2893\n",
      "Epoch 94/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8830 - loss: 0.2917 - val_binary_accuracy: 0.8720 - val_loss: 0.2880\n",
      "Epoch 95/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8783 - loss: 0.2985 - val_binary_accuracy: 0.8560 - val_loss: 0.3412\n",
      "Epoch 96/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8803 - loss: 0.2912 - val_binary_accuracy: 0.8560 - val_loss: 0.2955\n",
      "Epoch 97/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8884 - loss: 0.2865 - val_binary_accuracy: 0.8680 - val_loss: 0.2924\n",
      "Epoch 98/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8837 - loss: 0.2891 - val_binary_accuracy: 0.8720 - val_loss: 0.2939\n",
      "Epoch 99/10000\n",
      "47/47 - 1s - 15ms/step - binary_accuracy: 0.8844 - loss: 0.2873 - val_binary_accuracy: 0.8560 - val_loss: 0.3023\n",
      "Epoch 100/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8763 - loss: 0.3006 - val_binary_accuracy: 0.8560 - val_loss: 0.2967\n",
      "Epoch 101/10000\n",
      "47/47 - 0s - 10ms/step - binary_accuracy: 0.8817 - loss: 0.2967 - val_binary_accuracy: 0.8560 - val_loss: 0.2941\n",
      "Epoch 102/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8857 - loss: 0.2887 - val_binary_accuracy: 0.8680 - val_loss: 0.2879\n",
      "Epoch 103/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8830 - loss: 0.2850 - val_binary_accuracy: 0.8600 - val_loss: 0.2894\n",
      "Epoch 104/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8824 - loss: 0.2886 - val_binary_accuracy: 0.8600 - val_loss: 0.3166\n",
      "Epoch 105/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8844 - loss: 0.2823 - val_binary_accuracy: 0.8520 - val_loss: 0.2986\n",
      "Epoch 106/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8824 - loss: 0.2938 - val_binary_accuracy: 0.8720 - val_loss: 0.3048\n",
      "Epoch 107/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8776 - loss: 0.2979 - val_binary_accuracy: 0.8560 - val_loss: 0.3268\n",
      "Epoch 108/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8830 - loss: 0.2889 - val_binary_accuracy: 0.8640 - val_loss: 0.2913\n",
      "Epoch 109/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8864 - loss: 0.2825 - val_binary_accuracy: 0.8600 - val_loss: 0.2954\n",
      "Epoch 110/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8851 - loss: 0.2822 - val_binary_accuracy: 0.8600 - val_loss: 0.2947\n",
      "Epoch 111/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8837 - loss: 0.2860 - val_binary_accuracy: 0.8520 - val_loss: 0.2999\n",
      "Epoch 112/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8824 - loss: 0.2818 - val_binary_accuracy: 0.8680 - val_loss: 0.2923\n",
      "Epoch 113/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8851 - loss: 0.2797 - val_binary_accuracy: 0.8640 - val_loss: 0.2972\n",
      "Epoch 114/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8871 - loss: 0.2845 - val_binary_accuracy: 0.8640 - val_loss: 0.2945\n",
      "Epoch 115/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8844 - loss: 0.2809 - val_binary_accuracy: 0.8520 - val_loss: 0.3026\n",
      "Epoch 116/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8817 - loss: 0.2780 - val_binary_accuracy: 0.8560 - val_loss: 0.2945\n",
      "Epoch 117/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8918 - loss: 0.2764 - val_binary_accuracy: 0.8720 - val_loss: 0.2950\n",
      "Epoch 118/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8830 - loss: 0.2794 - val_binary_accuracy: 0.8600 - val_loss: 0.2940\n",
      "Epoch 119/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8851 - loss: 0.2794 - val_binary_accuracy: 0.8560 - val_loss: 0.3086\n",
      "Epoch 120/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8830 - loss: 0.2758 - val_binary_accuracy: 0.8520 - val_loss: 0.3091\n",
      "Epoch 121/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8871 - loss: 0.2768 - val_binary_accuracy: 0.8560 - val_loss: 0.3338\n",
      "Epoch 122/10000\n",
      "47/47 - 1s - 15ms/step - binary_accuracy: 0.8932 - loss: 0.2749 - val_binary_accuracy: 0.8600 - val_loss: 0.2997\n",
      "Epoch 123/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8918 - loss: 0.2773 - val_binary_accuracy: 0.8520 - val_loss: 0.3010\n",
      "Epoch 124/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8844 - loss: 0.2828 - val_binary_accuracy: 0.8480 - val_loss: 0.3009\n",
      "Epoch 125/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8810 - loss: 0.2755 - val_binary_accuracy: 0.8480 - val_loss: 0.3047\n",
      "Epoch 126/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8871 - loss: 0.2757 - val_binary_accuracy: 0.8560 - val_loss: 0.3427\n",
      "Epoch 127/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8817 - loss: 0.2871 - val_binary_accuracy: 0.8520 - val_loss: 0.3014\n",
      "Epoch 128/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8824 - loss: 0.2902 - val_binary_accuracy: 0.8680 - val_loss: 0.3081\n",
      "Epoch 129/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8769 - loss: 0.2831 - val_binary_accuracy: 0.8520 - val_loss: 0.3212\n",
      "Epoch 130/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8905 - loss: 0.2666 - val_binary_accuracy: 0.8480 - val_loss: 0.3175\n",
      "Epoch 131/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8851 - loss: 0.2710 - val_binary_accuracy: 0.8600 - val_loss: 0.3030\n",
      "Epoch 132/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8925 - loss: 0.2701 - val_binary_accuracy: 0.8480 - val_loss: 0.3143\n",
      "Epoch 133/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8884 - loss: 0.2755 - val_binary_accuracy: 0.8680 - val_loss: 0.3252\n",
      "Epoch 134/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8844 - loss: 0.2774 - val_binary_accuracy: 0.8720 - val_loss: 0.3045\n",
      "Epoch 135/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8898 - loss: 0.2684 - val_binary_accuracy: 0.8640 - val_loss: 0.3043\n",
      "Epoch 136/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8891 - loss: 0.2707 - val_binary_accuracy: 0.8640 - val_loss: 0.3149\n",
      "Epoch 137/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8844 - loss: 0.2773 - val_binary_accuracy: 0.8520 - val_loss: 0.3172\n",
      "Epoch 138/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8918 - loss: 0.2678 - val_binary_accuracy: 0.8680 - val_loss: 0.3028\n",
      "Epoch 139/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8932 - loss: 0.2651 - val_binary_accuracy: 0.8600 - val_loss: 0.3072\n",
      "Epoch 140/10000\n",
      "47/47 - 1s - 15ms/step - binary_accuracy: 0.8918 - loss: 0.2595 - val_binary_accuracy: 0.8600 - val_loss: 0.3238\n",
      "Epoch 141/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8824 - loss: 0.2836 - val_binary_accuracy: 0.8640 - val_loss: 0.3050\n",
      "Epoch 142/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8905 - loss: 0.2655 - val_binary_accuracy: 0.8560 - val_loss: 0.3362\n",
      "Epoch 143/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8945 - loss: 0.2579 - val_binary_accuracy: 0.8600 - val_loss: 0.3114\n",
      "Epoch 144/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8972 - loss: 0.2611 - val_binary_accuracy: 0.8600 - val_loss: 0.3220\n",
      "Epoch 145/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8783 - loss: 0.2784 - val_binary_accuracy: 0.8600 - val_loss: 0.3177\n",
      "Epoch 146/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8932 - loss: 0.2612 - val_binary_accuracy: 0.8600 - val_loss: 0.3066\n",
      "Epoch 147/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8925 - loss: 0.2621 - val_binary_accuracy: 0.8600 - val_loss: 0.3151\n",
      "Epoch 148/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8891 - loss: 0.2767 - val_binary_accuracy: 0.8640 - val_loss: 0.3126\n",
      "Epoch 149/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8972 - loss: 0.2656 - val_binary_accuracy: 0.8680 - val_loss: 0.3065\n",
      "Epoch 150/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8945 - loss: 0.2560 - val_binary_accuracy: 0.8560 - val_loss: 0.3138\n",
      "Trained model saved to CNN_models/sdB_2025-10-30_model_5.keras\n",
      "Epoch 1/10000\n",
      "47/47 - 2s - 44ms/step - binary_accuracy: 0.5410 - loss: 0.6913 - val_binary_accuracy: 0.5320 - val_loss: 0.6924\n",
      "Epoch 2/10000\n",
      "47/47 - 0s - 10ms/step - binary_accuracy: 0.5403 - loss: 0.6909 - val_binary_accuracy: 0.5320 - val_loss: 0.6912\n",
      "Epoch 3/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.5403 - loss: 0.6903 - val_binary_accuracy: 0.5320 - val_loss: 0.6911\n",
      "Epoch 4/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.5403 - loss: 0.6912 - val_binary_accuracy: 0.5320 - val_loss: 0.6911\n",
      "Epoch 5/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.5403 - loss: 0.6905 - val_binary_accuracy: 0.5320 - val_loss: 0.6928\n",
      "Epoch 6/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.5403 - loss: 0.6905 - val_binary_accuracy: 0.5320 - val_loss: 0.6915\n",
      "Epoch 7/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.5328 - loss: 0.6916 - val_binary_accuracy: 0.5320 - val_loss: 0.6912\n",
      "Epoch 8/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.5403 - loss: 0.6901 - val_binary_accuracy: 0.5320 - val_loss: 0.6910\n",
      "Epoch 9/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.5403 - loss: 0.6913 - val_binary_accuracy: 0.5320 - val_loss: 0.6912\n",
      "Epoch 10/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.5403 - loss: 0.6903 - val_binary_accuracy: 0.5320 - val_loss: 0.6910\n",
      "Epoch 11/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.5403 - loss: 0.6901 - val_binary_accuracy: 0.5320 - val_loss: 0.6909\n",
      "Epoch 12/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.5403 - loss: 0.6904 - val_binary_accuracy: 0.5320 - val_loss: 0.6904\n",
      "Epoch 13/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.5403 - loss: 0.6894 - val_binary_accuracy: 0.5320 - val_loss: 0.6899\n",
      "Epoch 14/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.5403 - loss: 0.6889 - val_binary_accuracy: 0.5320 - val_loss: 0.6894\n",
      "Epoch 15/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.5403 - loss: 0.6879 - val_binary_accuracy: 0.5320 - val_loss: 0.6878\n",
      "Epoch 16/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.5403 - loss: 0.6847 - val_binary_accuracy: 0.5320 - val_loss: 0.6805\n",
      "Epoch 17/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.5755 - loss: 0.6785 - val_binary_accuracy: 0.5320 - val_loss: 0.6820\n",
      "Epoch 18/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.6601 - loss: 0.6531 - val_binary_accuracy: 0.6280 - val_loss: 0.6183\n",
      "Epoch 19/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.7292 - loss: 0.5624 - val_binary_accuracy: 0.8040 - val_loss: 0.4896\n",
      "Epoch 20/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.7935 - loss: 0.4821 - val_binary_accuracy: 0.7560 - val_loss: 0.4831\n",
      "Epoch 21/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8260 - loss: 0.4165 - val_binary_accuracy: 0.7160 - val_loss: 0.5638\n",
      "Epoch 22/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8050 - loss: 0.4393 - val_binary_accuracy: 0.8320 - val_loss: 0.3680\n",
      "Epoch 23/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8450 - loss: 0.3734 - val_binary_accuracy: 0.8560 - val_loss: 0.3324\n",
      "Epoch 24/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8368 - loss: 0.3657 - val_binary_accuracy: 0.8600 - val_loss: 0.3669\n",
      "Epoch 25/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8531 - loss: 0.3436 - val_binary_accuracy: 0.8360 - val_loss: 0.3182\n",
      "Epoch 26/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8626 - loss: 0.3407 - val_binary_accuracy: 0.8480 - val_loss: 0.3245\n",
      "Epoch 27/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8659 - loss: 0.3365 - val_binary_accuracy: 0.8640 - val_loss: 0.3363\n",
      "Epoch 28/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8565 - loss: 0.3351 - val_binary_accuracy: 0.8560 - val_loss: 0.3257\n",
      "Epoch 29/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8517 - loss: 0.3537 - val_binary_accuracy: 0.8600 - val_loss: 0.3328\n",
      "Epoch 30/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8558 - loss: 0.3420 - val_binary_accuracy: 0.7960 - val_loss: 0.3969\n",
      "Epoch 31/10000\n",
      "47/47 - 0s - 10ms/step - binary_accuracy: 0.8612 - loss: 0.3380 - val_binary_accuracy: 0.8400 - val_loss: 0.3126\n",
      "Epoch 32/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8639 - loss: 0.3305 - val_binary_accuracy: 0.8560 - val_loss: 0.3215\n",
      "Epoch 33/10000\n",
      "47/47 - 0s - 10ms/step - binary_accuracy: 0.8538 - loss: 0.3516 - val_binary_accuracy: 0.8520 - val_loss: 0.3195\n",
      "Epoch 34/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8714 - loss: 0.3217 - val_binary_accuracy: 0.8360 - val_loss: 0.3144\n",
      "Epoch 35/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8646 - loss: 0.3304 - val_binary_accuracy: 0.8480 - val_loss: 0.3139\n",
      "Epoch 36/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8653 - loss: 0.3288 - val_binary_accuracy: 0.8520 - val_loss: 0.3211\n",
      "Epoch 37/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8619 - loss: 0.3282 - val_binary_accuracy: 0.8600 - val_loss: 0.3299\n",
      "Epoch 38/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8626 - loss: 0.3344 - val_binary_accuracy: 0.7680 - val_loss: 0.4609\n",
      "Epoch 39/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8355 - loss: 0.3655 - val_binary_accuracy: 0.8560 - val_loss: 0.3776\n",
      "Epoch 40/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8450 - loss: 0.3397 - val_binary_accuracy: 0.8440 - val_loss: 0.3354\n",
      "Epoch 41/10000\n",
      "47/47 - 1s - 13ms/step - binary_accuracy: 0.8626 - loss: 0.3234 - val_binary_accuracy: 0.8640 - val_loss: 0.3398\n",
      "Epoch 42/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8599 - loss: 0.3338 - val_binary_accuracy: 0.8440 - val_loss: 0.3250\n",
      "Epoch 43/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8585 - loss: 0.3368 - val_binary_accuracy: 0.8400 - val_loss: 0.3138\n",
      "Epoch 44/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8639 - loss: 0.3274 - val_binary_accuracy: 0.8400 - val_loss: 0.3304\n",
      "Epoch 45/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8565 - loss: 0.3344 - val_binary_accuracy: 0.8520 - val_loss: 0.3134\n",
      "Epoch 46/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8673 - loss: 0.3175 - val_binary_accuracy: 0.8640 - val_loss: 0.3433\n",
      "Epoch 47/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8646 - loss: 0.3195 - val_binary_accuracy: 0.8560 - val_loss: 0.3181\n",
      "Epoch 48/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8720 - loss: 0.3149 - val_binary_accuracy: 0.8680 - val_loss: 0.3304\n",
      "Epoch 49/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8720 - loss: 0.3199 - val_binary_accuracy: 0.8480 - val_loss: 0.3120\n",
      "Epoch 50/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8599 - loss: 0.3303 - val_binary_accuracy: 0.8520 - val_loss: 0.3107\n",
      "Epoch 51/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8693 - loss: 0.3201 - val_binary_accuracy: 0.8400 - val_loss: 0.3121\n",
      "Epoch 52/10000\n",
      "47/47 - 1s - 14ms/step - binary_accuracy: 0.8768 - loss: 0.3239 - val_binary_accuracy: 0.8360 - val_loss: 0.3131\n",
      "Epoch 53/10000\n",
      "47/47 - 1s - 11ms/step - binary_accuracy: 0.8680 - loss: 0.3248 - val_binary_accuracy: 0.8360 - val_loss: 0.3209\n",
      "Epoch 54/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8653 - loss: 0.3180 - val_binary_accuracy: 0.8520 - val_loss: 0.3115\n",
      "Epoch 55/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8666 - loss: 0.3140 - val_binary_accuracy: 0.8440 - val_loss: 0.3104\n",
      "Epoch 56/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8626 - loss: 0.3353 - val_binary_accuracy: 0.8640 - val_loss: 0.3390\n",
      "Epoch 57/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8646 - loss: 0.3255 - val_binary_accuracy: 0.8280 - val_loss: 0.3171\n",
      "Epoch 58/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8673 - loss: 0.3194 - val_binary_accuracy: 0.8400 - val_loss: 0.3402\n",
      "Epoch 59/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8700 - loss: 0.3147 - val_binary_accuracy: 0.8320 - val_loss: 0.3180\n",
      "Epoch 60/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8680 - loss: 0.3205 - val_binary_accuracy: 0.8440 - val_loss: 0.3293\n",
      "Epoch 61/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8734 - loss: 0.3160 - val_binary_accuracy: 0.8640 - val_loss: 0.3239\n",
      "Epoch 62/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8741 - loss: 0.3147 - val_binary_accuracy: 0.8680 - val_loss: 0.3437\n",
      "Epoch 63/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8747 - loss: 0.3131 - val_binary_accuracy: 0.8480 - val_loss: 0.3093\n",
      "Epoch 64/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8687 - loss: 0.3168 - val_binary_accuracy: 0.8600 - val_loss: 0.3226\n",
      "Epoch 65/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8741 - loss: 0.3212 - val_binary_accuracy: 0.8600 - val_loss: 0.3226\n",
      "Epoch 66/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8558 - loss: 0.3226 - val_binary_accuracy: 0.8520 - val_loss: 0.3100\n",
      "Epoch 67/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8585 - loss: 0.3293 - val_binary_accuracy: 0.8480 - val_loss: 0.3271\n",
      "Epoch 68/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8795 - loss: 0.3107 - val_binary_accuracy: 0.8560 - val_loss: 0.3144\n",
      "Epoch 69/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8734 - loss: 0.3068 - val_binary_accuracy: 0.8480 - val_loss: 0.3094\n",
      "Epoch 70/10000\n",
      "47/47 - 1s - 14ms/step - binary_accuracy: 0.8754 - loss: 0.3082 - val_binary_accuracy: 0.8600 - val_loss: 0.3216\n",
      "Epoch 71/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8693 - loss: 0.3119 - val_binary_accuracy: 0.8480 - val_loss: 0.3088\n",
      "Epoch 72/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8761 - loss: 0.3100 - val_binary_accuracy: 0.8520 - val_loss: 0.3136\n",
      "Epoch 73/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8754 - loss: 0.3011 - val_binary_accuracy: 0.8480 - val_loss: 0.3090\n",
      "Epoch 74/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8741 - loss: 0.3040 - val_binary_accuracy: 0.8560 - val_loss: 0.3286\n",
      "Epoch 75/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8835 - loss: 0.3051 - val_binary_accuracy: 0.8520 - val_loss: 0.3106\n",
      "Epoch 76/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8781 - loss: 0.3053 - val_binary_accuracy: 0.8560 - val_loss: 0.3274\n",
      "Epoch 77/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8761 - loss: 0.3009 - val_binary_accuracy: 0.8560 - val_loss: 0.3133\n",
      "Epoch 78/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8720 - loss: 0.3102 - val_binary_accuracy: 0.8600 - val_loss: 0.3166\n",
      "Epoch 79/10000\n",
      "47/47 - 0s - 10ms/step - binary_accuracy: 0.8761 - loss: 0.3024 - val_binary_accuracy: 0.8520 - val_loss: 0.3069\n",
      "Epoch 80/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8768 - loss: 0.3013 - val_binary_accuracy: 0.8640 - val_loss: 0.3298\n",
      "Epoch 81/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8822 - loss: 0.3007 - val_binary_accuracy: 0.8480 - val_loss: 0.3168\n",
      "Epoch 82/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8747 - loss: 0.3124 - val_binary_accuracy: 0.8640 - val_loss: 0.3315\n",
      "Epoch 83/10000\n",
      "47/47 - 0s - 10ms/step - binary_accuracy: 0.8808 - loss: 0.3033 - val_binary_accuracy: 0.8520 - val_loss: 0.3077\n",
      "Epoch 84/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8781 - loss: 0.3060 - val_binary_accuracy: 0.8560 - val_loss: 0.3092\n",
      "Epoch 85/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8863 - loss: 0.2972 - val_binary_accuracy: 0.8360 - val_loss: 0.3118\n",
      "Epoch 86/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8727 - loss: 0.3089 - val_binary_accuracy: 0.8640 - val_loss: 0.3298\n",
      "Epoch 87/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8707 - loss: 0.3057 - val_binary_accuracy: 0.8280 - val_loss: 0.3552\n",
      "Epoch 88/10000\n",
      "47/47 - 0s - 10ms/step - binary_accuracy: 0.8802 - loss: 0.3037 - val_binary_accuracy: 0.8440 - val_loss: 0.3066\n",
      "Epoch 89/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8802 - loss: 0.2955 - val_binary_accuracy: 0.8480 - val_loss: 0.3493\n",
      "Epoch 90/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8835 - loss: 0.2986 - val_binary_accuracy: 0.8400 - val_loss: 0.3191\n",
      "Epoch 91/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8768 - loss: 0.3072 - val_binary_accuracy: 0.8520 - val_loss: 0.3081\n",
      "Epoch 92/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8835 - loss: 0.2916 - val_binary_accuracy: 0.8400 - val_loss: 0.3107\n",
      "Epoch 93/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8775 - loss: 0.2989 - val_binary_accuracy: 0.8680 - val_loss: 0.3382\n",
      "Epoch 94/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8727 - loss: 0.2990 - val_binary_accuracy: 0.8320 - val_loss: 0.3114\n",
      "Epoch 95/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8599 - loss: 0.3313 - val_binary_accuracy: 0.8440 - val_loss: 0.3085\n",
      "Epoch 96/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8734 - loss: 0.3095 - val_binary_accuracy: 0.8480 - val_loss: 0.3054\n",
      "Epoch 97/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8727 - loss: 0.3023 - val_binary_accuracy: 0.8440 - val_loss: 0.3329\n",
      "Epoch 98/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8754 - loss: 0.2955 - val_binary_accuracy: 0.8440 - val_loss: 0.3053\n",
      "Epoch 99/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8795 - loss: 0.3083 - val_binary_accuracy: 0.8600 - val_loss: 0.3164\n",
      "Epoch 100/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8775 - loss: 0.2990 - val_binary_accuracy: 0.8680 - val_loss: 0.3236\n",
      "Epoch 101/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8856 - loss: 0.2902 - val_binary_accuracy: 0.8560 - val_loss: 0.3102\n",
      "Epoch 102/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8788 - loss: 0.2956 - val_binary_accuracy: 0.8520 - val_loss: 0.3059\n",
      "Epoch 103/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8835 - loss: 0.2917 - val_binary_accuracy: 0.8480 - val_loss: 0.3031\n",
      "Epoch 104/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8890 - loss: 0.2866 - val_binary_accuracy: 0.8560 - val_loss: 0.3229\n",
      "Epoch 105/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8849 - loss: 0.2899 - val_binary_accuracy: 0.8400 - val_loss: 0.3046\n",
      "Epoch 106/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8775 - loss: 0.2960 - val_binary_accuracy: 0.8440 - val_loss: 0.3077\n",
      "Epoch 107/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8781 - loss: 0.2925 - val_binary_accuracy: 0.8520 - val_loss: 0.3064\n",
      "Epoch 108/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8659 - loss: 0.3124 - val_binary_accuracy: 0.8520 - val_loss: 0.3082\n",
      "Epoch 109/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8869 - loss: 0.2947 - val_binary_accuracy: 0.8560 - val_loss: 0.3095\n",
      "Epoch 110/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8856 - loss: 0.2968 - val_binary_accuracy: 0.8560 - val_loss: 0.3111\n",
      "Epoch 111/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8923 - loss: 0.2807 - val_binary_accuracy: 0.8480 - val_loss: 0.3115\n",
      "Epoch 112/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8734 - loss: 0.3013 - val_binary_accuracy: 0.8520 - val_loss: 0.3100\n",
      "Epoch 113/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8808 - loss: 0.2925 - val_binary_accuracy: 0.8520 - val_loss: 0.3078\n",
      "Epoch 114/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8869 - loss: 0.2810 - val_binary_accuracy: 0.8520 - val_loss: 0.3047\n",
      "Epoch 115/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8754 - loss: 0.3005 - val_binary_accuracy: 0.8480 - val_loss: 0.3074\n",
      "Epoch 116/10000\n",
      "47/47 - 1s - 13ms/step - binary_accuracy: 0.8788 - loss: 0.2949 - val_binary_accuracy: 0.8640 - val_loss: 0.3157\n",
      "Epoch 117/10000\n",
      "47/47 - 0s - 10ms/step - binary_accuracy: 0.8890 - loss: 0.2821 - val_binary_accuracy: 0.8480 - val_loss: 0.3082\n",
      "Epoch 118/10000\n",
      "47/47 - 1s - 11ms/step - binary_accuracy: 0.8822 - loss: 0.2872 - val_binary_accuracy: 0.8560 - val_loss: 0.3008\n",
      "Epoch 119/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8835 - loss: 0.2824 - val_binary_accuracy: 0.8680 - val_loss: 0.3225\n",
      "Epoch 120/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8856 - loss: 0.2878 - val_binary_accuracy: 0.8520 - val_loss: 0.3160\n",
      "Epoch 121/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8808 - loss: 0.2847 - val_binary_accuracy: 0.8480 - val_loss: 0.3524\n",
      "Epoch 122/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8768 - loss: 0.3090 - val_binary_accuracy: 0.8480 - val_loss: 0.3034\n",
      "Epoch 123/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8856 - loss: 0.2822 - val_binary_accuracy: 0.8600 - val_loss: 0.3141\n",
      "Epoch 124/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8890 - loss: 0.2808 - val_binary_accuracy: 0.8520 - val_loss: 0.3055\n",
      "Epoch 125/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8869 - loss: 0.2834 - val_binary_accuracy: 0.8480 - val_loss: 0.3059\n",
      "Epoch 126/10000\n",
      "47/47 - 1s - 14ms/step - binary_accuracy: 0.8903 - loss: 0.2749 - val_binary_accuracy: 0.8640 - val_loss: 0.3201\n",
      "Epoch 127/10000\n",
      "47/47 - 1s - 16ms/step - binary_accuracy: 0.8856 - loss: 0.2854 - val_binary_accuracy: 0.8440 - val_loss: 0.3052\n",
      "Epoch 128/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8863 - loss: 0.2821 - val_binary_accuracy: 0.8520 - val_loss: 0.3148\n",
      "Epoch 129/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8876 - loss: 0.2826 - val_binary_accuracy: 0.8480 - val_loss: 0.3134\n",
      "Epoch 130/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8890 - loss: 0.2733 - val_binary_accuracy: 0.8480 - val_loss: 0.3106\n",
      "Epoch 131/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8876 - loss: 0.2761 - val_binary_accuracy: 0.8520 - val_loss: 0.3046\n",
      "Epoch 132/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8923 - loss: 0.2740 - val_binary_accuracy: 0.8520 - val_loss: 0.3037\n",
      "Epoch 133/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8971 - loss: 0.2727 - val_binary_accuracy: 0.8480 - val_loss: 0.3081\n",
      "Epoch 134/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8883 - loss: 0.2803 - val_binary_accuracy: 0.8440 - val_loss: 0.3071\n",
      "Epoch 135/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8978 - loss: 0.2679 - val_binary_accuracy: 0.8680 - val_loss: 0.3266\n",
      "Epoch 136/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8842 - loss: 0.2762 - val_binary_accuracy: 0.8480 - val_loss: 0.3055\n",
      "Epoch 137/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8903 - loss: 0.2755 - val_binary_accuracy: 0.8440 - val_loss: 0.3010\n",
      "Epoch 138/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8903 - loss: 0.2690 - val_binary_accuracy: 0.8600 - val_loss: 0.3171\n",
      "Epoch 139/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8890 - loss: 0.2689 - val_binary_accuracy: 0.8560 - val_loss: 0.3019\n",
      "Epoch 140/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8849 - loss: 0.2737 - val_binary_accuracy: 0.8560 - val_loss: 0.3171\n",
      "Epoch 141/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8869 - loss: 0.2775 - val_binary_accuracy: 0.8520 - val_loss: 0.3023\n",
      "Epoch 142/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8951 - loss: 0.2687 - val_binary_accuracy: 0.8440 - val_loss: 0.3075\n",
      "Epoch 143/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8923 - loss: 0.2736 - val_binary_accuracy: 0.8560 - val_loss: 0.2998\n",
      "Epoch 144/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8896 - loss: 0.2710 - val_binary_accuracy: 0.8440 - val_loss: 0.3025\n",
      "Epoch 145/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8842 - loss: 0.2792 - val_binary_accuracy: 0.8680 - val_loss: 0.3483\n",
      "Epoch 146/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8835 - loss: 0.2797 - val_binary_accuracy: 0.8560 - val_loss: 0.3173\n",
      "Epoch 147/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8795 - loss: 0.2817 - val_binary_accuracy: 0.8720 - val_loss: 0.3420\n",
      "Epoch 148/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8808 - loss: 0.2879 - val_binary_accuracy: 0.8440 - val_loss: 0.3129\n",
      "Epoch 149/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8829 - loss: 0.2863 - val_binary_accuracy: 0.8640 - val_loss: 0.3202\n",
      "Epoch 150/10000\n",
      "47/47 - 1s - 15ms/step - binary_accuracy: 0.8883 - loss: 0.2677 - val_binary_accuracy: 0.8600 - val_loss: 0.3406\n",
      "Trained model saved to CNN_models/sdB_2025-10-30_model_6.keras\n",
      "Epoch 1/10000\n",
      "47/47 - 2s - 48ms/step - binary_accuracy: 0.5376 - loss: 0.6922 - val_binary_accuracy: 0.5560 - val_loss: 0.6892\n",
      "Epoch 2/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.5376 - loss: 0.6911 - val_binary_accuracy: 0.5560 - val_loss: 0.6882\n",
      "Epoch 3/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.5376 - loss: 0.6909 - val_binary_accuracy: 0.5560 - val_loss: 0.6881\n",
      "Epoch 4/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.5376 - loss: 0.6909 - val_binary_accuracy: 0.5560 - val_loss: 0.6877\n",
      "Epoch 5/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.5376 - loss: 0.6907 - val_binary_accuracy: 0.5560 - val_loss: 0.6888\n",
      "Epoch 6/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.5376 - loss: 0.6906 - val_binary_accuracy: 0.5560 - val_loss: 0.6869\n",
      "Epoch 7/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.5376 - loss: 0.6910 - val_binary_accuracy: 0.5560 - val_loss: 0.6872\n",
      "Epoch 8/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.5376 - loss: 0.6902 - val_binary_accuracy: 0.5560 - val_loss: 0.6885\n",
      "Epoch 9/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.5376 - loss: 0.6908 - val_binary_accuracy: 0.5560 - val_loss: 0.6884\n",
      "Epoch 10/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.5376 - loss: 0.6902 - val_binary_accuracy: 0.5560 - val_loss: 0.6872\n",
      "Epoch 11/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.5376 - loss: 0.6903 - val_binary_accuracy: 0.5560 - val_loss: 0.6884\n",
      "Epoch 12/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.5376 - loss: 0.6902 - val_binary_accuracy: 0.5560 - val_loss: 0.6872\n",
      "Epoch 13/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.5376 - loss: 0.6908 - val_binary_accuracy: 0.5560 - val_loss: 0.6872\n",
      "Epoch 14/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.5376 - loss: 0.6905 - val_binary_accuracy: 0.5560 - val_loss: 0.6866\n",
      "Epoch 15/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.5376 - loss: 0.6904 - val_binary_accuracy: 0.5560 - val_loss: 0.6870\n",
      "Epoch 16/10000\n",
      "47/47 - 1s - 14ms/step - binary_accuracy: 0.5376 - loss: 0.6896 - val_binary_accuracy: 0.5560 - val_loss: 0.6870\n",
      "Epoch 17/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.5376 - loss: 0.6888 - val_binary_accuracy: 0.5560 - val_loss: 0.6844\n",
      "Epoch 18/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.5376 - loss: 0.6867 - val_binary_accuracy: 0.5560 - val_loss: 0.6853\n",
      "Epoch 19/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.5424 - loss: 0.6814 - val_binary_accuracy: 0.8520 - val_loss: 0.6709\n",
      "Epoch 20/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.6705 - loss: 0.6473 - val_binary_accuracy: 0.8520 - val_loss: 0.5905\n",
      "Epoch 21/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.7207 - loss: 0.5810 - val_binary_accuracy: 0.6680 - val_loss: 0.5460\n",
      "Epoch 22/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.7742 - loss: 0.5153 - val_binary_accuracy: 0.8600 - val_loss: 0.3978\n",
      "Epoch 23/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8163 - loss: 0.4213 - val_binary_accuracy: 0.8400 - val_loss: 0.3821\n",
      "Epoch 24/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8468 - loss: 0.3692 - val_binary_accuracy: 0.8520 - val_loss: 0.3417\n",
      "Epoch 25/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8590 - loss: 0.3545 - val_binary_accuracy: 0.8240 - val_loss: 0.3856\n",
      "Epoch 26/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8475 - loss: 0.3574 - val_binary_accuracy: 0.8520 - val_loss: 0.3427\n",
      "Epoch 27/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8597 - loss: 0.3399 - val_binary_accuracy: 0.8560 - val_loss: 0.3592\n",
      "Epoch 28/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8515 - loss: 0.3433 - val_binary_accuracy: 0.7400 - val_loss: 0.5512\n",
      "Epoch 29/10000\n",
      "47/47 - 1s - 16ms/step - binary_accuracy: 0.8393 - loss: 0.3580 - val_binary_accuracy: 0.8400 - val_loss: 0.3402\n",
      "Epoch 30/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8631 - loss: 0.3274 - val_binary_accuracy: 0.8280 - val_loss: 0.3967\n",
      "Epoch 31/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8610 - loss: 0.3292 - val_binary_accuracy: 0.8200 - val_loss: 0.3853\n",
      "Epoch 32/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8597 - loss: 0.3428 - val_binary_accuracy: 0.8440 - val_loss: 0.3442\n",
      "Epoch 33/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8692 - loss: 0.3230 - val_binary_accuracy: 0.8280 - val_loss: 0.3703\n",
      "Epoch 34/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8617 - loss: 0.3208 - val_binary_accuracy: 0.8520 - val_loss: 0.3559\n",
      "Epoch 35/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8475 - loss: 0.3482 - val_binary_accuracy: 0.8480 - val_loss: 0.3476\n",
      "Epoch 36/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8549 - loss: 0.3360 - val_binary_accuracy: 0.8240 - val_loss: 0.3580\n",
      "Epoch 37/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8739 - loss: 0.3125 - val_binary_accuracy: 0.8200 - val_loss: 0.3714\n",
      "Epoch 38/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8664 - loss: 0.3273 - val_binary_accuracy: 0.8520 - val_loss: 0.3440\n",
      "Epoch 39/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8705 - loss: 0.3199 - val_binary_accuracy: 0.8280 - val_loss: 0.3573\n",
      "Epoch 40/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8698 - loss: 0.3192 - val_binary_accuracy: 0.8240 - val_loss: 0.3613\n",
      "Epoch 41/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8746 - loss: 0.3130 - val_binary_accuracy: 0.8560 - val_loss: 0.3594\n",
      "Epoch 42/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8725 - loss: 0.3187 - val_binary_accuracy: 0.8560 - val_loss: 0.3497\n",
      "Epoch 43/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8780 - loss: 0.3127 - val_binary_accuracy: 0.8480 - val_loss: 0.3513\n",
      "Epoch 44/10000\n",
      "47/47 - 1s - 14ms/step - binary_accuracy: 0.8786 - loss: 0.3102 - val_binary_accuracy: 0.8440 - val_loss: 0.3489\n",
      "Epoch 45/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8705 - loss: 0.3078 - val_binary_accuracy: 0.8480 - val_loss: 0.3557\n",
      "Epoch 46/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8637 - loss: 0.3192 - val_binary_accuracy: 0.8480 - val_loss: 0.3480\n",
      "Epoch 47/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8685 - loss: 0.3134 - val_binary_accuracy: 0.8440 - val_loss: 0.3466\n",
      "Epoch 48/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8725 - loss: 0.3124 - val_binary_accuracy: 0.8000 - val_loss: 0.4726\n",
      "Epoch 49/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8468 - loss: 0.3643 - val_binary_accuracy: 0.8440 - val_loss: 0.3529\n",
      "Epoch 50/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8712 - loss: 0.3126 - val_binary_accuracy: 0.8240 - val_loss: 0.3685\n",
      "Epoch 51/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8624 - loss: 0.3223 - val_binary_accuracy: 0.8280 - val_loss: 0.3976\n",
      "Epoch 52/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8563 - loss: 0.3318 - val_binary_accuracy: 0.8440 - val_loss: 0.3487\n",
      "Epoch 53/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8705 - loss: 0.3114 - val_binary_accuracy: 0.8320 - val_loss: 0.3596\n",
      "Epoch 54/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8671 - loss: 0.3237 - val_binary_accuracy: 0.8360 - val_loss: 0.3604\n",
      "Epoch 55/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8759 - loss: 0.3107 - val_binary_accuracy: 0.8400 - val_loss: 0.3475\n",
      "Epoch 56/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8719 - loss: 0.3137 - val_binary_accuracy: 0.8200 - val_loss: 0.4255\n",
      "Epoch 57/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8685 - loss: 0.3274 - val_binary_accuracy: 0.8240 - val_loss: 0.3819\n",
      "Epoch 58/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8766 - loss: 0.3131 - val_binary_accuracy: 0.8280 - val_loss: 0.3740\n",
      "Epoch 59/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8753 - loss: 0.3130 - val_binary_accuracy: 0.8520 - val_loss: 0.3539\n",
      "Epoch 60/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8793 - loss: 0.3056 - val_binary_accuracy: 0.8280 - val_loss: 0.3657\n",
      "Epoch 61/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8793 - loss: 0.3049 - val_binary_accuracy: 0.8480 - val_loss: 0.3538\n",
      "Epoch 62/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8698 - loss: 0.3113 - val_binary_accuracy: 0.8520 - val_loss: 0.3534\n",
      "Epoch 63/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8800 - loss: 0.3069 - val_binary_accuracy: 0.8320 - val_loss: 0.3632\n",
      "Epoch 64/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8732 - loss: 0.3043 - val_binary_accuracy: 0.8440 - val_loss: 0.3534\n",
      "Epoch 65/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8746 - loss: 0.3107 - val_binary_accuracy: 0.8440 - val_loss: 0.3521\n",
      "Epoch 66/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8759 - loss: 0.2998 - val_binary_accuracy: 0.8440 - val_loss: 0.3519\n",
      "Epoch 67/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8786 - loss: 0.3025 - val_binary_accuracy: 0.8360 - val_loss: 0.3677\n",
      "Epoch 68/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8759 - loss: 0.3050 - val_binary_accuracy: 0.8440 - val_loss: 0.3521\n",
      "Epoch 69/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8780 - loss: 0.3009 - val_binary_accuracy: 0.8560 - val_loss: 0.3602\n",
      "Epoch 70/10000\n",
      "47/47 - 0s - 10ms/step - binary_accuracy: 0.8698 - loss: 0.3050 - val_binary_accuracy: 0.8440 - val_loss: 0.3613\n",
      "Epoch 71/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8800 - loss: 0.2980 - val_binary_accuracy: 0.8320 - val_loss: 0.3723\n",
      "Epoch 72/10000\n",
      "47/47 - 1s - 12ms/step - binary_accuracy: 0.8631 - loss: 0.3199 - val_binary_accuracy: 0.8560 - val_loss: 0.3526\n",
      "Epoch 73/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8671 - loss: 0.3137 - val_binary_accuracy: 0.8520 - val_loss: 0.3577\n",
      "Epoch 74/10000\n",
      "47/47 - 1s - 14ms/step - binary_accuracy: 0.8759 - loss: 0.3117 - val_binary_accuracy: 0.8560 - val_loss: 0.3562\n",
      "Epoch 75/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8793 - loss: 0.2962 - val_binary_accuracy: 0.8280 - val_loss: 0.3824\n",
      "Epoch 76/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8671 - loss: 0.3147 - val_binary_accuracy: 0.8200 - val_loss: 0.4097\n",
      "Epoch 77/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8786 - loss: 0.3055 - val_binary_accuracy: 0.8320 - val_loss: 0.3554\n",
      "Epoch 78/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8786 - loss: 0.2978 - val_binary_accuracy: 0.8240 - val_loss: 0.3898\n",
      "Epoch 79/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8719 - loss: 0.3047 - val_binary_accuracy: 0.8160 - val_loss: 0.4489\n",
      "Epoch 80/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8732 - loss: 0.3003 - val_binary_accuracy: 0.8480 - val_loss: 0.3633\n",
      "Epoch 81/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8773 - loss: 0.2944 - val_binary_accuracy: 0.8400 - val_loss: 0.3573\n",
      "Epoch 82/10000\n",
      "47/47 - 1s - 13ms/step - binary_accuracy: 0.8712 - loss: 0.3048 - val_binary_accuracy: 0.8240 - val_loss: 0.3839\n",
      "Epoch 83/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8725 - loss: 0.3015 - val_binary_accuracy: 0.8480 - val_loss: 0.3627\n",
      "Epoch 84/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8780 - loss: 0.3026 - val_binary_accuracy: 0.8480 - val_loss: 0.3653\n",
      "Epoch 85/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8637 - loss: 0.3177 - val_binary_accuracy: 0.8360 - val_loss: 0.3670\n",
      "Epoch 86/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8786 - loss: 0.2946 - val_binary_accuracy: 0.8120 - val_loss: 0.4145\n",
      "Epoch 87/10000\n",
      "47/47 - 1s - 13ms/step - binary_accuracy: 0.8651 - loss: 0.3056 - val_binary_accuracy: 0.8520 - val_loss: 0.3626\n",
      "Epoch 88/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8698 - loss: 0.3042 - val_binary_accuracy: 0.8440 - val_loss: 0.3542\n",
      "Epoch 89/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8793 - loss: 0.2977 - val_binary_accuracy: 0.8520 - val_loss: 0.3571\n",
      "Epoch 90/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8746 - loss: 0.3005 - val_binary_accuracy: 0.8200 - val_loss: 0.4099\n",
      "Epoch 91/10000\n",
      "47/47 - 1s - 13ms/step - binary_accuracy: 0.8786 - loss: 0.2969 - val_binary_accuracy: 0.8360 - val_loss: 0.3595\n",
      "Epoch 92/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8786 - loss: 0.2920 - val_binary_accuracy: 0.8520 - val_loss: 0.3576\n",
      "Epoch 93/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8800 - loss: 0.2972 - val_binary_accuracy: 0.8520 - val_loss: 0.3550\n",
      "Epoch 94/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8766 - loss: 0.2951 - val_binary_accuracy: 0.8160 - val_loss: 0.4085\n",
      "Epoch 95/10000\n",
      "47/47 - 1s - 13ms/step - binary_accuracy: 0.8698 - loss: 0.3038 - val_binary_accuracy: 0.8520 - val_loss: 0.3573\n",
      "Epoch 96/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8712 - loss: 0.3028 - val_binary_accuracy: 0.8360 - val_loss: 0.3579\n",
      "Epoch 97/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8780 - loss: 0.2930 - val_binary_accuracy: 0.8320 - val_loss: 0.3619\n",
      "Epoch 98/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8786 - loss: 0.2961 - val_binary_accuracy: 0.8440 - val_loss: 0.3935\n",
      "Epoch 99/10000\n",
      "47/47 - 1s - 14ms/step - binary_accuracy: 0.8766 - loss: 0.2976 - val_binary_accuracy: 0.8200 - val_loss: 0.3794\n",
      "Epoch 100/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8739 - loss: 0.2983 - val_binary_accuracy: 0.8320 - val_loss: 0.3597\n",
      "Epoch 101/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8827 - loss: 0.2888 - val_binary_accuracy: 0.8360 - val_loss: 0.3661\n",
      "Epoch 102/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8861 - loss: 0.2934 - val_binary_accuracy: 0.8360 - val_loss: 0.3592\n",
      "Epoch 103/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8847 - loss: 0.2878 - val_binary_accuracy: 0.8480 - val_loss: 0.3603\n",
      "Epoch 104/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8780 - loss: 0.2995 - val_binary_accuracy: 0.8360 - val_loss: 0.3646\n",
      "Epoch 105/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8719 - loss: 0.2955 - val_binary_accuracy: 0.8480 - val_loss: 0.3630\n",
      "Epoch 106/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8793 - loss: 0.2900 - val_binary_accuracy: 0.8560 - val_loss: 0.3655\n",
      "Epoch 107/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8847 - loss: 0.2935 - val_binary_accuracy: 0.8120 - val_loss: 0.4151\n",
      "Epoch 108/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8814 - loss: 0.3023 - val_binary_accuracy: 0.8360 - val_loss: 0.3575\n",
      "Epoch 109/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8678 - loss: 0.3000 - val_binary_accuracy: 0.8480 - val_loss: 0.3581\n",
      "Epoch 110/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8739 - loss: 0.3032 - val_binary_accuracy: 0.8560 - val_loss: 0.3570\n",
      "Epoch 111/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8739 - loss: 0.2944 - val_binary_accuracy: 0.8440 - val_loss: 0.3595\n",
      "Epoch 112/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8732 - loss: 0.2983 - val_binary_accuracy: 0.8480 - val_loss: 0.3575\n",
      "Epoch 113/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8692 - loss: 0.2935 - val_binary_accuracy: 0.8400 - val_loss: 0.3600\n",
      "Epoch 114/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8820 - loss: 0.2888 - val_binary_accuracy: 0.8480 - val_loss: 0.3626\n",
      "Epoch 115/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8834 - loss: 0.3009 - val_binary_accuracy: 0.8680 - val_loss: 0.3594\n",
      "Epoch 116/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8881 - loss: 0.2824 - val_binary_accuracy: 0.8440 - val_loss: 0.3641\n",
      "Epoch 117/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8814 - loss: 0.2861 - val_binary_accuracy: 0.8400 - val_loss: 0.3650\n",
      "Epoch 118/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8834 - loss: 0.2845 - val_binary_accuracy: 0.8280 - val_loss: 0.3884\n",
      "Epoch 119/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8841 - loss: 0.2837 - val_binary_accuracy: 0.8400 - val_loss: 0.3690\n",
      "Epoch 120/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8834 - loss: 0.2808 - val_binary_accuracy: 0.8360 - val_loss: 0.3700\n",
      "Epoch 121/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8719 - loss: 0.3003 - val_binary_accuracy: 0.8360 - val_loss: 0.3711\n",
      "Epoch 122/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8814 - loss: 0.2855 - val_binary_accuracy: 0.8360 - val_loss: 0.3772\n",
      "Epoch 123/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8847 - loss: 0.2744 - val_binary_accuracy: 0.8280 - val_loss: 0.3849\n",
      "Epoch 124/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8888 - loss: 0.2796 - val_binary_accuracy: 0.8440 - val_loss: 0.3658\n",
      "Epoch 125/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8902 - loss: 0.2782 - val_binary_accuracy: 0.8280 - val_loss: 0.3828\n",
      "Epoch 126/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8834 - loss: 0.2792 - val_binary_accuracy: 0.8400 - val_loss: 0.3750\n",
      "Epoch 127/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8800 - loss: 0.2898 - val_binary_accuracy: 0.8240 - val_loss: 0.3949\n",
      "Epoch 128/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8807 - loss: 0.2907 - val_binary_accuracy: 0.8600 - val_loss: 0.3717\n",
      "Epoch 129/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8746 - loss: 0.2918 - val_binary_accuracy: 0.8360 - val_loss: 0.3775\n",
      "Epoch 130/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8888 - loss: 0.2737 - val_binary_accuracy: 0.8160 - val_loss: 0.4554\n",
      "Epoch 131/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8746 - loss: 0.2859 - val_binary_accuracy: 0.8440 - val_loss: 0.3745\n",
      "Epoch 132/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8881 - loss: 0.2764 - val_binary_accuracy: 0.8440 - val_loss: 0.3714\n",
      "Epoch 133/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8881 - loss: 0.2711 - val_binary_accuracy: 0.8320 - val_loss: 0.3939\n",
      "Epoch 134/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8847 - loss: 0.2699 - val_binary_accuracy: 0.8440 - val_loss: 0.3827\n",
      "Epoch 135/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8868 - loss: 0.2711 - val_binary_accuracy: 0.8480 - val_loss: 0.3804\n",
      "Epoch 136/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8895 - loss: 0.2748 - val_binary_accuracy: 0.8440 - val_loss: 0.3734\n",
      "Epoch 137/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8881 - loss: 0.2743 - val_binary_accuracy: 0.8560 - val_loss: 0.3797\n",
      "Epoch 138/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8786 - loss: 0.2976 - val_binary_accuracy: 0.8480 - val_loss: 0.3641\n",
      "Epoch 139/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8956 - loss: 0.2699 - val_binary_accuracy: 0.8440 - val_loss: 0.3795\n",
      "Epoch 140/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8868 - loss: 0.2694 - val_binary_accuracy: 0.8400 - val_loss: 0.3772\n",
      "Epoch 141/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8902 - loss: 0.2704 - val_binary_accuracy: 0.8400 - val_loss: 0.3784\n",
      "Epoch 142/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8969 - loss: 0.2682 - val_binary_accuracy: 0.8320 - val_loss: 0.4000\n",
      "Epoch 143/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8902 - loss: 0.2673 - val_binary_accuracy: 0.8240 - val_loss: 0.4150\n",
      "Epoch 144/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8902 - loss: 0.2670 - val_binary_accuracy: 0.8440 - val_loss: 0.3897\n",
      "Epoch 145/10000\n",
      "47/47 - 1s - 14ms/step - binary_accuracy: 0.8861 - loss: 0.2763 - val_binary_accuracy: 0.8440 - val_loss: 0.3784\n",
      "Epoch 146/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8915 - loss: 0.2677 - val_binary_accuracy: 0.8480 - val_loss: 0.3828\n",
      "Epoch 147/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8915 - loss: 0.2649 - val_binary_accuracy: 0.8480 - val_loss: 0.3835\n",
      "Epoch 148/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8847 - loss: 0.2680 - val_binary_accuracy: 0.8480 - val_loss: 0.3878\n",
      "Epoch 149/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8854 - loss: 0.2710 - val_binary_accuracy: 0.8400 - val_loss: 0.3852\n",
      "Epoch 150/10000\n",
      "47/47 - 1s - 14ms/step - binary_accuracy: 0.8949 - loss: 0.2645 - val_binary_accuracy: 0.8480 - val_loss: 0.3947\n",
      "Trained model saved to CNN_models/sdB_2025-10-30_model_7.keras\n",
      "Epoch 1/10000\n",
      "47/47 - 2s - 45ms/step - binary_accuracy: 0.5369 - loss: 0.6908 - val_binary_accuracy: 0.5360 - val_loss: 0.6911\n",
      "Epoch 2/10000\n",
      "47/47 - 1s - 12ms/step - binary_accuracy: 0.5396 - loss: 0.6907 - val_binary_accuracy: 0.5360 - val_loss: 0.6910\n",
      "Epoch 3/10000\n",
      "47/47 - 0s - 10ms/step - binary_accuracy: 0.5396 - loss: 0.6913 - val_binary_accuracy: 0.5360 - val_loss: 0.6905\n",
      "Epoch 4/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.5396 - loss: 0.6907 - val_binary_accuracy: 0.5360 - val_loss: 0.6905\n",
      "Epoch 5/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.5396 - loss: 0.6908 - val_binary_accuracy: 0.5360 - val_loss: 0.6904\n",
      "Epoch 6/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.5396 - loss: 0.6900 - val_binary_accuracy: 0.5360 - val_loss: 0.6902\n",
      "Epoch 7/10000\n",
      "47/47 - 0s - 10ms/step - binary_accuracy: 0.5396 - loss: 0.6897 - val_binary_accuracy: 0.5360 - val_loss: 0.6897\n",
      "Epoch 8/10000\n",
      "47/47 - 1s - 17ms/step - binary_accuracy: 0.5396 - loss: 0.6905 - val_binary_accuracy: 0.5360 - val_loss: 0.6893\n",
      "Epoch 9/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.5396 - loss: 0.6885 - val_binary_accuracy: 0.5360 - val_loss: 0.6888\n",
      "Epoch 10/10000\n",
      "47/47 - 1s - 13ms/step - binary_accuracy: 0.5396 - loss: 0.6873 - val_binary_accuracy: 0.5360 - val_loss: 0.6866\n",
      "Epoch 11/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.5396 - loss: 0.6854 - val_binary_accuracy: 0.5360 - val_loss: 0.6782\n",
      "Epoch 12/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.5714 - loss: 0.6669 - val_binary_accuracy: 0.8520 - val_loss: 0.6068\n",
      "Epoch 13/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.7833 - loss: 0.5353 - val_binary_accuracy: 0.8600 - val_loss: 0.4282\n",
      "Epoch 14/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8219 - loss: 0.4255 - val_binary_accuracy: 0.8360 - val_loss: 0.3954\n",
      "Epoch 15/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8321 - loss: 0.3930 - val_binary_accuracy: 0.8720 - val_loss: 0.3828\n",
      "Epoch 16/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8179 - loss: 0.3994 - val_binary_accuracy: 0.8680 - val_loss: 0.3744\n",
      "Epoch 17/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8409 - loss: 0.3686 - val_binary_accuracy: 0.8760 - val_loss: 0.3346\n",
      "Epoch 18/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8510 - loss: 0.3556 - val_binary_accuracy: 0.8760 - val_loss: 0.3289\n",
      "Epoch 19/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8490 - loss: 0.3491 - val_binary_accuracy: 0.8760 - val_loss: 0.3319\n",
      "Epoch 20/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8470 - loss: 0.3486 - val_binary_accuracy: 0.8760 - val_loss: 0.3316\n",
      "Epoch 21/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8565 - loss: 0.3412 - val_binary_accuracy: 0.8400 - val_loss: 0.3904\n",
      "Epoch 22/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8450 - loss: 0.3570 - val_binary_accuracy: 0.8080 - val_loss: 0.4213\n",
      "Epoch 23/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8585 - loss: 0.3447 - val_binary_accuracy: 0.8680 - val_loss: 0.3281\n",
      "Epoch 24/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8646 - loss: 0.3283 - val_binary_accuracy: 0.8120 - val_loss: 0.4186\n",
      "Epoch 25/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8477 - loss: 0.3492 - val_binary_accuracy: 0.8800 - val_loss: 0.3376\n",
      "Epoch 26/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8605 - loss: 0.3312 - val_binary_accuracy: 0.8040 - val_loss: 0.4354\n",
      "Epoch 27/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8544 - loss: 0.3422 - val_binary_accuracy: 0.8840 - val_loss: 0.3178\n",
      "Epoch 28/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8571 - loss: 0.3324 - val_binary_accuracy: 0.8760 - val_loss: 0.3231\n",
      "Epoch 29/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8659 - loss: 0.3274 - val_binary_accuracy: 0.8600 - val_loss: 0.3582\n",
      "Epoch 30/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8477 - loss: 0.3384 - val_binary_accuracy: 0.8760 - val_loss: 0.3197\n",
      "Epoch 31/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8632 - loss: 0.3256 - val_binary_accuracy: 0.8840 - val_loss: 0.3169\n",
      "Epoch 32/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8653 - loss: 0.3252 - val_binary_accuracy: 0.8760 - val_loss: 0.3190\n",
      "Epoch 33/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8592 - loss: 0.3244 - val_binary_accuracy: 0.8760 - val_loss: 0.3380\n",
      "Epoch 34/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8646 - loss: 0.3213 - val_binary_accuracy: 0.8800 - val_loss: 0.3180\n",
      "Epoch 35/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8585 - loss: 0.3420 - val_binary_accuracy: 0.8800 - val_loss: 0.3195\n",
      "Epoch 36/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8504 - loss: 0.3419 - val_binary_accuracy: 0.8760 - val_loss: 0.3276\n",
      "Epoch 37/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8531 - loss: 0.3453 - val_binary_accuracy: 0.8520 - val_loss: 0.3738\n",
      "Epoch 38/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8544 - loss: 0.3405 - val_binary_accuracy: 0.8720 - val_loss: 0.3243\n",
      "Epoch 39/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8693 - loss: 0.3170 - val_binary_accuracy: 0.8720 - val_loss: 0.3210\n",
      "Epoch 40/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8680 - loss: 0.3171 - val_binary_accuracy: 0.8040 - val_loss: 0.4327\n",
      "Epoch 41/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8619 - loss: 0.3373 - val_binary_accuracy: 0.8720 - val_loss: 0.3267\n",
      "Epoch 42/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8619 - loss: 0.3246 - val_binary_accuracy: 0.8800 - val_loss: 0.3208\n",
      "Epoch 43/10000\n",
      "47/47 - 1s - 14ms/step - binary_accuracy: 0.8585 - loss: 0.3270 - val_binary_accuracy: 0.8760 - val_loss: 0.3183\n",
      "Epoch 44/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8585 - loss: 0.3177 - val_binary_accuracy: 0.8840 - val_loss: 0.3164\n",
      "Epoch 45/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8700 - loss: 0.3215 - val_binary_accuracy: 0.8800 - val_loss: 0.3188\n",
      "Epoch 46/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8700 - loss: 0.3135 - val_binary_accuracy: 0.8800 - val_loss: 0.3355\n",
      "Epoch 47/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8605 - loss: 0.3246 - val_binary_accuracy: 0.8760 - val_loss: 0.3216\n",
      "Epoch 48/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8727 - loss: 0.3171 - val_binary_accuracy: 0.8840 - val_loss: 0.3173\n",
      "Epoch 49/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8707 - loss: 0.3121 - val_binary_accuracy: 0.8720 - val_loss: 0.3281\n",
      "Epoch 50/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8666 - loss: 0.3208 - val_binary_accuracy: 0.8600 - val_loss: 0.3574\n",
      "Epoch 51/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8585 - loss: 0.3282 - val_binary_accuracy: 0.8840 - val_loss: 0.3164\n",
      "Epoch 52/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8646 - loss: 0.3250 - val_binary_accuracy: 0.8760 - val_loss: 0.3245\n",
      "Epoch 53/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8612 - loss: 0.3217 - val_binary_accuracy: 0.8680 - val_loss: 0.3387\n",
      "Epoch 54/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8673 - loss: 0.3216 - val_binary_accuracy: 0.8760 - val_loss: 0.3234\n",
      "Epoch 55/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8646 - loss: 0.3202 - val_binary_accuracy: 0.8920 - val_loss: 0.3175\n",
      "Epoch 56/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8700 - loss: 0.3086 - val_binary_accuracy: 0.8880 - val_loss: 0.3187\n",
      "Epoch 57/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8666 - loss: 0.3179 - val_binary_accuracy: 0.8840 - val_loss: 0.3274\n",
      "Epoch 58/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8707 - loss: 0.3115 - val_binary_accuracy: 0.8760 - val_loss: 0.3207\n",
      "Epoch 59/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8754 - loss: 0.3062 - val_binary_accuracy: 0.8800 - val_loss: 0.3257\n",
      "Epoch 60/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8599 - loss: 0.3231 - val_binary_accuracy: 0.8840 - val_loss: 0.3192\n",
      "Epoch 61/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8646 - loss: 0.3218 - val_binary_accuracy: 0.8720 - val_loss: 0.3248\n",
      "Epoch 62/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8639 - loss: 0.3096 - val_binary_accuracy: 0.8920 - val_loss: 0.3172\n",
      "Epoch 63/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8700 - loss: 0.3102 - val_binary_accuracy: 0.8760 - val_loss: 0.3204\n",
      "Epoch 64/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8747 - loss: 0.3046 - val_binary_accuracy: 0.8760 - val_loss: 0.3343\n",
      "Epoch 65/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8578 - loss: 0.3301 - val_binary_accuracy: 0.8240 - val_loss: 0.3952\n",
      "Epoch 66/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8558 - loss: 0.3261 - val_binary_accuracy: 0.8800 - val_loss: 0.3200\n",
      "Epoch 67/10000\n",
      "47/47 - 1s - 13ms/step - binary_accuracy: 0.8754 - loss: 0.3052 - val_binary_accuracy: 0.8720 - val_loss: 0.3239\n",
      "Epoch 68/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8687 - loss: 0.3134 - val_binary_accuracy: 0.8800 - val_loss: 0.3240\n",
      "Epoch 69/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8693 - loss: 0.3116 - val_binary_accuracy: 0.8680 - val_loss: 0.3222\n",
      "Epoch 70/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8632 - loss: 0.3209 - val_binary_accuracy: 0.8880 - val_loss: 0.3174\n",
      "Epoch 71/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8619 - loss: 0.3255 - val_binary_accuracy: 0.8800 - val_loss: 0.3174\n",
      "Epoch 72/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8659 - loss: 0.3142 - val_binary_accuracy: 0.8800 - val_loss: 0.3184\n",
      "Epoch 73/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8700 - loss: 0.3070 - val_binary_accuracy: 0.8880 - val_loss: 0.3182\n",
      "Epoch 74/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8680 - loss: 0.3117 - val_binary_accuracy: 0.8800 - val_loss: 0.3216\n",
      "Epoch 75/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8693 - loss: 0.3110 - val_binary_accuracy: 0.8880 - val_loss: 0.3195\n",
      "Epoch 76/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8775 - loss: 0.3059 - val_binary_accuracy: 0.8680 - val_loss: 0.3411\n",
      "Epoch 77/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8707 - loss: 0.3067 - val_binary_accuracy: 0.8640 - val_loss: 0.3470\n",
      "Epoch 78/10000\n",
      "47/47 - 1s - 15ms/step - binary_accuracy: 0.8693 - loss: 0.3160 - val_binary_accuracy: 0.8800 - val_loss: 0.3210\n",
      "Epoch 79/10000\n",
      "47/47 - 1s - 11ms/step - binary_accuracy: 0.8653 - loss: 0.3106 - val_binary_accuracy: 0.8880 - val_loss: 0.3183\n",
      "Epoch 80/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8707 - loss: 0.3063 - val_binary_accuracy: 0.8360 - val_loss: 0.3906\n",
      "Epoch 81/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8741 - loss: 0.3125 - val_binary_accuracy: 0.8840 - val_loss: 0.3217\n",
      "Epoch 82/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8747 - loss: 0.3024 - val_binary_accuracy: 0.8880 - val_loss: 0.3210\n",
      "Epoch 83/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8700 - loss: 0.3123 - val_binary_accuracy: 0.8760 - val_loss: 0.3278\n",
      "Epoch 84/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8761 - loss: 0.3039 - val_binary_accuracy: 0.8760 - val_loss: 0.3235\n",
      "Epoch 85/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8653 - loss: 0.3053 - val_binary_accuracy: 0.8760 - val_loss: 0.3283\n",
      "Epoch 86/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8646 - loss: 0.3136 - val_binary_accuracy: 0.8680 - val_loss: 0.3310\n",
      "Epoch 87/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8666 - loss: 0.3058 - val_binary_accuracy: 0.8840 - val_loss: 0.3226\n",
      "Epoch 88/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8680 - loss: 0.3162 - val_binary_accuracy: 0.8720 - val_loss: 0.3356\n",
      "Epoch 89/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8700 - loss: 0.3102 - val_binary_accuracy: 0.8800 - val_loss: 0.3249\n",
      "Epoch 90/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8714 - loss: 0.3020 - val_binary_accuracy: 0.8560 - val_loss: 0.3520\n",
      "Epoch 91/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8605 - loss: 0.3243 - val_binary_accuracy: 0.8640 - val_loss: 0.3573\n",
      "Epoch 92/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8720 - loss: 0.3030 - val_binary_accuracy: 0.8800 - val_loss: 0.3191\n",
      "Epoch 93/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8775 - loss: 0.3032 - val_binary_accuracy: 0.8840 - val_loss: 0.3187\n",
      "Epoch 94/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8605 - loss: 0.3273 - val_binary_accuracy: 0.8600 - val_loss: 0.3584\n",
      "Epoch 95/10000\n",
      "47/47 - 1s - 14ms/step - binary_accuracy: 0.8741 - loss: 0.3092 - val_binary_accuracy: 0.8880 - val_loss: 0.3194\n",
      "Epoch 96/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8646 - loss: 0.3134 - val_binary_accuracy: 0.8640 - val_loss: 0.3333\n",
      "Epoch 97/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8754 - loss: 0.3008 - val_binary_accuracy: 0.8880 - val_loss: 0.3199\n",
      "Epoch 98/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8768 - loss: 0.3047 - val_binary_accuracy: 0.8800 - val_loss: 0.3240\n",
      "Epoch 99/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8781 - loss: 0.2930 - val_binary_accuracy: 0.8840 - val_loss: 0.3209\n",
      "Epoch 100/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8653 - loss: 0.3212 - val_binary_accuracy: 0.9000 - val_loss: 0.3216\n",
      "Epoch 101/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8741 - loss: 0.2979 - val_binary_accuracy: 0.8600 - val_loss: 0.3442\n",
      "Epoch 102/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8653 - loss: 0.3092 - val_binary_accuracy: 0.8800 - val_loss: 0.3188\n",
      "Epoch 103/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8802 - loss: 0.2937 - val_binary_accuracy: 0.8960 - val_loss: 0.3211\n",
      "Epoch 104/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8747 - loss: 0.3018 - val_binary_accuracy: 0.8680 - val_loss: 0.3375\n",
      "Epoch 105/10000\n",
      "47/47 - 0s - 10ms/step - binary_accuracy: 0.8714 - loss: 0.3090 - val_binary_accuracy: 0.8840 - val_loss: 0.3252\n",
      "Epoch 106/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8707 - loss: 0.3095 - val_binary_accuracy: 0.8680 - val_loss: 0.3314\n",
      "Epoch 107/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8835 - loss: 0.2910 - val_binary_accuracy: 0.8680 - val_loss: 0.3279\n",
      "Epoch 108/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8734 - loss: 0.3042 - val_binary_accuracy: 0.8800 - val_loss: 0.3243\n",
      "Epoch 109/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8626 - loss: 0.3256 - val_binary_accuracy: 0.8840 - val_loss: 0.3177\n",
      "Epoch 110/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8754 - loss: 0.3061 - val_binary_accuracy: 0.8840 - val_loss: 0.3169\n",
      "Epoch 111/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8700 - loss: 0.3088 - val_binary_accuracy: 0.8720 - val_loss: 0.3266\n",
      "Epoch 112/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8822 - loss: 0.2961 - val_binary_accuracy: 0.8600 - val_loss: 0.3521\n",
      "Epoch 113/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8741 - loss: 0.2991 - val_binary_accuracy: 0.8800 - val_loss: 0.3216\n",
      "Epoch 114/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8815 - loss: 0.2906 - val_binary_accuracy: 0.8800 - val_loss: 0.3197\n",
      "Epoch 115/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8707 - loss: 0.3007 - val_binary_accuracy: 0.8840 - val_loss: 0.3169\n",
      "Epoch 116/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8822 - loss: 0.2944 - val_binary_accuracy: 0.8520 - val_loss: 0.3502\n",
      "Epoch 117/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8808 - loss: 0.2945 - val_binary_accuracy: 0.8680 - val_loss: 0.3395\n",
      "Epoch 118/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8693 - loss: 0.3053 - val_binary_accuracy: 0.8720 - val_loss: 0.3450\n",
      "Epoch 119/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8720 - loss: 0.2987 - val_binary_accuracy: 0.8720 - val_loss: 0.3402\n",
      "Epoch 120/10000\n",
      "47/47 - 1s - 14ms/step - binary_accuracy: 0.8734 - loss: 0.2978 - val_binary_accuracy: 0.8640 - val_loss: 0.3424\n",
      "Epoch 121/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8720 - loss: 0.3053 - val_binary_accuracy: 0.8720 - val_loss: 0.3256\n",
      "Epoch 122/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8802 - loss: 0.2878 - val_binary_accuracy: 0.8840 - val_loss: 0.3191\n",
      "Epoch 123/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8761 - loss: 0.2937 - val_binary_accuracy: 0.8760 - val_loss: 0.3318\n",
      "Epoch 124/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8822 - loss: 0.2850 - val_binary_accuracy: 0.8760 - val_loss: 0.3326\n",
      "Epoch 125/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8761 - loss: 0.2928 - val_binary_accuracy: 0.8640 - val_loss: 0.3251\n",
      "Epoch 126/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8808 - loss: 0.2865 - val_binary_accuracy: 0.8800 - val_loss: 0.3205\n",
      "Epoch 127/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8802 - loss: 0.2853 - val_binary_accuracy: 0.8680 - val_loss: 0.3384\n",
      "Epoch 128/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8680 - loss: 0.3096 - val_binary_accuracy: 0.8280 - val_loss: 0.3792\n",
      "Epoch 129/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8795 - loss: 0.2940 - val_binary_accuracy: 0.8800 - val_loss: 0.3212\n",
      "Epoch 130/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8761 - loss: 0.2925 - val_binary_accuracy: 0.8840 - val_loss: 0.3268\n",
      "Epoch 131/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8802 - loss: 0.2852 - val_binary_accuracy: 0.8800 - val_loss: 0.3210\n",
      "Epoch 132/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8775 - loss: 0.2919 - val_binary_accuracy: 0.8640 - val_loss: 0.3574\n",
      "Epoch 133/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8781 - loss: 0.2935 - val_binary_accuracy: 0.8840 - val_loss: 0.3226\n",
      "Epoch 134/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8802 - loss: 0.2791 - val_binary_accuracy: 0.8640 - val_loss: 0.3395\n",
      "Epoch 135/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8842 - loss: 0.2803 - val_binary_accuracy: 0.8640 - val_loss: 0.3442\n",
      "Epoch 136/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8808 - loss: 0.2872 - val_binary_accuracy: 0.8800 - val_loss: 0.3245\n",
      "Epoch 137/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8802 - loss: 0.2867 - val_binary_accuracy: 0.8800 - val_loss: 0.3256\n",
      "Epoch 138/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8788 - loss: 0.2873 - val_binary_accuracy: 0.8600 - val_loss: 0.3438\n",
      "Epoch 139/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8714 - loss: 0.3013 - val_binary_accuracy: 0.8640 - val_loss: 0.3493\n",
      "Epoch 140/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8822 - loss: 0.2821 - val_binary_accuracy: 0.8760 - val_loss: 0.3237\n",
      "Epoch 141/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8802 - loss: 0.2827 - val_binary_accuracy: 0.8840 - val_loss: 0.3258\n",
      "Epoch 142/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8822 - loss: 0.2793 - val_binary_accuracy: 0.8760 - val_loss: 0.3250\n",
      "Epoch 143/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8876 - loss: 0.2780 - val_binary_accuracy: 0.8800 - val_loss: 0.3404\n",
      "Epoch 144/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8808 - loss: 0.2778 - val_binary_accuracy: 0.8640 - val_loss: 0.3430\n",
      "Epoch 145/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8687 - loss: 0.2906 - val_binary_accuracy: 0.8840 - val_loss: 0.3231\n",
      "Epoch 146/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8829 - loss: 0.2807 - val_binary_accuracy: 0.8840 - val_loss: 0.3324\n",
      "Epoch 147/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8842 - loss: 0.2747 - val_binary_accuracy: 0.8800 - val_loss: 0.3325\n",
      "Epoch 148/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8815 - loss: 0.2841 - val_binary_accuracy: 0.8640 - val_loss: 0.3723\n",
      "Epoch 149/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8734 - loss: 0.2887 - val_binary_accuracy: 0.8800 - val_loss: 0.3270\n",
      "Epoch 150/10000\n",
      "47/47 - 1s - 15ms/step - binary_accuracy: 0.8775 - loss: 0.2783 - val_binary_accuracy: 0.8760 - val_loss: 0.3306\n",
      "Trained model saved to CNN_models/sdB_2025-10-30_model_8.keras\n",
      "Epoch 1/10000\n",
      "47/47 - 2s - 45ms/step - binary_accuracy: 0.5434 - loss: 0.6912 - val_binary_accuracy: 0.5120 - val_loss: 0.6937\n",
      "Epoch 2/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.5434 - loss: 0.6898 - val_binary_accuracy: 0.5120 - val_loss: 0.6953\n",
      "Epoch 3/10000\n",
      "47/47 - 0s - 10ms/step - binary_accuracy: 0.5434 - loss: 0.6895 - val_binary_accuracy: 0.5120 - val_loss: 0.6929\n",
      "Epoch 4/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.5434 - loss: 0.6891 - val_binary_accuracy: 0.5120 - val_loss: 0.6938\n",
      "Epoch 5/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.5434 - loss: 0.6891 - val_binary_accuracy: 0.5120 - val_loss: 0.6951\n",
      "Epoch 6/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.5434 - loss: 0.6896 - val_binary_accuracy: 0.5120 - val_loss: 0.6966\n",
      "Epoch 7/10000\n",
      "47/47 - 0s - 10ms/step - binary_accuracy: 0.5434 - loss: 0.6895 - val_binary_accuracy: 0.5120 - val_loss: 0.6924\n",
      "Epoch 8/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.5434 - loss: 0.6883 - val_binary_accuracy: 0.5120 - val_loss: 0.6913\n",
      "Epoch 9/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.5434 - loss: 0.6876 - val_binary_accuracy: 0.5120 - val_loss: 0.6907\n",
      "Epoch 10/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.5434 - loss: 0.6852 - val_binary_accuracy: 0.5120 - val_loss: 0.6858\n",
      "Epoch 11/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.5440 - loss: 0.6780 - val_binary_accuracy: 0.5120 - val_loss: 0.6828\n",
      "Epoch 12/10000\n",
      "47/47 - 0s - 10ms/step - binary_accuracy: 0.6321 - loss: 0.6520 - val_binary_accuracy: 0.7720 - val_loss: 0.6301\n",
      "Epoch 13/10000\n",
      "47/47 - 0s - 10ms/step - binary_accuracy: 0.7263 - loss: 0.5895 - val_binary_accuracy: 0.7120 - val_loss: 0.6173\n",
      "Epoch 14/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.7940 - loss: 0.5061 - val_binary_accuracy: 0.7960 - val_loss: 0.4584\n",
      "Epoch 15/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.7981 - loss: 0.4604 - val_binary_accuracy: 0.7240 - val_loss: 0.5229\n",
      "Epoch 16/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8388 - loss: 0.4106 - val_binary_accuracy: 0.7600 - val_loss: 0.4752\n",
      "Epoch 17/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8266 - loss: 0.4080 - val_binary_accuracy: 0.8600 - val_loss: 0.3611\n",
      "Epoch 18/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8462 - loss: 0.3773 - val_binary_accuracy: 0.8560 - val_loss: 0.3423\n",
      "Epoch 19/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8415 - loss: 0.3765 - val_binary_accuracy: 0.7920 - val_loss: 0.4224\n",
      "Epoch 20/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8509 - loss: 0.3667 - val_binary_accuracy: 0.8440 - val_loss: 0.3479\n",
      "Epoch 21/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8584 - loss: 0.3450 - val_binary_accuracy: 0.8520 - val_loss: 0.3306\n",
      "Epoch 22/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8550 - loss: 0.3536 - val_binary_accuracy: 0.8560 - val_loss: 0.3195\n",
      "Epoch 23/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8679 - loss: 0.3350 - val_binary_accuracy: 0.8560 - val_loss: 0.3224\n",
      "Epoch 24/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8503 - loss: 0.3651 - val_binary_accuracy: 0.8720 - val_loss: 0.3167\n",
      "Epoch 25/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8652 - loss: 0.3351 - val_binary_accuracy: 0.8320 - val_loss: 0.3680\n",
      "Epoch 26/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8476 - loss: 0.3460 - val_binary_accuracy: 0.8560 - val_loss: 0.3231\n",
      "Epoch 27/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8313 - loss: 0.3897 - val_binary_accuracy: 0.8360 - val_loss: 0.3645\n",
      "Epoch 28/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8503 - loss: 0.3558 - val_binary_accuracy: 0.8640 - val_loss: 0.3141\n",
      "Epoch 29/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8638 - loss: 0.3279 - val_binary_accuracy: 0.8680 - val_loss: 0.3068\n",
      "Epoch 30/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8652 - loss: 0.3261 - val_binary_accuracy: 0.8520 - val_loss: 0.3208\n",
      "Epoch 31/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8631 - loss: 0.3292 - val_binary_accuracy: 0.8840 - val_loss: 0.3047\n",
      "Epoch 32/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8598 - loss: 0.3383 - val_binary_accuracy: 0.8680 - val_loss: 0.3126\n",
      "Epoch 33/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8584 - loss: 0.3241 - val_binary_accuracy: 0.8160 - val_loss: 0.3843\n",
      "Epoch 34/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8428 - loss: 0.3512 - val_binary_accuracy: 0.8280 - val_loss: 0.3593\n",
      "Epoch 35/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8611 - loss: 0.3297 - val_binary_accuracy: 0.8560 - val_loss: 0.3215\n",
      "Epoch 36/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8686 - loss: 0.3292 - val_binary_accuracy: 0.8760 - val_loss: 0.3023\n",
      "Epoch 37/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8604 - loss: 0.3311 - val_binary_accuracy: 0.8760 - val_loss: 0.3021\n",
      "Epoch 38/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8584 - loss: 0.3229 - val_binary_accuracy: 0.8440 - val_loss: 0.3426\n",
      "Epoch 39/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8686 - loss: 0.3264 - val_binary_accuracy: 0.8720 - val_loss: 0.3015\n",
      "Epoch 40/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8557 - loss: 0.3304 - val_binary_accuracy: 0.8640 - val_loss: 0.3018\n",
      "Epoch 41/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8618 - loss: 0.3222 - val_binary_accuracy: 0.8760 - val_loss: 0.3112\n",
      "Epoch 42/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8631 - loss: 0.3280 - val_binary_accuracy: 0.8800 - val_loss: 0.3036\n",
      "Epoch 43/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8564 - loss: 0.3416 - val_binary_accuracy: 0.8720 - val_loss: 0.3075\n",
      "Epoch 44/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8570 - loss: 0.3377 - val_binary_accuracy: 0.8680 - val_loss: 0.3084\n",
      "Epoch 45/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8686 - loss: 0.3275 - val_binary_accuracy: 0.8200 - val_loss: 0.3922\n",
      "Epoch 46/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8482 - loss: 0.3439 - val_binary_accuracy: 0.8800 - val_loss: 0.3066\n",
      "Epoch 47/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8638 - loss: 0.3198 - val_binary_accuracy: 0.8720 - val_loss: 0.3144\n",
      "Epoch 48/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8631 - loss: 0.3214 - val_binary_accuracy: 0.8680 - val_loss: 0.3137\n",
      "Epoch 49/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8726 - loss: 0.3173 - val_binary_accuracy: 0.8800 - val_loss: 0.3041\n",
      "Epoch 50/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8659 - loss: 0.3135 - val_binary_accuracy: 0.8640 - val_loss: 0.3003\n",
      "Epoch 51/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8672 - loss: 0.3206 - val_binary_accuracy: 0.8760 - val_loss: 0.3025\n",
      "Epoch 52/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8679 - loss: 0.3230 - val_binary_accuracy: 0.8680 - val_loss: 0.3047\n",
      "Epoch 53/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8638 - loss: 0.3336 - val_binary_accuracy: 0.8440 - val_loss: 0.3320\n",
      "Epoch 54/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8523 - loss: 0.3401 - val_binary_accuracy: 0.8520 - val_loss: 0.3381\n",
      "Epoch 55/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8706 - loss: 0.3195 - val_binary_accuracy: 0.8720 - val_loss: 0.3020\n",
      "Epoch 56/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8672 - loss: 0.3169 - val_binary_accuracy: 0.8760 - val_loss: 0.3019\n",
      "Epoch 57/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8618 - loss: 0.3220 - val_binary_accuracy: 0.8760 - val_loss: 0.3106\n",
      "Epoch 58/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8672 - loss: 0.3167 - val_binary_accuracy: 0.8720 - val_loss: 0.3055\n",
      "Epoch 59/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8692 - loss: 0.3142 - val_binary_accuracy: 0.8680 - val_loss: 0.3007\n",
      "Epoch 60/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8611 - loss: 0.3457 - val_binary_accuracy: 0.8600 - val_loss: 0.3225\n",
      "Epoch 61/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8503 - loss: 0.3339 - val_binary_accuracy: 0.8720 - val_loss: 0.3083\n",
      "Epoch 62/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8720 - loss: 0.3119 - val_binary_accuracy: 0.8600 - val_loss: 0.3231\n",
      "Epoch 63/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8692 - loss: 0.3269 - val_binary_accuracy: 0.8720 - val_loss: 0.3046\n",
      "Epoch 64/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8692 - loss: 0.3116 - val_binary_accuracy: 0.8720 - val_loss: 0.3026\n",
      "Epoch 65/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8618 - loss: 0.3305 - val_binary_accuracy: 0.8720 - val_loss: 0.3103\n",
      "Epoch 66/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8598 - loss: 0.3191 - val_binary_accuracy: 0.8640 - val_loss: 0.3194\n",
      "Epoch 67/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8706 - loss: 0.3144 - val_binary_accuracy: 0.8640 - val_loss: 0.3178\n",
      "Epoch 68/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8570 - loss: 0.3417 - val_binary_accuracy: 0.8640 - val_loss: 0.3101\n",
      "Epoch 69/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8692 - loss: 0.3159 - val_binary_accuracy: 0.8600 - val_loss: 0.3067\n",
      "Epoch 70/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8631 - loss: 0.3182 - val_binary_accuracy: 0.8360 - val_loss: 0.3535\n",
      "Epoch 71/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8740 - loss: 0.3174 - val_binary_accuracy: 0.8560 - val_loss: 0.3382\n",
      "Epoch 72/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8625 - loss: 0.3206 - val_binary_accuracy: 0.8680 - val_loss: 0.3064\n",
      "Epoch 73/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8699 - loss: 0.3101 - val_binary_accuracy: 0.8760 - val_loss: 0.3099\n",
      "Epoch 74/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8672 - loss: 0.3125 - val_binary_accuracy: 0.8680 - val_loss: 0.3043\n",
      "Epoch 75/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8665 - loss: 0.3168 - val_binary_accuracy: 0.8680 - val_loss: 0.3063\n",
      "Epoch 76/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8699 - loss: 0.3113 - val_binary_accuracy: 0.8720 - val_loss: 0.3161\n",
      "Epoch 77/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8659 - loss: 0.3182 - val_binary_accuracy: 0.8760 - val_loss: 0.3074\n",
      "Epoch 78/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8679 - loss: 0.3140 - val_binary_accuracy: 0.8720 - val_loss: 0.3079\n",
      "Epoch 79/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8591 - loss: 0.3172 - val_binary_accuracy: 0.8800 - val_loss: 0.3114\n",
      "Epoch 80/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8604 - loss: 0.3243 - val_binary_accuracy: 0.8680 - val_loss: 0.3082\n",
      "Epoch 81/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8699 - loss: 0.3111 - val_binary_accuracy: 0.8760 - val_loss: 0.3091\n",
      "Epoch 82/10000\n",
      "47/47 - 0s - 10ms/step - binary_accuracy: 0.8726 - loss: 0.3102 - val_binary_accuracy: 0.8680 - val_loss: 0.3060\n",
      "Epoch 83/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8760 - loss: 0.3068 - val_binary_accuracy: 0.8640 - val_loss: 0.3076\n",
      "Epoch 84/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8672 - loss: 0.3083 - val_binary_accuracy: 0.8680 - val_loss: 0.3061\n",
      "Epoch 85/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8747 - loss: 0.3081 - val_binary_accuracy: 0.8720 - val_loss: 0.3124\n",
      "Epoch 86/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8706 - loss: 0.3158 - val_binary_accuracy: 0.8640 - val_loss: 0.3058\n",
      "Epoch 87/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8706 - loss: 0.3077 - val_binary_accuracy: 0.8640 - val_loss: 0.3132\n",
      "Epoch 88/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8740 - loss: 0.3053 - val_binary_accuracy: 0.8640 - val_loss: 0.3080\n",
      "Epoch 89/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8686 - loss: 0.3066 - val_binary_accuracy: 0.8680 - val_loss: 0.3127\n",
      "Epoch 90/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8598 - loss: 0.3245 - val_binary_accuracy: 0.8680 - val_loss: 0.3034\n",
      "Epoch 91/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8740 - loss: 0.3154 - val_binary_accuracy: 0.8640 - val_loss: 0.3268\n",
      "Epoch 92/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8659 - loss: 0.3144 - val_binary_accuracy: 0.8680 - val_loss: 0.3069\n",
      "Epoch 93/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8733 - loss: 0.3045 - val_binary_accuracy: 0.8680 - val_loss: 0.3094\n",
      "Epoch 94/10000\n",
      "47/47 - 1s - 14ms/step - binary_accuracy: 0.8652 - loss: 0.3040 - val_binary_accuracy: 0.8680 - val_loss: 0.3048\n",
      "Epoch 95/10000\n",
      "47/47 - 1s - 15ms/step - binary_accuracy: 0.8740 - loss: 0.3049 - val_binary_accuracy: 0.8520 - val_loss: 0.3469\n",
      "Epoch 96/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8638 - loss: 0.3111 - val_binary_accuracy: 0.8680 - val_loss: 0.3111\n",
      "Epoch 97/10000\n",
      "47/47 - 1s - 14ms/step - binary_accuracy: 0.8570 - loss: 0.3523 - val_binary_accuracy: 0.8720 - val_loss: 0.3137\n",
      "Epoch 98/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8713 - loss: 0.3176 - val_binary_accuracy: 0.8720 - val_loss: 0.3062\n",
      "Epoch 99/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8692 - loss: 0.3084 - val_binary_accuracy: 0.8760 - val_loss: 0.3123\n",
      "Epoch 100/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8720 - loss: 0.3088 - val_binary_accuracy: 0.8760 - val_loss: 0.3071\n",
      "Epoch 101/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8699 - loss: 0.3139 - val_binary_accuracy: 0.8680 - val_loss: 0.3061\n",
      "Epoch 102/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8733 - loss: 0.3110 - val_binary_accuracy: 0.8000 - val_loss: 0.4140\n",
      "Epoch 103/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8543 - loss: 0.3452 - val_binary_accuracy: 0.8680 - val_loss: 0.3041\n",
      "Epoch 104/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8672 - loss: 0.3134 - val_binary_accuracy: 0.8800 - val_loss: 0.3080\n",
      "Epoch 105/10000\n",
      "47/47 - 0s - 10ms/step - binary_accuracy: 0.8720 - loss: 0.3053 - val_binary_accuracy: 0.8680 - val_loss: 0.2978\n",
      "Epoch 106/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8638 - loss: 0.3234 - val_binary_accuracy: 0.8640 - val_loss: 0.3152\n",
      "Epoch 107/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8638 - loss: 0.3107 - val_binary_accuracy: 0.8680 - val_loss: 0.3003\n",
      "Epoch 108/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8713 - loss: 0.3107 - val_binary_accuracy: 0.8720 - val_loss: 0.3078\n",
      "Epoch 109/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8740 - loss: 0.3039 - val_binary_accuracy: 0.8720 - val_loss: 0.3190\n",
      "Epoch 110/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8760 - loss: 0.3060 - val_binary_accuracy: 0.8720 - val_loss: 0.3176\n",
      "Epoch 111/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8740 - loss: 0.3040 - val_binary_accuracy: 0.8520 - val_loss: 0.3399\n",
      "Epoch 112/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8699 - loss: 0.3085 - val_binary_accuracy: 0.8720 - val_loss: 0.3164\n",
      "Epoch 113/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8753 - loss: 0.2999 - val_binary_accuracy: 0.8680 - val_loss: 0.3017\n",
      "Epoch 114/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8733 - loss: 0.3026 - val_binary_accuracy: 0.8720 - val_loss: 0.3053\n",
      "Epoch 115/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8774 - loss: 0.3004 - val_binary_accuracy: 0.8720 - val_loss: 0.3041\n",
      "Epoch 116/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8733 - loss: 0.2990 - val_binary_accuracy: 0.8680 - val_loss: 0.3077\n",
      "Epoch 117/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8801 - loss: 0.3010 - val_binary_accuracy: 0.8680 - val_loss: 0.3015\n",
      "Epoch 118/10000\n",
      "47/47 - 0s - 10ms/step - binary_accuracy: 0.8848 - loss: 0.2987 - val_binary_accuracy: 0.8720 - val_loss: 0.3311\n",
      "Epoch 119/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8706 - loss: 0.3159 - val_binary_accuracy: 0.8720 - val_loss: 0.3128\n",
      "Epoch 120/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8659 - loss: 0.3102 - val_binary_accuracy: 0.8640 - val_loss: 0.3040\n",
      "Epoch 121/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8726 - loss: 0.2961 - val_binary_accuracy: 0.8680 - val_loss: 0.3309\n",
      "Epoch 122/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8713 - loss: 0.3078 - val_binary_accuracy: 0.8680 - val_loss: 0.3007\n",
      "Epoch 123/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8767 - loss: 0.3016 - val_binary_accuracy: 0.8760 - val_loss: 0.3029\n",
      "Epoch 124/10000\n",
      "47/47 - 0s - 10ms/step - binary_accuracy: 0.8747 - loss: 0.2979 - val_binary_accuracy: 0.8720 - val_loss: 0.3018\n",
      "Epoch 125/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8740 - loss: 0.2969 - val_binary_accuracy: 0.8640 - val_loss: 0.3019\n",
      "Epoch 126/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8760 - loss: 0.2962 - val_binary_accuracy: 0.8720 - val_loss: 0.3191\n",
      "Epoch 127/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8794 - loss: 0.3009 - val_binary_accuracy: 0.8680 - val_loss: 0.3103\n",
      "Epoch 128/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8767 - loss: 0.2933 - val_binary_accuracy: 0.8680 - val_loss: 0.3174\n",
      "Epoch 129/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8760 - loss: 0.2949 - val_binary_accuracy: 0.8640 - val_loss: 0.3267\n",
      "Epoch 130/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8706 - loss: 0.3004 - val_binary_accuracy: 0.8680 - val_loss: 0.3355\n",
      "Epoch 131/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8631 - loss: 0.3322 - val_binary_accuracy: 0.8440 - val_loss: 0.3504\n",
      "Epoch 132/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8584 - loss: 0.3220 - val_binary_accuracy: 0.8640 - val_loss: 0.3310\n",
      "Epoch 133/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8625 - loss: 0.3218 - val_binary_accuracy: 0.8680 - val_loss: 0.2981\n",
      "Epoch 134/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8753 - loss: 0.2922 - val_binary_accuracy: 0.8680 - val_loss: 0.2990\n",
      "Epoch 135/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8787 - loss: 0.2916 - val_binary_accuracy: 0.8720 - val_loss: 0.3203\n",
      "Epoch 136/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8733 - loss: 0.2965 - val_binary_accuracy: 0.8680 - val_loss: 0.2976\n",
      "Epoch 137/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8767 - loss: 0.2941 - val_binary_accuracy: 0.8760 - val_loss: 0.3005\n",
      "Epoch 138/10000\n",
      "47/47 - 0s - 10ms/step - binary_accuracy: 0.8686 - loss: 0.3092 - val_binary_accuracy: 0.8720 - val_loss: 0.3017\n",
      "Epoch 139/10000\n",
      "47/47 - 0s - 10ms/step - binary_accuracy: 0.8740 - loss: 0.2994 - val_binary_accuracy: 0.8680 - val_loss: 0.3004\n",
      "Epoch 140/10000\n",
      "47/47 - 1s - 13ms/step - binary_accuracy: 0.8760 - loss: 0.2949 - val_binary_accuracy: 0.8720 - val_loss: 0.2980\n",
      "Epoch 141/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8780 - loss: 0.2883 - val_binary_accuracy: 0.8720 - val_loss: 0.2996\n",
      "Epoch 142/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8794 - loss: 0.2911 - val_binary_accuracy: 0.8680 - val_loss: 0.3025\n",
      "Epoch 143/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8835 - loss: 0.2887 - val_binary_accuracy: 0.8720 - val_loss: 0.2976\n",
      "Epoch 144/10000\n",
      "47/47 - 1s - 15ms/step - binary_accuracy: 0.8774 - loss: 0.3019 - val_binary_accuracy: 0.8280 - val_loss: 0.3635\n",
      "Epoch 145/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8733 - loss: 0.2994 - val_binary_accuracy: 0.8360 - val_loss: 0.3595\n",
      "Epoch 146/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8780 - loss: 0.2969 - val_binary_accuracy: 0.8720 - val_loss: 0.2991\n",
      "Epoch 147/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8760 - loss: 0.2984 - val_binary_accuracy: 0.8800 - val_loss: 0.2942\n",
      "Epoch 148/10000\n",
      "47/47 - 0s - 9ms/step - binary_accuracy: 0.8753 - loss: 0.2995 - val_binary_accuracy: 0.8760 - val_loss: 0.2957\n",
      "Epoch 149/10000\n",
      "47/47 - 0s - 8ms/step - binary_accuracy: 0.8767 - loss: 0.2965 - val_binary_accuracy: 0.8600 - val_loss: 0.3094\n",
      "Epoch 150/10000\n",
      "47/47 - 0s - 7ms/step - binary_accuracy: 0.8808 - loss: 0.2920 - val_binary_accuracy: 0.8640 - val_loss: 0.3051\n",
      "Trained model saved to CNN_models/sdB_2025-10-30_model_9.keras\n"
     ]
    }
   ],
   "source": [
    "# Number of CNN models train in ensemble\n",
    "n_models = 10\n",
    "\n",
    "# Early stopping callback to halt training if validation loss doesn't improve\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\",\n",
    "                                              mode=\"min\",\n",
    "                                              patience=100,\n",
    "                                              start_from_epoch=50,\n",
    "                                              restore_best_weights=False)\n",
    "\n",
    "for n in range(n_models):\n",
    "\n",
    "    # Generate timestamped model path\n",
    "    date_stamp = datetime.today().strftime('%Y-%m-%d')\n",
    "    model_path = f\"CNN_models/sdB_{date_stamp}_model_{n}.keras\"\n",
    "\n",
    "    # Checkpoint callback to save the best model during training\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(model_path,\n",
    "                                                    monitor=\"val_loss\",\n",
    "                                                    mode=\"min\",\n",
    "                                                    save_best_only=True,\n",
    "                                                    verbose=0)\n",
    "\n",
    "    # Create new training and validation sets for this run\n",
    "    fluxes_train, fluxes_val = make_train_val(fluxes_train_val, n_val)\n",
    "\n",
    "    # Build and compile the CNN model\n",
    "    model = make_model()\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "    model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"binary_accuracy\"])\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(x=fluxes_train[wvl_columns], y=fluxes_train[\"label\"],\n",
    "              validation_data=(fluxes_val[wvl_columns], fluxes_val[\"label\"]),\n",
    "              epochs=10000,\n",
    "              batch_size=32,\n",
    "              callbacks=[early_stop, checkpoint],\n",
    "              verbose=2)\n",
    "\n",
    "    print(f\"Trained model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e967b1d4-629c-4487-8b41-346e8c1f7fd2",
   "metadata": {},
   "source": [
    "### Pick best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65416b5f-4d31-4f74-8336-03065304b3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_losses(date_stamp, data_test, n_models):\n",
    "    \"\"\"\n",
    "    Evaluate multiple Keras models and return their test losses.\n",
    "\n",
    "    Parameters:\n",
    "    - date_stamp (str): Date identifier used in model filenames.\n",
    "    - data_test (DataFrame): Test dataset containing input features and target labels.\n",
    "    - n_runs (int): Number of model runs to evaluate.\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray: Array of test losses for each model.\n",
    "    \"\"\"\n",
    "    model_losses = []\n",
    "\n",
    "    for n in range(n_models):\n",
    "        # Construct the model file path\n",
    "        model_path = f\"CNN_models/sdB_{date_stamp}_model_{n}.keras\"\n",
    "        \n",
    "        # Load the trained model\n",
    "        model = keras.models.load_model(model_path)\n",
    "        \n",
    "        # Evaluate the model on the test set\n",
    "        eval_loss = model.evaluate(\n",
    "                                    data_test[wvl_columns],               # Input features\n",
    "                                    data_test[\"label\"],                   # Target labels\n",
    "                                    batch_size=16,\n",
    "                                    verbose=0)[0]\n",
    "\n",
    "        print(f\"Test loss of model {model_path}: {eval_loss:.4f}\")\n",
    "        model_losses.append(eval_loss)\n",
    "\n",
    "    print(\"\\nDisplayed losses do not have class weights.\\n\")\n",
    "\n",
    "    return np.array(model_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3794cb37-b9a4-4853-9a7a-f7a72b02e6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "date_stamp = \"2025-10-30\"\n",
    "n_models = 10\n",
    "n_keep = 5\n",
    "\n",
    "# Evaluate models and get their losses for the test set\n",
    "model_losses = get_model_losses(date_stamp, fluxes_test, n_models)\n",
    "\n",
    "# Identify indices of the best-performing models (lowest losses)\n",
    "i_best_models = np.argsort(model_losses)[:n_keep]\n",
    "\n",
    "print(f\"\\nIndices of the {n_keep} best models: {i_best_models}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bda9c7-b883-4b0d-ab02-ee2953bd7335",
   "metadata": {},
   "source": [
    "### Evaluate best models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb858b92-7558-42f1-8831-d9fa311cf078",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_set(data_set, i_best_models, date_stamp):\n",
    "    \"\"\"\n",
    "    Evaluate an ensemble of the best models on a given dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - data_set (DataFrame): Dataset containing features and true labels.\n",
    "    - i_best_models (list or array): Indices of the best-performing models.\n",
    "    - date_stamp (str): Date identifier used in model filenames.\n",
    "\n",
    "    Returns:\n",
    "    - None (prints evaluation metrics)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize array to store predictions from each model\n",
    "    predictions_runs = np.zeros((len(i_best_models), len(data_set)))\n",
    "\n",
    "    for a, i in enumerate(i_best_models):\n",
    "        # Construct model path using the index of the best model\n",
    "        model_path = f\"CNN_models/sdB_{date_stamp}_model_{n}.keras\"\n",
    "        \n",
    "        # Load the model\n",
    "        model = keras.models.load_model(model_path)\n",
    "        \n",
    "        # Predict and store the results\n",
    "        predictions = model.predict(data_set[wvl_columns], verbose=0).flatten()\n",
    "        predictions_runs[a, :] = predictions\n",
    "\n",
    "    # Compute mean and standard deviation of predictions across models\n",
    "    predictions_mean = np.mean(predictions_runs, axis=0)\n",
    "    predictions_std = np.std(predictions_runs, axis=0)\n",
    "\n",
    "    # Create a DataFrame to store predictions and true labels\n",
    "    p = pd.DataFrame({\"label\": data_set[\"label\"], \"prediction\": predictions_mean, \"std\": predictions_std})\n",
    "\n",
    "    # Threshold that maximises F1 score\n",
    "    precision, recall, thresholds = sklearn.metrics.precision_recall_curve(p[\"label\"], p[\"prediction\"])\n",
    "    numerator = 2 * recall * precision\n",
    "    denom = recall + precision\n",
    "    f1_scores = np.divide(numerator, denom, out=np.zeros_like(denom), where=(denom!=0))\n",
    "    max_f1_thresh = thresholds[np.argmax(f1_scores)]\n",
    "\n",
    "    print(f\"Threshold that maximizes F1: {max_f1_thresh:.3f}\")\n",
    "    print()\n",
    "    print(\"With that threshold:\")\n",
    "\n",
    "    f1 = np.max(f1_scores)\n",
    "\n",
    "    # Sensitivity, specificity, and precision\n",
    "    p[\"predicted_label\"] = 0\n",
    "    p.loc[p[\"prediction\"] > max_f1_thresh, \"predicted_label\"] = 1\n",
    "\n",
    "    true_positive = ((p[\"predicted_label\"] == 1) & (p[\"label\"] == 1)).sum()\n",
    "    false_positive = ((p[\"predicted_label\"] == 1) & (p[\"label\"] == 0)).sum()\n",
    "    true_negative = ((p[\"predicted_label\"] == 0) & (p[\"label\"] == 0)).sum()\n",
    "    false_negative = ((p[\"predicted_label\"] == 0) & (p[\"label\"] == 1)).sum()\n",
    "\n",
    "    tpr = true_positive / (true_positive + false_negative) if (true_positive + false_negative) > 0 else 0\n",
    "    tnr = true_negative / (true_negative + false_positive) if (true_negative + false_positive) > 0 else 0\n",
    "    ppv = true_positive / (true_positive + false_positive) if (true_positive + false_positive) > 0 else 0\n",
    "\n",
    "    # Print results\n",
    "    print()\n",
    "    print(f\"F1: {f1:.3f}\")\n",
    "    print(f\"True Positive Rate (Sensitivity): {tpr:.3f}\")\n",
    "    print(f\"True Negative Rate (Specificity): {tnr:.3f}\")\n",
    "    print(f\"Positive Predictive Value (Precision): {ppv:.3f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f38a30-a2bf-4ebb-920f-03876c26115d",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_stamp = \"2025-10-30\"\n",
    "\n",
    "print(\"Full set\")\n",
    "eval_set(fluxes, i_best_models, date_stamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af30797-00c4-4f30-a67a-5121858c8a5e",
   "metadata": {},
   "source": [
    "### Network gradients for class sdB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d99d46-137d-449c-9157-dbb5c31c232c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load the trained CNN model ---\n",
    "model_path = f\"CNN_models/sdB_{date_stamp}_model_{i_best_models[0]}.keras\"\n",
    "print(f\"Loading model from: {model_path}\")\n",
    "model = keras.models.load_model(model_path)\n",
    "\n",
    "# --- Prepare input fluxes for gradient calculation ---\n",
    "# Convert selected flux columns to a TensorFlow variable\n",
    "fluxes_watch = tf.Variable(fluxes[wavelength_cols], dtype='float32')\n",
    "\n",
    "# --- Compute gradients of the model's predictions with respect to input fluxes ---\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(fluxes_watch)\n",
    "    label_prediction = model(fluxes_watch, training=False)\n",
    "    grad = tape.gradient(label_prediction, fluxes_watch)\n",
    "\n",
    "# Average gradients across all input spectra\n",
    "grad_sdB = np.mean(grad, axis=0)\n",
    "\n",
    "# --- Compute the average spectrum ---\n",
    "fluxes_mean = np.mean(fluxes[wavelength_cols], axis=0)\n",
    "\n",
    "# --- Plot the average spectrum and the CNN gradients ---\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=1, nrows=2, gridspec_kw={'height_ratios': [2, 1]})\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "# Plot mean spectrum\n",
    "ax1.set_title(\"Mean Spectrum\")\n",
    "ax1.plot(wavelengths, fluxes_mean, color=\"black\", lw=2)\n",
    "ax1.set_xlabel(\"Wavelength (nm)\")\n",
    "ax1.set_ylabel(\"Normalized Flux\")\n",
    "#ax1.set_xlim(400, 650)\n",
    "\n",
    "# Plot CNN gradients\n",
    "ax2.set_title(\"CNN Gradients for sdB\")\n",
    "ax2.plot(wavelengths.astype(\"float\"), grad_sdB, color=\"black\", lw=2)\n",
    "ax2.axhline(0, color=\"black\", linestyle=\"--\")\n",
    "ax2.set_xlabel(\"Wavelength (nm)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fc74fe-1598-441b-a7db-27e64b415d3f",
   "metadata": {},
   "source": [
    "### Predict labels for all sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28e754a-6d58-4863-8deb-3dc140343f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(fluxes, i_best_models, date_stamp):\n",
    "    \"\"\"\n",
    "    Generate ensemble predictions and uncertainty estimates using the best models.\n",
    "\n",
    "    Parameters:\n",
    "    - fluxes (DataFrame): Input data for prediction.\n",
    "    - i_best_models (list or array): Indices of the best-performing models.\n",
    "    - date_stamp (str): Date identifier used in model filenames.\n",
    "\n",
    "    Returns:\n",
    "    - Tuple of np.ndarray: (mean predictions, standard deviation of predictions)\n",
    "    \"\"\"\n",
    "    # Initialize array to store predictions from each model\n",
    "    predictions_models = np.zeros((len(i_best_models), len(fluxes)))\n",
    "\n",
    "    for a, i in enumerate(i_best_models):\n",
    "        model_path = f\"CNN_models/sdB_{date_stamp}_model_{i}.keras\"\n",
    "        print(f\"Loading model: {model_path}\")\n",
    "        \n",
    "        model = keras.models.load_model(model_path)\n",
    "        predictions = model.predict(fluxes[wavelength_cols], verbose=0).flatten()\n",
    "        predictions_models[a, :] = predictions\n",
    "\n",
    "    # Return mean and standard deviation across model predictions\n",
    "    return np.mean(predictions_models, axis=0), np.std(predictions_models, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9919b4-15f8-48ea-8c85-bb5e988c577a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all normalized spectra\n",
    "filepath = \"data/XP_spectra_norm.par\"\n",
    "all_fluxes = pd.read_parquet(filepath)\n",
    "print(filepath)\n",
    "\n",
    "# Extract names of wavelength columns and the wavelength values\n",
    "column_names = all_fluxes.columns.values\n",
    "wvl_columns = column_names[1:]\n",
    "wvl_values = wvl_columns.astype(\"float64\")\n",
    "\n",
    "date_stamp = \"2025-10-29\"\n",
    "predictions_mean, predictions_std = predict(fluxes_all, i_best_models, date_stamp)\n",
    "\n",
    "fluxes_all[\"P_sdB_CNN\"] = predictions_mean\n",
    "fluxes_all[\"std_sdB_CNN\"] = predictions_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b663c13-371f-47fc-ab3f-5595f704c175",
   "metadata": {},
   "source": [
    "### Save results to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30123b1d-1868-4867-8dc3-e137563b2bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"data/CNN_predictions_sdB.csv\"\n",
    "\n",
    "fluxes_all[[\"GaiaEDR3\", \"P_sdB_CNN\", \"std_sdB_CNN\"]].to_csv(path_or_buf=filepath, index=False)\n",
    "\n",
    "print(f\"Label predictions saved to {filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64c1008-99b3-4e27-ae94-58199a9db4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(fluxes_all[\"P_sdB_CNN\"], fluxes_all[\"std_sdB_CNN\"], s=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e98647d-38c6-4c2f-9506-250970c49ad9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f2a261-1e66-4d12-affa-06ce330a8f7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
