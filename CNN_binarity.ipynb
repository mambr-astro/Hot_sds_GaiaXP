{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42e7ad4-fb63-469d-9503-1419ab8ca4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "\n",
    "from datetime import datetime\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85958e65-a1fb-4d5d-88c7-092708fc4c24",
   "metadata": {},
   "source": [
    "### Load XP coefficients and VOSA training labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4266b9-66a5-4213-a3c1-d82096f5e76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = pd.read_parquet(\"data/coeffs_20061_L2-norm.par\")\n",
    "# Columns in coeffs table that are not GaiaEDR3\n",
    "xp_columns = coeffs.columns[coeffs.columns != \"GaiaDR3\"]\n",
    "\n",
    "coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b8c364-df94-4d5f-92d5-f3ccdca96d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"data/VOSA_labels_training.csv\")\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e7e478-b41f-4ca4-8acf-072cf55d074a",
   "metadata": {},
   "source": [
    "### Cross-match coefficients and VOSA labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a24b3ce-f4d0-41e5-a387-ac14a7733720",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(coeffs, labels, on=\"GaiaDR3\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2615766d-da4e-46ca-873a-88012863b867",
   "metadata": {},
   "source": [
    "### Make test, training, and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c34ef3-fcf0-4f27-a453-8b6223d51375",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_test_set(data, n_test):\n",
    "    \"\"\"\n",
    "    Randomly selects a test set from the dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - data (pd.DataFrame): The full dataset.\n",
    "    - n_test (int): Number of samples to include in the test set.\n",
    "\n",
    "    Returns:\n",
    "    - data_test (pd.DataFrame): Randomly selected test set.\n",
    "    - data_train_val (pd.DataFrame): Remaining data after test set is removed.\n",
    "    \"\"\"\n",
    "\n",
    "    # Randomly sample test set\n",
    "    data_test = data.sample(n=n_test, ignore_index=True)\n",
    "\n",
    "    # Exclude test set rows from the original dataset\n",
    "    data_train_val = data[~data[\"GaiaDR3\"].isin(data_test[\"GaiaDR3\"])].reset_index(drop=True)\n",
    "\n",
    "    return data_test, data_train_val\n",
    "\n",
    "\n",
    "def split_train_val(data_train_val, xp_columns, n_val):\n",
    "    \"\"\"\n",
    "    Splits the dataset into a validation set and a training set.\n",
    "    The training set is balanced using SMOTE to address class imbalance.\n",
    "\n",
    "    Parameters:\n",
    "    - data_train_val (pd.DataFrame): The full dataset (minus the test samples) with features and labels.\n",
    "    - xp_columns (list): List of columns with XP coefficients to use for SMOTE.\n",
    "    - n_val (int): Number of samples to include in the validation set.\n",
    "\n",
    "    Returns:\n",
    "    - data_train (pd.DataFrame): Balanced training set.\n",
    "    - data_val (pd.DataFrame): Unbalanced validation set.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sample validation set randomly\n",
    "    data_val = data_train_val.sample(n=n_val)\n",
    "\n",
    "    # Create training set by excluding validation samples\n",
    "    data_train = data_train_val[~data_train_val[\"GaiaDR3\"].isin(data_val[\"GaiaDR3\"])]\n",
    "\n",
    "    # Apply SMOTE to balance the training set\n",
    "    smote = SMOTE(sampling_strategy=0.5, k_neighbors=2)\n",
    "    X_resampled, y_resampled = smote.fit_resample(data_train[xp_columns],\n",
    "                                                  data_train[\"VOSA\"])\n",
    "\n",
    "    # Reconstruct the training DataFrame with resampled data\n",
    "    data_train = pd.DataFrame(X_resampled, columns=xp_columns)\n",
    "    data_train[\"VOSA\"] = y_resampled\n",
    "\n",
    "    return data_train, data_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d797bc-8a82-463e-8a6c-b585fc48d0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test, data_train_val = select_test_set(data, n_test=1000)\n",
    "data_train, data_val = split_train_val(data_train_val, xp_columns, n_val=500)\n",
    "\n",
    "print(f\"Training set: {len(data_train)}\")\n",
    "n_single_training = len(data_train[data_train[\"VOSA\"] == 0])\n",
    "n_binary_training = len(data_train[data_train[\"VOSA\"] == 1])\n",
    "print(f\"{n_single_training} singles\")\n",
    "print(f\"{n_binary_training} binaries ({n_binary_training/len(data_train)*100:0.0f} %, \\\n",
    "upsampled with SMOTE)\" + \"\\n\")\n",
    "\n",
    "print(f\"Validation set: {len(data_val)} samples\")\n",
    "n_single = len(data_val[data_val[\"VOSA\"] == 0])\n",
    "n_binary = len(data_val[data_val[\"VOSA\"] == 1])\n",
    "print(f\"{n_single} singles\")\n",
    "print(f\"{n_binary} binaries ({n_binary/len(data_val)*100:0.0f} %)\" + \"\\n\")\n",
    "\n",
    "print(f\"Test set: {len(data_test)} samples\")\n",
    "n_single = len(data_test[data_test[\"VOSA\"] == 0])\n",
    "n_binary = len(data_test[data_test[\"VOSA\"] == 1])\n",
    "print(f\"{n_single} singles\")\n",
    "print(f\"{n_binary} binaries ({n_binary/len(data_test)*100:0.0f} %)\" + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed2a585-0e91-4f29-9535-8c5ebe5bf231",
   "metadata": {},
   "source": [
    "### Build CNN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1a42da-da3b-49a3-8fe4-693d6687ae6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_CNN():\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "    \n",
    "        tf.keras.layers.Input(shape=(110, 1)),\n",
    "\n",
    "        keras.layers.Conv1D(filters=16, kernel_size=3),\n",
    "        keras.layers.LeakyReLU(),\n",
    "    \n",
    "        keras.layers.Conv1D(filters=16, kernel_size=3),\n",
    "        keras.layers.LeakyReLU(),\n",
    "        \n",
    "        keras.layers.Conv1D(filters=16, kernel_size=3),\n",
    "        keras.layers.LeakyReLU(),\n",
    "\n",
    "        keras.layers.Flatten(),\n",
    "\n",
    "        tf.keras.layers.Dense(128),\n",
    "        tf.keras.layers.LeakyReLU(),\n",
    "\n",
    "        tf.keras.layers.Dense(512),\n",
    "        tf.keras.layers.LeakyReLU(),\n",
    "        tf.keras.layers.Dropout(0.33),\n",
    "\n",
    "        tf.keras.layers.Dense(265),\n",
    "        tf.keras.layers.LeakyReLU(),\n",
    "        \n",
    "        tf.keras.layers.Dense(64),\n",
    "        tf.keras.layers.LeakyReLU(),\n",
    "\n",
    "        tf.keras.layers.Dense(16),\n",
    "        tf.keras.layers.LeakyReLU(),\n",
    "\n",
    "        tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "    \n",
    "    ])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "get_model_CNN().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222224cf-77ce-45dd-8f7e-d1b209c6fa19",
   "metadata": {},
   "source": [
    "### Training of CNN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff088228-eb43-4665-8254-b986d6862f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of CNNs to train in ensamble training\n",
    "n_models = 10\n",
    "\n",
    "# Callback to stop trainig when performance on validation set does not increase\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor=\"val_loss\", mode=\"min\",\n",
    "                                           patience=100,\n",
    "                                           start_from_epoch=50,\n",
    "                                           restore_best_weights=False)\n",
    "\n",
    "for n in range(n_models):\n",
    "    # Generate a unique model path for each run\n",
    "    date_stamp = datetime.today().strftime('%Y-%m-%d')\n",
    "    model_path = f\"CNN_models/binarity_{date_stamp}_model_{n}.keras\"\n",
    "\n",
    "    # Checkpoint callback to save the best model during training\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(model_path, \n",
    "                                                    monitor=\"val_loss\", mode=\"min\", \n",
    "                                                    save_best_only=True, verbose=0)\n",
    "\n",
    "    # Create new training and validation sets for the current model\n",
    "    data_train, data_val = split_train_val(data_train_val, xp_columns, n_val=500)\n",
    "\n",
    "    # Compute class weights to address imbalance\n",
    "    n_single = len(data_train[data_train[\"VOSA\"] == 0])\n",
    "    n_binary = len(data_train[data_train[\"VOSA\"] == 1])\n",
    "    total = len(data_train)\n",
    "\n",
    "    weight_single = 1 - n_single / total\n",
    "    weight_binary = 1 - n_binary / total\n",
    "    class_weight = {0: weight_single, 1: weight_binary}\n",
    "\n",
    "        # For training set...\n",
    "    class_weight_training = {0: weight_single, 1: weight_binary}\n",
    "\n",
    "        # For validation set...\n",
    "    data_val[\"class_weight\"] = np.zeros(shape=len(data_val))\n",
    "    data_val.loc[data_val[\"VOSA\"] == 0, \"class_weight\"] = weight_single\n",
    "    data_val.loc[data_val[\"VOSA\"] == 1, \"class_weight\"] = weight_binary\n",
    "\n",
    "    # Build and compile the CNN model\n",
    "    model = get_model_CNN()\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "        loss=\"binary_crossentropy\")\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(x=data_train[xp_columns], y=data_train[\"VOSA\"], class_weight=class_weight,\n",
    "              validation_data=(data_val[xp_columns], data_val[\"VOSA\"], data_val[\"class_weight\"]),\n",
    "              epochs=10000,\n",
    "              batch_size=16,\n",
    "              callbacks=[early_stop, checkpoint],\n",
    "              verbose=2)\n",
    "\n",
    "    print(f\"Best model saved to {model_path}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bed146d-95d5-42c3-9df2-58622ddb5553",
   "metadata": {},
   "source": [
    "### Evaluate performance of CNN models and pick best 5, based on test set losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6660c6-3389-45d0-9acc-7e6d245fb4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_losses(date_stamp, data_test, n_models):\n",
    "    \"\"\"\n",
    "    Evaluate multiple Keras models and return their test losses.\n",
    "\n",
    "    Parameters:\n",
    "    - date_stamp (str): Date identifier used in model filenames.\n",
    "    - data_test (DataFrame): Test dataset containing input features and target labels.\n",
    "    - n_runs (int): Number of model runs to evaluate.\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray: Array of test losses for each model.\n",
    "    \"\"\"\n",
    "    model_losses = []\n",
    "\n",
    "    for n in range(n_models):\n",
    "        # Construct the model file path\n",
    "        model_path = f\"CNN_models/binarity_{date_stamp}_model_{n}.keras\"\n",
    "        \n",
    "        # Load the trained model\n",
    "        model = keras.models.load_model(model_path)\n",
    "        \n",
    "        # Evaluate the model on the test set\n",
    "        eval_loss = model.evaluate(\n",
    "            data_test[xp_columns],               # Input features\n",
    "            data_test[\"VOSA\"],                   # Target labels\n",
    "            batch_size=16,\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        print(f\"Test loss of model {model_path}: {eval_loss:.4f}\")\n",
    "        model_losses.append(eval_loss)\n",
    "\n",
    "    print(\"\\nDisplayed losses do not have class weights.\\n\")\n",
    "\n",
    "    return np.array(model_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4d72ef-7d33-4315-8a77-f81c616570a5",
   "metadata": {},
   "source": [
    "#### Pick best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b556b323-152c-4469-8e1a-c019beb23cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "date_stamp = \"2025-10-23\"\n",
    "n_models = 10\n",
    "n_keep = 5\n",
    "\n",
    "# Evaluate models and get their losses for the test set\n",
    "model_losses = get_model_losses(date_stamp, data_test, n_models)\n",
    "\n",
    "# Identify indices of the best-performing models (lowest losses)\n",
    "i_best_models = np.argsort(model_losses)[:n_keep]\n",
    "\n",
    "print(f\"Indices of the {n_keep} best models: {i_best_models}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a33ba9-113a-4097-baf4-bb2960f4a7ab",
   "metadata": {},
   "source": [
    "#### Evaluate best models on full, training, validation, and test sets. Use several metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b69c06-a5bd-4260-9015-82a980f8269a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_set(data_set, i_best_models, date_stamp):\n",
    "    \"\"\"\n",
    "    Evaluate an ensemble of the best models on a given dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - data_set (DataFrame): Dataset containing features and true labels.\n",
    "    - i_best_models (list or array): Indices of the best-performing models.\n",
    "    - date_stamp (str): Date identifier used in model filenames.\n",
    "\n",
    "    Returns:\n",
    "    - None (prints evaluation metrics)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize array to store predictions from each model\n",
    "    predictions_runs = np.zeros((len(i_best_models), len(data_set)))\n",
    "\n",
    "    for a, i in enumerate(i_best_models):\n",
    "        # Construct model path using the index of the best model\n",
    "        model_path = f\"CNN_models/binarity_{date_stamp}_model_{n}.keras\"\n",
    "        \n",
    "        # Load the model\n",
    "        model = keras.models.load_model(model_path)\n",
    "        \n",
    "        # Predict and store the results\n",
    "        predictions = model.predict(data_set[xp_columns], verbose=0).flatten()\n",
    "        predictions_runs[a, :] = predictions\n",
    "\n",
    "    # Compute mean and standard deviation of predictions across models\n",
    "    predictions_mean = np.mean(predictions_runs, axis=0)\n",
    "    predictions_std = np.std(predictions_runs, axis=0)\n",
    "\n",
    "    # Create a DataFrame to store predictions and true labels\n",
    "    p = pd.DataFrame({\"VOSA\": data_set[\"VOSA\"], \"prediction\": predictions_mean, \"std\": predictions_std})\n",
    "\n",
    "    # Threshold that maximises F1 score\n",
    "    precision, recall, thresholds = sklearn.metrics.precision_recall_curve(p[\"VOSA\"], p[\"prediction\"])\n",
    "    numerator = 2 * recall * precision\n",
    "    denom = recall + precision\n",
    "    f1_scores = np.divide(numerator, denom, out=np.zeros_like(denom), where=(denom!=0))\n",
    "    max_f1_thresh = thresholds[np.argmax(f1_scores)]\n",
    "\n",
    "    print(f\"Threshold that maximizes F1: {max_f1_thresh:.3f}\")\n",
    "    print()\n",
    "    print(\"With that threshold:\")\n",
    "\n",
    "    f1 = np.max(f1_scores)\n",
    "\n",
    "    # Sensitivity, specificity, and precision\n",
    "    p[\"predicted_label\"] = 0\n",
    "    p.loc[p[\"prediction\"] > max_f1_thresh, \"predicted_label\"] = 1\n",
    "\n",
    "    true_positive = ((p[\"predicted_label\"] == 1) & (p[\"VOSA\"] == 1)).sum()\n",
    "    false_positive = ((p[\"predicted_label\"] == 1) & (p[\"VOSA\"] == 0)).sum()\n",
    "    true_negative = ((p[\"predicted_label\"] == 0) & (p[\"VOSA\"] == 0)).sum()\n",
    "    false_negative = ((p[\"predicted_label\"] == 0) & (p[\"VOSA\"] == 1)).sum()\n",
    "\n",
    "    tpr = true_positive / (true_positive + false_negative) if (true_positive + false_negative) > 0 else 0\n",
    "    tnr = true_negative / (true_negative + false_positive) if (true_negative + false_positive) > 0 else 0\n",
    "    ppv = true_positive / (true_positive + false_positive) if (true_positive + false_positive) > 0 else 0\n",
    "\n",
    "    # Print results\n",
    "    print()\n",
    "    print(f\"F1: {f1:.3f}\")\n",
    "    print(f\"True Positive Rate (Sensitivity): {tpr:.3f}\")\n",
    "    print(f\"True Negative Rate (Specificity): {tnr:.3f}\")\n",
    "    print(f\"Positive Predictive Value (Precision): {ppv:.3f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161a40dc-cebb-4b98-b945-2f113d5a05fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "date_stamp = \"2025-10-23\"\n",
    "\n",
    "print(\"Full set\")\n",
    "print()\n",
    "eval_set(data, i_best_models, date_stamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f307e13-4f31-4824-b4aa-5319eff54b64",
   "metadata": {},
   "source": [
    "### Predict labels for 20061 sds coefficients.\n",
    "\n",
    "Results are the averages of the predictions from the 5 best CNN models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3861a01-98c9-4815-b4da-5194fa9f48c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data_set, i_best_models, date_stamp):\n",
    "    \"\"\"\n",
    "    Generate ensemble predictions and uncertainty estimates using the best models.\n",
    "\n",
    "    Parameters:\n",
    "    - data_set (DataFrame): Input data for prediction.\n",
    "    - i_best_models (list or array): Indices of the best-performing models.\n",
    "    - date_stamp (str): Date identifier used in model filenames.\n",
    "\n",
    "    Returns:\n",
    "    - Tuple of np.ndarray: (mean predictions, standard deviation of predictions)\n",
    "    \"\"\"\n",
    "    # Initialize array to store predictions from each model\n",
    "    predictions_runs = np.zeros((len(i_best_models), len(data_set)))\n",
    "\n",
    "    for a, i in enumerate(i_best_models):\n",
    "        model_path = f\"CNN_models/binarity_{date_stamp}_model_{n}.keras\"\n",
    "        print(f\"Loading model: {model_path}\")\n",
    "        \n",
    "        model = keras.models.load_model(model_path)\n",
    "        predictions = model.predict(data_set[xp_columns], verbose=0).flatten()\n",
    "        predictions_runs[a, :] = predictions\n",
    "\n",
    "    # Return mean and standard deviation across model predictions\n",
    "    return np.mean(predictions_runs, axis=0), np.std(predictions_runs, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7867490d-810d-47b4-b446-4e4c10531476",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_stamp = \"2025-09-16\"\n",
    "predictions_mean, predictions_std = predict(coeffs, i_best_models, date_stamp)\n",
    "\n",
    "coeffs[\"P_binary_CNN\"] = predictions_mean\n",
    "coeffs[\"std_binary_CNN\"] = predictions_std\n",
    "\n",
    "# Plot histrogram of predicted probabilities\n",
    "plt.hist(coeffs[\"P_binary_CNN\"], bins=50)\n",
    "plt.xlabel(\"P_binary_CNN\")\n",
    "plt.ylabel(\"N\")\n",
    "plt.show()\n",
    "\n",
    "# Plot scatter between 5 models relative to predicted probabilities\n",
    "plt.scatter(coeffs[\"P_binary_CNN\"], coeffs[\"std_binary_CNN\"], s=1)\n",
    "plt.xlabel(\"P_binary_CNN\")\n",
    "plt.ylabel(\"std_binary_CNN\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cba14f-b18b-428a-9aac-f58094d3a95e",
   "metadata": {},
   "source": [
    "#### Save results to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ad5859-489d-47f2-97cc-b464ad87a1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = f\"data/CNN_predictions_binarity_{date_stamp}.csv\"\n",
    "\n",
    "coeffs[[\"GaiaDR3\", \"P_binary_CNN\", \"std_binary_CNN\"]].to_csv(path_or_buf=filepath, index=False)\n",
    "\n",
    "print(f\"Label predictions saved to {filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952a12df-2a4f-45db-b842-2a9547ef3e09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
